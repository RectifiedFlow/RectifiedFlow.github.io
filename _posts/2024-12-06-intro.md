---
layout: distill
title: Rectified Flow, An Introduction
description: A Brief Introduction to the Rectified Flow Model
teaser_image: /assets/images/rectified_flow_overview.png
teaser_image_alt: "Overview of Rectified Flow"
tags: introduction
giscus_comments: true
date: 2024-12-06 10:00:00
featured: false
mermaid:
  enabled: true
  zoomable: true
code_diff: true
map: true
chart:
  chartjs: true
  echarts: true
  vega_lite: true
tikzjax: true
typograms: true
bibliography: 2024-12-06-intro.bib

# 如需添加作者信息，在下方添加authors字段
authors:
  - name: Qiang Liu
    url: "mailto:rectifiedflow@googlegroups.com"
    affiliations:
      name: UT Austin
  - name: Runlong Liao
  - name: Xixi Hu
  - name: Bo Liu

# 如果有文献，请指定bibliography文件
# bibliography: 2024-12-11-distill.bib

# 可选的目录配置
toc:
  - name: "Overview"
  - name: "Rectified Flow"
  - name: "Reflow"
---

<div class="hero">
  <img src="/assets/img/teaser_post1.png" alt="Rectified Flow Overview" style="width: 100%; max-height: 500px; object-fit: cover; border-radius: 10px; margin-bottom: 20px;">
</div>

## Overview


This blog provides a brief introduction to the Rectified Flow idea, which serves as a mainstream algorithm for training deep generative models. For a more comprehensive and rigorous discussion on the introduction, please refer to Chapter 1 in the [Rectified Flow book]() and the original paper<d-cite key="Liu2022FlowSA"></d-cite>.

Generative modeling can be formulated as finding a computational procedure that transforms a noise distribution, denoted by $$\pi_0$$, into the unknown data distribution $$\pi_1$$. In flow models, this procedure is represented by an ordinary differential equation (ODE):

$$
\dot{Z}_t = v_t(Z_t), \quad \forall t \in [0,1], \quad \text{starting from } Z_0 \sim \pi_0, \tag{1}
$$

where $$\dot{Z}_t = \mathrm dZ_t / \mathrm dt$$ denotes the time derivative, and the velocity field $$v_t(x) = v(x, t)$$ is a learnable function to be estimated to ensure that $$Z_1$$ follows the target distribution $$\pi_1$$ when starting from $$Z_0 \sim \pi_0$$. In this case, we say that the stochastic process $$Z = \{Z_t\}$$ provides an (ODE) transport from $$\pi_0$$ to $$\pi_1$$.

It is important to note that, in all but trivial cases, there exist _infinitely many_ ODE transports from $$\pi_0$$ to $$\pi_1$$, provided that at least one such process exists. Thus, it is essential to be clear about which types of ODEs we should prefer.

One option is to favor ODEs that are easy to solve at inference time. In practice, the ODEs are approximated using numerical methods, which typically construct piecewise linear approximations of the ODE trajectories. For instance, a common choice is Euler's method:

$$
\hat{Z}_{t+\epsilon} = \hat{Z}_t + \epsilon v_t(\hat{Z}_t), \quad \forall t \in \{0, \epsilon, 2\epsilon, \dots, 1\}, \tag{2}
$$

where $$\epsilon > 0$$ is a step size. Varying the step size $$\epsilon$$ introduces a trade-off between accuracy and computational cost: smaller $$\epsilon$$ yields high accuracy but incurs a larger number of calculation steps. Therefore, we should seek ODEs that can be approximated accurately even with large step sizes.

<div class="l-body">
  <iframe src="{{ '/assets/plotly/intro_euler_approximation_with_arrows.html' | relative_url }}" 
          frameborder="0" 
          scrolling="no" 
          height="480px" 
          width="100%"></iframe>
</div>

The ideal scenario arises when the ODE follows straight-line trajectories, in which case Euler approximation yields zero discretization error regardless of the choice of step sizes. In such cases, the ODE, up to time reparameterization, should satisfy:

$$
Z_t = t Z_1 + (1 - t) Z_0, \quad \implies \quad \dot{Z}_t = Z_1 - Z_0.
$$

These ODEs, known as straight transports, enable fast generative models that can be simulated in a single step. We refer to the resulting pair $$(Z_0, Z_1)$$ as a straight coupling of $$\pi_0$$ and $$\pi_1$$. In practice, perfect straightness may not be achievable, but a goal we can aim for is to make the ODE trajectories as straight as possible to maximize computational efficiency.

It is possible to discuss generalized notions of straightness when solvers other than Euler’s method are used.

## Rectified Flow

To construct a flow transporting $$\pi_0$$ to $$\pi_1$$, let us assume that we are given an arbitrary coupling $$(X_0, X_1)$$ of $$\pi_0$$ and $$\pi_1$$, from which we can obtain empirical draws. This can be simply the independent coupling with law $$\pi_0 \times \pi_1$$, as is common in practice when we have access to independent samples from $$\pi_0$$ and $$\pi_1$$. The idea is that we are going to take $$(X_0, X_1)$$ and convert it to a better coupling generated by an ODE model, and optionally, we can go further to iteratively repeat this process to further enhance desired properties, such as straightness.

Rectified flow works in the following ways:

- **Build Interpolation:**  
   We build an interpolation process $$\{X_t\} = \{X_t : t \in [0, 1]\}$$ that smoothly interpolates between $$X_0$$ and $$X_1$$. Although general choices are possible, let us consider the canonical choice of straight-line interpolation:
  $$
  X_t = t X_1 + (1 - t) X_0.
  $$
  Here $$\{X_t\}$$ is a stochastic process generated in a special way: we first sample the endpoints $$X_0$$ and $$X_1$$ and then sample the intermediate trajectory connecting them. Such processes are also known as bridge processes, where the intermediate values of $$X_t$$ smoothly "bridge" the distribution between $$X_0$$ and $$X_1$$.

<div class="l-body">
  <iframe src="{{ '/assets/plotly/intro_straight_interp.html' | relative_url }}" 
          frameborder="0" 
          scrolling="no" 
          height="630px" 
          width="100%"></iframe>
</div>
   
- **Marginal Matching:**  
   By construction, the marginal distributions of $$X_0$$ and $$X_1$$ match the target distributions $$\pi_0$$ and $$\pi_1$$ through the interpolation process $$\{X_t\}$$. However, $$\{X_t\}$$ is not a causal ODE process like $$\dot{Z}_t = v_t(Z_t)$$, which evolves forward from $$Z_0$$. Instead, generating $$X_t$$ requires knowledge of both $$X_0$$ and $$X_1$$, rather than evolving solely from $$X_0$$ as $$t$$ increases.

This issue can be resolved if we can convert $$\{X_t\}$$ somehow into a causal ODE process while preserving the marginal distributions of $$X_t$$ at each time $$t$$. Perhaps surprisingly, this can be achieved by simply training the ODE model $$\dot{Z}_t = v_t(Z_t)$$ to match the slope $$\dot{X}_t$$ of the interpolation process via:

$$
\min_v \int_0^1 \mathbb{E} \left[ \left\| \dot{X}_t - v_t(X_t) \right\|^2 \right] \mathrm dt. \tag{3}
$$

The theoretical minimum is achieved by:

$$
v_t^*(x) = \mathbb{E} \left[ \dot{X}_t \mid X_t = x \right],
$$

which denotes the expectation of the slope $$\dot{X}_t$$ of the interpolation process passing through a given point $$X_t = x$$.

> **Definition: Rectified Flow.**
>
> For any time-differential stochastic process $$\{X_t\} = \{X_t : t \in [0, 1]\}$$, we call the ODE process:
>
> $$
> \dot{Z}_t = v_t^*(Z_t) \quad \text{with} \quad v_t^*(x) = \mathbb{E} \left[ \dot{X}_t \mid X_t = x \right],
> $$
>
> and $$Z_0 = X_0$$ the **rectified flow** induced by $$\{X_t\}$$. We denote it as:
>
> $$
> \{Z_t\} = \text{RectFlow}(\{X_t\}).
> $$

With the canonical straight interpolation, we have $$\dot{X}_t = X_1 - X_0$$ by taking the derivative of $$X_t$$ with respect to $$t$$. It yields:

$$
\min_v \int_0^1 \mathbb{E} \left[ \| \dot{X}_t - v_t(X_t) \|^2 \right] \mathrm dt, \quad X_t = t X_1 + (1 - t) X_0.
$$

In practice, the optimization in (3) can be efficiently solved even for large AI models when $$v$$ is parameterized as modern deep neural nets. This is achieved by leveraging off-the-shelf optimizers with stochastic gradients, computed by drawing pairs $$(X_0, X_1)$$ from data, sampling $$t$$ uniformly in $$[0, 1]$$, and then computing the corresponding $$(X_t, \dot{X}_t)$$ using the interpolation formula.

<div class="l-body">
  <iframe src="{{ '/assets/plotly/intro_1rf.html' | relative_url }}" 
          frameborder="0" 
          scrolling="no" 
          height="630px" 
          width="100%"></iframe>
</div>

This figure illustrates the intuition. In the interpolation process $$\{X_t\}$$, different trajectories may have intersecting points, resulting in multiple possible values of $$\dot{X}_t$$ associated with the same point $$X_t$$ due to uncertainty about the originating trajectory (see the straight interpolation figure). However, by the definition of an ODE $$\dot{Z}_t = v_t^*(Z_t)$$, the update direction $$\dot{Z}_t$$ at each point $$Z_t$$ is uniquely determined by $$Z_t$$, making it impossible for different trajectories of $$\{Z_t\}$$ to intersect and then diverge. At these intersection points of $$\{X_t\}$$, where $$\dot{X}_t$$ is stochastic and non-unique, $$Z_t$$ "derandomizes" the update direction by following the conditional expectation:

$$
v_t^*(X_t) = \mathbb{E} \left[ \dot{X}_t \mid X_t \right],
$$

thus providing the unique update direction required by ODEs.

What makes rectified flow $$\{Z_t\}$$ useful is that it preserves the marginal distributions of $$\{X_t\}$$ at each point while resulting in a "better" coupling $$(Z_0, Z_1)$$ in terms of optimal transport:

#### 1. Marginal Preservation

The $$\{X_t\}$$ and its rectified flow $$\{Z_t\}$$ share the same marginal distributions at each time $$t \in [0, 1]$$, that is:

$$
\text{Law}(Z_t) = \text{Law}(X_t), \quad \forall t \in [0, 1].
$$

<div class="l-body">
  <img src="/assets/img/flow_in_out.png" alt="cross" style="max-width:100%;" />
</div>

#### 2. Transport Cost

The start-end pairs $$(Z_0, Z_1)$$ from the rectified flow $$\{Z_t\}$$ guarantee to yield no larger transport cost than $$(X_0, X_1)$$, simultaneously for all convex cost functions $$c$$:

$$
\mathbb{E} \left[ c(Z_1 - Z_0) \right] \leq \mathbb{E} \left[ c(X_1 - X_0) \right], \quad \forall \text{convex } c : \mathbb{R}^d \to \mathbb{R}.
$$

## Reflow

While rectified flows tend to favor straight trajectories, they are not perfectly straight. As shown in Figure, the flow makes turns at intersection points of the interpolation trajectories $$\{X_t\}$$. How can we further improve the flow to achieve straighter trajectories and hence speed up inference?

A key insight is that the start-end pairs $$(Z_0, Z_1)$$ generated by rectified flow, called the **rectified coupling** of $$(X_0, X_1)$$, form a better and "straighter" coupling compared to $$(X_0, X_1)$$. This is because if we connect $$Z_0$$ and $$Z_1$$ with a new straight-line interpolation, it would yield fewer intersection points. Hence, training a new rectified flow based on this interpolation would result in straighter trajectories, leading to faster inference.

Formally, we apply the RectFlow(·) procedure recursively, yielding a sequence of rectified flows starting from $$\{Z_t^0\} = \{X_t^0\}$$:

**Reflow:**

$$
\{Z_t^{k+1}\} = \texttt{RectFlow}(\texttt{Interp}(Z_0^k, Z_1^k)), \tag{4}
$$

where $$\text{Interp}(Z_0^k, Z_1^k)$$ denotes an interpolation process given $$(Z_0^k, Z_1^k)$$ as the endpoints. We call $$\{Z_t^k\}$$ the k-th rectified flow, or simply **k-rectified flow**, induced from $$(X_0, X_1)$$.

This reflow procedure is proved to "straighten" the paths of rectified flows in the following sense: Define the following measure of straightness of $$\{Z_t\}$$:

$$
S(\{Z_t\}) = \int_0^1 \mathbb{E} \left[ \|Z_1 - Z_0 - \dot{Z}_t\|^2 \right] \mathrm dt,
$$

where $$S(\{Z_t\})$$ is a measure of the straightness of $$\{Z_t\}$$, with $$S(\{Z_t\}) = 0$$ corresponding to straight paths. Then we have the following for reflow:

$$
\mathbb{E}_{k \sim \text{Unif}(\{1, \dots, K\})} \left[S(\{Z_t^k\})\right] = \mathcal{O}(1 / K), \tag{5}
$$

Hence, we would obtain perfectly straight-line dynamics in the limit of $$k \to +\infty$$. Note that reflow can begin from any coupling $$(X_0, X_1)$$, so it provides a general procedure for straightening and thus speeding up any given dynamics while preserving the marginals.

<div class="l-body">
  <iframe src="{{ '/assets/plotly/intro_2rf.html' | relative_url }}" 
          frameborder="0" 
          scrolling="no" 
          height="630px" 
          width="100%"></iframe>
</div>
