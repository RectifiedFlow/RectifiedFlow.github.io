<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://rectifiedflow.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://rectifiedflow.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-12-18T18:12:03+00:00</updated><id>https://rectifiedflow.github.io/feed.xml</id><title type="html">blank</title><subtitle>Everything should be made as simple as possible, but not simpler. </subtitle><entry><title type="html">DDIM and Natural Euler Samplers</title><link href="https://rectifiedflow.github.io/blog/2024/discretization/" rel="alternate" type="text/html" title="DDIM and Natural Euler Samplers"/><published>2024-12-10T11:00:00+00:00</published><updated>2024-12-10T11:00:00+00:00</updated><id>https://rectifiedflow.github.io/blog/2024/discretization</id><content type="html" xml:base="https://rectifiedflow.github.io/blog/2024/discretization/"><![CDATA[ <h2 id="overview">Overview</h2> <p>Rectified flow learns an ODE of the form \(\mathrm{d}Z_t = v_t(Z_t; \theta)\) by minimizing the loss between its velocity field and the slope of an interpolation process. As <a href="../interpolation/#affine-interpolations-are-pointwise-transformable">previously discussed</a>, affine interpolations yield essentially equivalent rectified flows thus identical couplings.</p> <p>In practice, those ODE trajectories must be approximated by <strong>discrete steps</strong>. A standard approach is the Euler method: at each step, the local trajectory is approximated by its tangent line. For rectified flows induced by straight interpolation, this is a intuitive choice. However, if the interpolation is nonlinear (e.g., spherical), it may be more natural to approximate each step with a locally curved segment that matches the interpolation. We refer to such methods as <strong>natural Euler samplers</strong>.</p> <p>Notably, the DDIM sampler can be viewed as a natural Euler sampler under its interpolation. In this perspective, we can understand DDIM without complex derivation of its coefficients.</p> <p>A key property shares across pointwise transformable interpolations is:</p> <blockquote class="definition"> <p>If two interpolation processes are pointwise transformable into one another using maps \(\phi\) and \(\tau\), then the <strong>discrete sampling points produced by their respective natural Euler samplers are also pointwise transformable</strong> under the same mappings, provided their time grids are related by a time scaling function \(\tau_t\).</p> </blockquote> <p>In other words, <strong>when using natural Euler samplers, changing the affine interpolation scheme <em>at inference time</em> is essentially adjusting the sampling time grid.</strong> In the case of DDIM, one obtains <strong>exactly the same results</strong> as those produced by the vanilla Euler sampler (appropriately rescaling the time grid) applied to a rectified flow induced by a straight interpolation.</p> <p>For a more comprehensive and rigorous discussion on this topic, please refer to Chapter 5 in the <a href="https://github.com/lqiang67/rectified-flow/tree/main/pdf">Rectified Flow Lecture Notes</a>.</p> <h2 id="affine-interpolation-solver">Affine Interpolation Solver</h2> <p>Given a coupling \((X_0, X_1)\) of source distirbution \(X_0 \sim \pi_0\) and target unknown data distribution \(X_1 \sim \pi_1\), we define an interpolation function formally:</p> <blockquote class="definition"> <p><strong>Definition 1.</strong> Let \(\mathtt I:[0,1] \times \mathbb R^d \times \mathbb R^d \mapsto \mathbb R^d\) be a <strong>interpolation function</strong> satisfying \(\mathtt I_0(x_0, x_1) = x_0, \quad \mathtt I_1(x_0, x_1)=x_1.\)</p> <p>We construct the interpolation process \(\{X_t\}\) by</p> \[X_t = \mathtt I_t(X_0, X_1).\] <p>We also require that \(\{X_t\}\) is differentiable in time, that is, the time derivative exists pointwise</p> \[\dot{X}_t := \partial_t \mathtt{I}_t(X_0, X_1).\] </blockquote> <p>In many cases, given \((X_t, \dot{X}_t)\), we wish to recover \((X_0, X_1)\) that satisfy</p> \[\begin{cases} X_t = \mathtt{I}_t(X_0, X_1), \\[6pt] \dot{X}_t = \partial_t \mathtt{I}_t(X_0, X_1). \end{cases}\] <p>For affine interpolations \((X_t = \alpha_t X_1 + \beta_t X_0)\), this problem reduces to solving a simple \(2 \times 2\) linear system. Moreover, because expectations are linear, conditional expectations under affine interpolation also inherit this linear structure.</p> <blockquote class="example"> <p><strong>Affine Interpolation Solvers.</strong> Define</p> \[\begin{aligned} v_t(x) &amp;:= \mathbb{E}[\dot{X}_t \mid X_t = x], &amp;\text{(RF velocity field)} \\[6pt] \hat{x}_{0\mid t}(x) &amp;:= \mathbb{E}[X_0 \mid X_t = x], &amp;\text{(Expected noise $X_0$)} \\[6pt] \hat{x}_{1\mid t}(x) &amp;:= \mathbb{E}[X_1 \mid X_t = x]. &amp;\text{(Expected data $X_1$)} \end{aligned}\] <p>Given any two of \(\{v_t, \hat x_{0\mid t}, \hat x_{1\mid t}, x_t\}\) or \(\{\dot X_t, X_0, X_1, X_t\}\), we can explicitly solve for the other two that satisfy</p> \[X_t = \alpha_t X_1 + \beta_t X_0, \quad \dot{X}_t = \dot{\alpha}_t X_1 + \dot{\beta}_t X_0. \\\] <p>or</p> \[x_t =\alpha_t\hat{x}_{1\mid t} + \beta_t \hat{x}_{0\mid t}, \quad v_t = \dot \alpha_t \hat{x}_{1\mid t} + \dot \beta_t \hat{x}_{0\mid t}\] <p>This can be efficiently implemented as <a href="https://github.com/lqiang67/rectified-flow/blob/main/rectified_flow/flow_components/interpolation_solver.py">affine interpolation solvers</a>.</p> </blockquote> <h2 id="natural-euler-sampler">Natural Euler Sampler</h2> <p>The vanilla Euler method approximates the flow \(\{Z_t\}\) on a discrete time grid \(\{t_i\}\) by locally linear steps:</p> \[\hat{z}_{t_{i+1}} = \hat{z}_{t_i} + (t_{i+1} - t_i) \cdot v_{t_i}(\hat{z}_{t_i}).\] <p>At each step, the solution is approximated by the straight line tangent to the rectified flow at \(\hat{z}_{t_i}\).</p> <p>In contrast, the <strong>natural Euler sampler</strong> replaces the straight line with an interpolation curve that is tangent at \(\hat{z}_{t_i}\). The update rule becomes:</p> \[\hat{z}_{t_{i+1}} = \mathtt{I}_{t_{i+1}}(\hat{x}_{0 \mid t_i}, \hat{x}_{1 \mid t_i}),\] <p>where \(\hat{x}_{0 \mid t_i}\) and \(\hat{x}_{1 \mid t_i}\) are obtained through the affine interpolation solver. These serve as the estimated endpoints of the interpolation curve passing through \(\hat{z}_{t_i}\) and matching the slope \(\partial \mathtt I_{t_i}(\hat{x}_{0 \mid t_i}, \hat{x}_{1 \mid t_i}) = v_{t_i}(\hat{z}_{t_i})\) at time \(t_i\). In other words, the natural Euler method updates the solution by advancing along a locally curved path that is consistent with underlying interpolation curve.</p> <p>For instance, the natural euler sampler under spherical rectified flow can be derived as:</p> <blockquote class="example"> <p><strong>Example 1. Natural Euler Sampler for Spherical Interpolation</strong></p> \[\hat z_{t + \epsilon} =\cos\left(\frac{\pi}{2} \cdot\epsilon\right) \cdot \hat z_{t} + \frac{2}{\pi} \sin \left(\frac{\pi}{2} \cdot\epsilon\right) \cdot v_t(\hat z_t)\] </blockquote> <p>As a more involved example, consider the DDIM algorithm. Despite its complex appearance, DDIM’s inference scheme can be viewed as a natural Euler sampler:</p> <blockquote class="example"> <p><strong>Example 2. Natural Euler Sampler for DDIM</strong></p> <p>The discretized inference scheme of DDIM is the instance of natural Euler sampler for spherical interpolations satisfying \(\alpha_t^2 + \beta_t^2 = 1\). The inference update of DDIM is written in terms of the expected noise \(\hat{x}_{0\mid t}(x) = \mathbb{E}[X_0 \mid X_t = x]\), we rewrite the update steo using \(\hat{x}_{0 \mid t}\):</p> \[\begin{aligned} \hat{z}_{t+\epsilon} &amp;= \alpha_{t+\epsilon} \cdot\hat{x}_{1\vert t}(\hat{z}_t) + \beta_{t+\epsilon} \cdot \hat{x}_{0\vert t}(\hat{z}_t) \\ &amp;\overset{*}{=} \alpha_{t+\epsilon} \left( \frac{\hat{z}_t - \beta_t \cdot\hat{x}_{0\vert t}(\hat{z}_t)}{\alpha_t} \right) + \beta_{t+\epsilon} \cdot \hat{x}_{0\vert t}(\hat{z}_t) \\ &amp;= \frac{\alpha_{t+\epsilon}}{\alpha_t} \hat{z}_t + \left( \beta_{t+\epsilon} - \frac{\alpha_{t+\epsilon} \beta_t}{\alpha_t} \right) \hat{x}_{0\vert t}(\hat{z}_t) \end{aligned}\] <p>where in \(\overset{*}{=}\) we used \(\alpha_t \cdot \hat{x}_{1\vert t}(\hat{z}_t) + \beta_t\cdot \hat{x}_{0\vert t}(\hat{z}_t) = \hat{z}_t\). We can slightly rewrite the update as:</p> \[\frac{\hat{z}_{t+\epsilon}}{\alpha_{t+\epsilon}} = \frac{\hat{z}_t}{\alpha_t} + \left( \frac{\beta_{t+\epsilon}}{\alpha_{t+\epsilon}} - \frac{\beta_t}{\alpha_t} \right) \hat{x}_{0\vert t}(\hat{z}_t),\] <p>which exactly matches Equation 13 of <d-cite key="song2020denoising"></d-cite>.</p> </blockquote> <h2 id="equivalence-of-natural-euler-trajectories">Equivalence of Natural Euler Trajectories</h2> <p>The trajectory points obtained from natural Euler samplers are equivalent under pointwise transformations.</p> <blockquote class="theorem"> <p><strong>Theorem 1. Equivalence of Natural Euler Trajectories</strong></p> <p>Suppose \(\{X_t\}\) and \(\{X_t'\}\) are two interpolation processes contructed from the same couping and that they’re related by a pointwise transform \(X_t' = \phi_t(X_{\tau_t})\). Consider the trajectories \(\{\hat{z}_{t_i}\}_i\) and \(\{\hat{z}_{t_i'}'\}_i\), generated by applying the natural Euler method to the rectified flows induced by \(\{X_t\}\) and \(\{X_t'\}\), respectively, on time grids \(\{t_i\}\) and \(\{t_i'\}\).</p> <p>If the time grids satisfy \(\tau(t_i') = t_i\) for all \(i\), and the initial conditions align via \(\hat{z}_{t_0}' = \phi(\hat{z}_{t_0})\), then the <strong>discrete</strong> trajectories also match under the same transform:</p> \[\hat{z}_{t_i'}' = \phi_{t_i}(\hat{z}_{t_i}) \quad \text{for all } i = 0,1,\ldots\] <p>In particular, applying the natural Euler method to a rectified flow induced by an affine interpolation \(\{X_t'\}\) on a uniform grid \(t_i' = i/n\) is equivalent to applying the standard (straight) Euler method to the rectified flow induced by the corresponding straight interpolation \(\{X_t\}\), but with a non-uniform time grid \(t_i = \tau(i/n)\).</p> </blockquote> <p>This result strengthens the earlier <a href="../interpolation/#affine-interpolations-are-pointwise-transformable">equivariance property</a> established for continuous-time ODEs. It shows that the same property holds at the discrete level: as the step size approaches zero, the discrete trajectories converge to their continuous-time counterparts, preserving the pointwise transformable structure.</p> <p>We can express the equivariance property succinctly. Let \(\{X_t'\} = \texttt{Transform}(\{X_t\})\) denote a pointwise transformation, and let \(\texttt{NaturalEulerRF}\) represent the operation of generating discrete trajectories from a rectified flow ODE using the natural Euler sampler. Then:</p> \[\texttt{NaturalEulerRF}(\texttt{Transform}(\{X_t\})) = \texttt{Transform}(\texttt{NaturalEulerRF}(\{X_t\})).\] <p>This <strong>discrete-level equivalence</strong> extends the continuous-time theore, ensuring that natural Euler samplers inherit the same invariances as the underlying rectified flow ODE.</p> <blockquote class="example"> <p><strong>Example 3. Equivalence of Straight Euler and DDIM sampler</strong></p> <p>Since DDIM is the natural Euler sampler under spherical interpolation, and the vanllia Euler method is the natural Euler under the straight interpolation, they yield the same results under proper transform on the time grid. Specifically, the natural Euler sampler on an affine interpolation \(X_t' = \alpha'_t X_1 + \beta'_t X_0\) using a uniform time grid \(t'_i = i/n\) is equivalent to applying the vanilla (straight) Euler method to the straight RF (induced from \(X_t = tX_1 + (1 - t)X_0\)) but with a non-uniform time grid:</p> \[t_i = \frac{\alpha'_{i/n}}{\alpha'_{i/n}+\beta'_{i/n}}\] <p>Conversely, starting from the straight RF and using a vanilla Euler sampler on the time grid \(\{t_i\}\), one can recover the DDIM sampler by finding a time grid \(\{t'_i\}\) that satisfies:</p> \[t_i = \frac{\alpha'_{t_{i'}}}{\alpha_{t_{i'}}'+\beta'_{t_i'}}\] </blockquote> <p>In the following figures, we use two identical straight RF and spherical RF to illustrate the claims above. We use spherical RF since DDIM is only a time rescaling of it.</p> <p>In the following figures, we compare two equivalent straight rf and a spherical rf to illustrate the points discussed. We use spherical rf since DDIM can be viewed as a simple time-rescaling of it.</p> <div class="l-body-outset"> <figure id="figure-1"> <iframe src="/assets/plotly/discrete_euler.html" frameborder="0" scrolling="no" height="630px" width="100%"> </iframe> <figcaption> <a href="#figure-1">Figure 1</a>. Although the straight and spherical RF induce the same coupling theoretically, discretization errors accumulate when using a finite number of Euler steps (here, 10 steps). As a result, the final generated samples differ significantly. </figcaption> </figure> </div> <div class="l-body-outset"> <figure id="figure-2"> <iframe src="/assets/plotly/discrete_natural_unmatch.html" frameborder="0" scrolling="no" height="630px" width="100%"> </iframe> <figcaption> <a href="#figure-2">Figure 2</a>. When using a natural Euler sampler with a uniform 10-step time grid for both RFs, the results are nearly identical. Minor deviations occur because the time parameterizations do not perfectly match. </figcaption> </figure> </div> <div class="l-body-outset"> <figure id="figure-3"> <iframe src="/assets/plotly/discrete_natural_match.html" frameborder="0" scrolling="no" height="630px" width="100%"> </iframe> <figcaption> <a href="#figure-3">Figure 3</a>. After adjusting the straight RF's time grid using \(\tau_t\), the discrete trajectories from both RFs align exactly. </figcaption> </figure> </div>]]></content><author><name>Runlong Liao</name></author><category term="tutorial"/><summary type="html"><![CDATA[Even discretized trajectories are equivalent]]></summary></entry><entry><title type="html">All Flows are One Flow</title><link href="https://rectifiedflow.github.io/blog/2024/interpolation/" rel="alternate" type="text/html" title="All Flows are One Flow"/><published>2024-12-10T10:00:00+00:00</published><updated>2024-12-10T10:00:00+00:00</updated><id>https://rectifiedflow.github.io/blog/2024/interpolation</id><content type="html" xml:base="https://rectifiedflow.github.io/blog/2024/interpolation/"><![CDATA[ <p>This blog introduces the equivalent relationships between rectified flows induced from different affine interpolations, based on Chapter 3 of these <a href="https://github.com/lqiang67/rectified-flow/tree/main/pdf">lecture notes</a>. Related observations and discussion can also be found in <d-cite key="karras2022elucidating,kingma2024understanding,shaulbespoke,gao2025diffusionmeetsflow"></d-cite>.</p> <h2 id="overview">Overview</h2> <p>Given an arbitrary coupling \((X_0, X_1)\) of source distribution \(X_0\sim \pi_0\) and target unknown data distribution \(X_1 \sim \pi_1\), recall that rectified flow learns a ODE</p> \[\mathrm d Z_t = v_t(Z_t) \, \mathrm d t,\] <p>which, starts from the noise \(Z_0=X_0\), leads to generated data \(Z_1\). This velocity is learned by minimizing the mean square loss from the slope of an interpolation process:</p> \[\min_v \int _0 ^1 \mathbb E \left[\left\| \dot X_t - v_t(X_t)\right\|^2 \right] \mathrm d t,\] <p>where \(\{X_t\} = \{X_t: t\in [0,1]\}\) is an interpolation process connecting \(X_0\) and \(X_1\), and \(\dot X_t\) denotes its time derivative. We call the ODE process \(\mathrm d Z_t = v_t(Z_t) \mathrm d t\) with \(Z_0=X_0\) the rectified flow induced from \(\{X_t\}\), and denote it as:</p> \[\{Z_t\} = \texttt {Rectify}(\{X_t\}).\] <p>Theoretically, \(\{X_t\}\) can be any smooth interpolation between source and target distributions. Different methods employ these or other interpolation schemes. One might suspect that, since these choices influence the learned rectified flow velocity and thus potentially affect inference performance and speed, they must be decided upon during training. But is this really necessary?</p> <p>In this blog, we show that if two interpolation processes are <em>pointwise transformable</em> in a suitable sense, then they would induce essentially <strong><em>equivalent</em></strong> rectified flow dynamics and identical couplings.</p> <p>Furthermore, as all affine interpolations are pointwise transformable into one another, it suffices to adopt a simple interpolation—such as the straight-line interpolation \(X_t = t X_1 + (1 - t) X_0\)—during training. Later, through simple transformations, any desired affine interpolation can be recovered at the sampling stage. Because of this flexibility, <em>the choice of interpolation at training time is less critical</em>, and different interpolation schemes can be freely adopted at inference, where their differences become more relevant.</p> <h2 id="point-wisely-transformable-interpolations">Point-wisely Transformable Interpolations</h2> <p>Let us start with a general notion of pointwise transformability between interpolation processes.</p> <blockquote class="definition"> <p><strong>Definition 1.</strong> Consider any two interpolation processes \(\{X_t : t \in [0,1]\}\) and \(\{X'_t : t \in [0,1]\}\). We say they are <strong>pointwise transformable</strong> if there exist differentiable maps \(\tau: [0,1] \to [0,1]\) and \(\phi: [0,1] \times \mathbb{R}^d \to \mathbb{R}^d\) such that \(\phi_t\) is invertible for every \(t \in [0,1]\) and</p> \[X'_t = \phi_t(X_{\tau_t}) \quad \text{for all } t \in [0,1].\] </blockquote> <p>If two interpolations are pointwise transformable, then the trajectories of their respective rectified flows satisfy the very same transform. In addition, if the two interpolations are constructed from the same coupling, they yields the same recitifed coupling theoretically.</p> <blockquote class="theorem"> <p><strong>Theorem 1.</strong> Suppose two interpolations \(\{X_t\}\) and \(\{X'_t\}\) are pointwise transformable and constructed from the same coupling \((X_0, X_1) = (X'_0, X'_1)\). Assume \(\tau_0=0\) and \(\tau_1=1\).</p> <p>Let \(\{v_t\}\) and \(\{v'_t\}\) be their corresponding rectified flow velocity fields, and \(\{Z_t\}\) and \(\{Z'_t\}\) their rectified flows with \(\mathrm d Z_t = v_t(Z_t)\mathrm d t\), \(Z_0 = X_0\), and \(\mathrm d Z'_t = v'_t(Z'_t)\mathrm d t\), \(Z'_0=X'_0\), respectively. Then</p> <ol> <li> <p>The rectified flows \(\{Z_t\}\to\{Z'_t\}\) can be transformed with the very same pointwise maps:</p> \[Z'_t = \phi_t(Z_{\tau_t}) \quad \text{for all } t \in [0,1].\] </li> <li> <p>The two rectified flows produce the rectified coupling:</p> \[(Z_0, Z_1) = (Z'_0, Z'_1).\] </li> <li> <p>Their velocity fields are related by:</p> \[v'_t(x) = \partial_t \phi_t(\phi_t^{-1}(x)) + \bigl(\nabla \phi_t(\phi_t^{-1}(x))\bigr)^\top v_{\tau_t}(\phi_t^{-1}(x)) \dot{\tau}_t. \tag{1}\] </li> </ol> </blockquote> <p>In other words, denote by \(\{X'_t\} := \texttt{Transform}(\{X_t\})\) a pointwise transformation on the interpolations. Then the result shows that the operation \(\texttt{Rectify}(\cdot)\), which maps an interpolation \(\{X_t\}\) to its corresponding rectified flow \(\{Z_t\}\), is <strong>equivariant</strong> under pointwise transformations:</p> \[\texttt{Rectify}(\texttt{Transform}(\{X_t\})) = \texttt{Transform}(\texttt{Rectify}(\{X_t\})).\] <h3 id="affine-interpolations-are-pointwise-transformable">Affine Interpolations are Pointwise Transformable</h3> <p>In practice, one often considers interpolations of the form</p> \[X_t = \alpha_t X_1 + \beta_t X_0,\] <p>where \(\alpha_t\) and \(\beta_t\) are monotonic on \(t\in[0,1]\) and satisfy the boundary conditions:</p> \[\alpha_0=\beta_1=0, \quad \alpha_1 = \beta_0 = 1.\] <p>All such interpolations are <em>affine</em>. Here are some examples of affine interpolations.</p> <ol> <li> <p><strong><em>Straight interpolation</em></strong>, as used in <d-cite key="liu2022flow,lipman2022flow,albergo2023stochastic"></d-cite>:</p> \[X_t = tX_1 + (1-t) X_0.\] <p>This yields straight lines connecting \(\pi_0\) and \(\pi_1\) at a constant speed \(\dot X_t = X_1 - X_0.\)</p> </li> <li> <p><strong><em>Spherical linear interpolation</em></strong> (<em>slerp</em>), employed by iDDPM <d-cite key="nichol2021improved"></d-cite>:</p> \[X_t = \sin\left(\frac{\pi}{2} t\right)X_1 + \cos\left(\frac{\pi}{2} t\right)X_0,\] <p>which travels along the shortest great-circle arc on a sphere at a constant speed.</p> </li> <li> <p><strong><em>DDIM interpolation</em></strong>,<d-cite key="song2020denoising"></d-cite> a spherical interpolation satisfying \(\alpha_t^2 + \beta_t^2 = 1\) but with a non-uniform speed defined by $\alpha_t$:</p> \[X_t = \alpha_t X_1 + \sqrt{1-\alpha_t^2} X_0,\] <p>where \(\alpha_t = \exp\bigl(-\frac{1}{4}a(1-t)^2 - \tfrac{1}{2}b(1-t)\bigr)\), and \(a=19.9,b=0.1\) by default.</p> </li> </ol> <p>For this class of interpolations, the maps \(\phi\) and \(\tau\) reduce to scalar transforms. <strong>All affine interpolations are pointwise transformable</strong> by appropriately scaling time and input. Consequently, their corresponding rectified flows can also be related through the same pointwise transforms, ultimately producing the same rectified couplings. This result aligns with observations made by other authors<d-cite key="karras2022elucidating,kingma2024understanding,shaulbespoke,gao2025diffusionmeetsflow"></d-cite>.</p> <blockquote class="definition"> <p><strong>Proposition 1.</strong> Consider two <strong>affine interpolation</strong> processes derived from the same coupling \((X_0, X_1)\):</p> \[X_t = \alpha_t X_1 + \beta_t X_0 \quad \text{and} \quad X_t' = \alpha_t' X_1 + \beta_t' X_0.\] <p>Then there exist scalar functions \(\tau_t\) and \(\omega_t\) such that</p> \[X_t' = \frac{1}{\omega_t} X_{\tau_t}, \quad \forall t \in [0,1],\] <p>where \(\tau_t\) and \(\omega_t\) are determined by solving</p> \[\frac{\alpha_{\tau_t}}{\beta_{\tau_t}} = \frac{\alpha'_t}{\beta'_t}, \quad \omega_t = \frac{\alpha_{\tau_t}}{\alpha'_t} = \frac{\beta_{\tau_t}}{\beta'_t}, \quad \forall t \in (0, 1) \tag{2}\] <p>under the boundary conditions</p> \[\omega_0 = \omega_1 = 1, \quad \tau_0 = 0, \quad \tau_1 = 1.\] <p>The solution of \((\tau_t, \omega_t)\) exists and is unique if \(\alpha'_t/\beta'_t \geq 0\) and \(\alpha_t/\beta_t\) is continuous and strictly increasing for \(t \in [0,1]\).</p> </blockquote> <p>In practice, the equation regarding \(\tau_t\) can be solved with a <a href="https://github.com/lqiang67/rectified-flow/blob/main/rectified_flow/flow_components/interpolation_convertor.py">simple binary search</a>. In some simple cases, the solution can be derived analytically.</p> <p>The figure below illustrates the \(\tau\) and \(\phi\) transformations that convert DDIM to spherical interpolation, and straight interpolation to spherical. Note that when converting DDIM to spherical interpolation, the only difference is in the time scaling—\(\omega_t\) remains constant at \(1\).</p> <div class="l-body-outset"> <figure id="figure-1"> <div style="display: flex;"> <iframe src="/assets/plotly/interp_tau_ddim_spherical.html" frameborder="0" scrolling="no" height="430px" width="49%"></iframe> <iframe src="/assets/plotly/interp_tau_straight_spherical.html" frameborder="0" scrolling="no" height="430px" width="49%"></iframe> </div> <figcaption> <a href="#figure-1">Figure 1</a>. The figure illustrates the \(\tau\) and \(\phi\) transformations that convert DDIM to spherical interpolation(left), and straight interpolation to spherical(right). Note that when converting DDIM to spherical interpolation, the only difference is in the time scaling—\(\omega_t\) remains constant at \(1\). </figcaption> </figure> </div> <p>Combining Proposition 1 with Theorem 1, we have:</p> <blockquote class="definition"> <p><strong>Proposition 2</strong>. Assume \(\{X_t\}\) and \(\{X'_t\}\) are two <strong>affine interpolations</strong>:</p> <ul> <li>Their respective rectified flows \(\{Z_t\}\) and \(\{Z'_t\}\) satisfy:</li> </ul> \[Z'_t = \omega_t^{-1} Z_{\tau_t}, \quad \forall t \in [0, 1].\] <ul> <li>Their rectified couplings are equivalent:</li> </ul> \[(Z_0, Z_1) = (Z'_0, Z'_1).\] <ul> <li>Their rectified flow velocity fields \(v_t\) and \(v'_t\) satisfy:</li> </ul> \[v'_t(x) = \frac{1}{\omega_t} \left( \dot{\tau}_t v_{\tau_t}(\omega_t x) - \dot{\omega}_t x \right). \tag{3}\] </blockquote> <blockquote class="example"> <p><strong>Example 1.</strong> Converting <strong>straight</strong> interpolation into <strong>affine</strong> ones.</p> <p>Consider the straight interpolation \(X_t=tX_1 + (1-t)X_0\) with \(\alpha_t=t\) and \(\beta_t=1-t\). We seek to transform it into another affine interpolation \(X'_t = \alpha'_t X_1 + \beta'_t X_0.\) Solving the equations</p> \[\omega_t = \frac{\tau_t}{\alpha'_t} = \frac{1-\tau_t}{\beta'_t}\] <p>yields</p> \[\tau_t = \frac{\alpha'_t}{\alpha'_t + \beta_t'}, \quad \omega_t = \frac{1}{\alpha_t' + \beta_t'}.\] <p>Their rectified flow velocity fields \(v_t\) and \(v'_t\) satisfy:</p> \[v'_t(x) = \frac{\dot{\alpha}'_t \beta'_t - \alpha'_t \dot{\beta}'_t}{\alpha'_t + \beta'_t} v_{\tau_t}(\omega_t x) \;+\; \frac{\dot{\alpha}'_t + \dot{\beta}'_t}{\alpha'_t + \beta'_t} x.\] </blockquote> <div class="l-body-outset"> <figure id="figure-2"> <iframe src="/assets/plotly/interp_convert_200step.html" frameborder="0" scrolling="no" height="630px" width="100%"> </iframe> <figcaption> <a href="#figure-2">Figure 2</a>. Starting from a pretrained straight rectified flow, we convert it into a spherical rf and then apply Euler sampling to both. Although the two rfs follow entirely different trajectories, they both converge to the same endpoint \(Z_1\), resulting in the same rectified coupling. </figcaption> </figure> </div> <div class="l-body-outset"> <figure id="figure-3"> <iframe src="/assets/plotly/interp_convert_10step.html" frameborder="0" scrolling="no" height="630px" width="100%"> </iframe> <figcaption> <a href="#figure-3">Figure 3</a>. As the number of sampling steps decreases to as few as \(10\), the endpoints \(Z_1\) and \(Z_1'\) begin to diverge, and the differences between them become more pronounced with fewer steps. Although different affine interpolation schemes yield the same rectified coupling \((Z_0, Z_1)\) in theory, their trajectories \(\{Z_t\}\) differ in practice. When solving ODEs numerically, discretization errors accumulate along the trajectory. Straighter trajectories are generally preferable because they reduce these errors and improve the accuracy of the final results. </figcaption> </figure> </div> <p>Thanks to the transformation relationships described above, it is possible to change the interpolation scheme of a pretrained model without retraining. This approach allows one to select a scheme that produces straighter trajectories \(\{Z_t\}\), thus improving the sampling performance.</p> <h2 id="implications-on-loss-functions">Implications on Loss Functions</h2> <p>Assume that we have trained a paramtric model \(v_t(x;\theta)\) for the RF velocity field \(v_t(x)\) under an affine interpolation. Using the formulas from the previous section, we can convert it to a model \(v'_t(x, \theta)\) for \(v'_t(x)\) corresponding to a different interpolation scheme at the post-training stage.</p> <p>This raises the question of what properties the converted model \(\hat{v}'_t\) may have compared to the models trained directly on the same interpolation, and whether it suffers from performance degradation due to the conversion.</p> <p>It turns out that using different affine interpolation schemes during training is equivalent to applying <strong>different time-weighting</strong> in the loss function, as well as an affine transform on the parametric model. Unless \(\omega_t\) and \(\tau_t\) are highly singular, the conversion does not necessarily degrade performance.</p> <p>Specifically, assume we have trained a parametric model \(v_t(x; \theta)\) to approximate the RF velocity \(v_t\) of interpolation \(X_t = \alpha_t X_1 + \beta_t X_0\), using the mean square loss:</p> \[\mathcal L(\theta) = \int_0^1 \mathbb E\left[ \eta_t \left \| \dot X_t - v_t(X_t;\theta)\right\|^2 \right] \mathrm dt \tag{4}\] <p>After training, we may convert the obtained model \(v_t(x; \theta)\) to an approximation of \(v'_t\) of a different interpolation \(X'_t = \alpha_t' X_1 + \beta_t' X_0\) via:</p> \[v'_t(x; \theta) = \frac{\dot{\tau}_t}{\omega_t} v_{\tau_t}(\omega_t x; \theta) - \frac{\dot{\omega}_t}{\omega_t} x,\] <p>On the other hand, if we train \(v'_t(x; \theta)\) directly to approximate \(v'_t\) of interpolation \(X'_t = \alpha'_t X_1 + \beta'_t X_0\), the loss function is:</p> \[\mathcal L'(\theta) = \int_0^1 \mathbb{E} \left[ \eta'_t \left\| \dot{X}'_t - v'_t(X'_t; \theta) \right\|^2 \right] \mathrm dt \tag{5}\] <p>By matching the loss \((4)\) and \((5)\), derivations show that these two training schemes are identical, except for the following time-weighting and reparametrization relationship:</p> \[\eta'_t = \frac{\omega_t^2}{\dot{\tau}_t} \eta_{\tau_t}, \quad v'_t(x; \theta) = \frac{\dot{\tau}_t}{\omega_t} v_{\tau_t}(\omega_t x; \theta) - \frac{\dot{\omega}_t}{\omega_t} x. \tag{6}\] <p>In other words, <strong>training with different interpolation schemes simply only introduces different training time weights and model parameterizations.</strong></p> <blockquote class="example"> <p><strong>Example 2. Loss from Straight to Affine</strong><br/> Consider the straight interpolation \(X_t = t X_1 + (1 - t) X_0\) with \(\alpha_t = t\) and \(\beta_t = 1 - t\), alongside another affine interpolation \(X_t' = \alpha_t' X_1 + \beta_t' X_0.\)</p> <p>Suppose we have trained the \(v_t\) for \(X_t\) with a time weight \(\eta_t\), then \(v_t'\) converted from \(v_t\) is equivalent to the RF trained with the parametrization in \((6)\), and another time weight:</p> \[\eta_t' = \frac{\omega_t^2}{\tau_t'} \eta_{\tau_t} = \frac{1}{\dot{\alpha}_t' \beta_t' - \alpha_t' \dot{\beta}_t'} \eta_{\tau_t},\] <p>Here, we substitute the relationships derived in Example 1 into \((6)\).</p> </blockquote> <h3 id="straight-vs-spherical-same-train-time-weight">Straight vs Spherical: Same Train Time Weight</h3> <blockquote class="example"> <p><strong>Example 3. Losses for Straight vs. Spherical Interpolation</strong></p> <p>Following Example 2, an interesting case is when \(\dot \alpha_t' \beta_t' - \alpha_t \beta_t' = \text{const},\) with which we have \(\eta_t' \propto \eta_{\tau_t}\). Moreover, if $\eta_t = 1$ is uniform, then $\eta_t’$ is also uniform, meaning that the two interpolations share the same loss function.</p> <p>This happens to the spherical interpolation \(X'_t = \sin\left(\frac{\pi t}{2}\right)X_1 + \cos\left(\frac{\pi t}{2}\right)X_0,\) for which we have \(\dot \alpha_t' \beta_t' - \alpha_t \beta_t' = \frac{\pi}{2}\) and hence</p> \[\eta'_t = \frac{2}{\pi} \eta_{\tau_t}, \quad \tau_t = \frac{\tan\left(\frac{\pi }{2} t \right)}{\tan\left(\frac{\pi }{2}t\right)+1}.\] <p>In this case, training \(v_t\) with the straight interpolation using a uniform weight \(\eta_t = 1\) is equivalent to training \(v'_t\) with the spherical interpolation, also with a uniform weight \(\eta'_t = 2 /\pi\). The sole difference is a reparameterization of the model:</p> \[v'_t(x, \theta) = \frac{\pi \omega_t}{2} \left( v_{\tau_t}(\omega_t x; \theta) + \left( \cos\left(\frac{\pi t}{2}\right) - \sin\left(\frac{\pi t}{2}\right) \right) x \right),\] <p>where \(\omega_t = (\sin(\frac{\pi t}{2}) + \cos(\frac{\pi t}{2}))^{-1}\) is bounded within \([1/\sqrt{2}, 1]\). This reparameterization does not significantly influence performance. As we’ll see in practice, choosing between straight or spherical interpolation makes <strong>little difference</strong> in training outcomes.</p> </blockquote> <div class="l-body-outset"> <figure id="figure-4"> <iframe src="/assets/plotly/interp_convert_double_rf.html" frameborder="0" scrolling="no" height="630px" width="100%"> </iframe> <figcaption> <a href="#figure-4">Figure 4</a>. Comparing two rf models, one trained with straight interpolation and another with spherical interpolation, we then convert the straight rf into the spherical one. As seen in Example 3, the two trajectories are nearly identical, differing slightly at the end due to accumulated numerical errors. </figcaption> </figure> </div> <div class="l-body-outset"> <figure id="figure-5"> <iframe src="/assets/plotly/interp_match_time_weight.html" frameborder="0" scrolling="no" height="630px" width="100%"> </iframe> <figcaption> <a href="#figure-5">Figure 5</a>. Here we reparameterize the straight RF into \(v'_t\) and train it using spherical interpolation. Under these matched conditions (both weighting and parameterization), the resulting trajectories align almost perfectly. </figcaption> </figure> </div>]]></content><author><name>Runlong Liao</name></author><category term="tutorial"/><summary type="html"><![CDATA[Affine Interpolations Result in Equivalent Rectified Flows]]></summary></entry><entry><title type="html">From Flow to Diffusion: Langevin is a Guardrail</title><link href="https://rectifiedflow.github.io/blog/2024/samplers/" rel="alternate" type="text/html" title="From Flow to Diffusion: Langevin is a Guardrail"/><published>2024-12-10T10:00:00+00:00</published><updated>2024-12-10T10:00:00+00:00</updated><id>https://rectifiedflow.github.io/blog/2024/samplers</id><content type="html" xml:base="https://rectifiedflow.github.io/blog/2024/samplers/"><![CDATA[ <h2 id="overview">Overview</h2> <p>Rectified flow yields an ordinary differential equation (ODE), also known as a flow model, of the form \(\mathrm d Z_t = v_t(Z_t)\mathrm d t\), which generates the data \(Z_1\) starting from an initial noise \(Z_0\). This approach offers a simplification compared to diffusion models, such as DDPM and score-based models, which rely on a stochastic differential equation (SDE) to generate data from noise.</p> <p>However, the boundary between flow and diffusion models has been known to be blurry since the work of DDIM and probability-flow ODEs, which show that it is possible to convert between SDEs and ODEs during the post-training phase, without requiring re-training of the model. Historically, SDE-based models were introduced first, followed by the derivation of simpler ODE-based counterparts. Now taking the ODE models, it is also possible to convert an ODE back to get SDE models. Several questions arises:</p> <ol> <li> <p>Why and how is it possible to convert between SDEs and ODEs?</p> </li> <li> <p>Why add diffusion noise to an ODE, and what are the pros and cons?</p> </li> </ol> <p>We will explore these questions in this blog. For a more detailed discussion, see Chapter 5 of the <a href="https://github.com/lqiang67/rectified-flow/tree/main/pdf">Rectified Flow Lecture Notes</a>. Related works include DDIM, score-based SDEs, EDM.</p> <h2 id="stochastic-samplers--rf--langevin">Stochastic Samplers = RF + Langevin</h2> <p>Given a coupling \((X_0, X_1)\) of noise and data points, rectified flow defines an interpolation process, such as \(X_t = t X_1 + (1 - t) X_0\), and “rectifies” or “causalizes” it to yield an ODE model \(\mathrm{d} Z_t = v_t(Z_t) \, \mathrm{d} t\) initialized from \(Z_0 = X_0.\) The velocity field is given by \(v_t(z) = \mathbb{E}[\dot{X}_t \mid X_t = z],\) which is estimated by minimizing the loss \(\mathbb{E}_{t, X_0, X_1} \left[ \left\| \dot{X}_t - v_t(X_t) \right\|^2 \right].\)</p> <p>The idea is that, by the construction of the velocity field \(v_t\), the distribution of \(Z_t\) on the ODE trajectory matches the distribution of \(X_t\) on the interpolation path at each time \(t\). As a result, the final output \(Z_1\) of the ODE follows the same distribution as \(X_1\), the target data distribution. This follows an inductive principle: if the distributions of \(X_t\) and \(Z_t\) match up to a given time, the construction of \(v_t\) ensures they will continue to match at the next (infinitesimal) step. By being “scheduled to do the right thing at the right time,” the process guarantees the correct final result.</p> <p>An obvious problem of this is that, in practice, errors can accumulate over time as we solve the ODE \(\mathrm{d} Z_t = v_t(Z_t) \mathrm{d} t\). These errors arise from model approximations and numerical discretization, causing drift between the estimated distribution and the true distribution. The issue can compound: if the estimated trajectory \(\hat{Z}_t\) deviates significantly from the distribution of \(X_t\), the update direction \(v_t(\hat{Z}_t)\) becomes less accurate. This happens because fewer data points are sampled in low-probability regions during training, where model inaccuracies are more pronounced.</p> <p>To address this problem, we may introduce a feedback mechanism to correct the error. One such approach is to use Langevin dynamics.</p> <p>Let \(\rho_t\) be the density function of \(X_t\), representing the true distribution that we aim to follow at time \(t\). At each time step \(t\), we can in principle apply a short segment of Langevin dynamics to adjust the trajectory’s distribution toward \(\rho_t\):</p> \[\mathrm{d} Z_{t, \tau} = \sigma_t^2 \nabla \log \rho_t(Z_{t, \tau}) \, \mathrm{d} \tau + \sqrt{2} \, \sigma_t \, \mathrm{d} W_\tau, \quad \tau \geq 0,\] <p>where \(\tau\) is a new time scale introduced for the Langevin dynamics, \(\sigma_t\) controls the noise level, and \(\nabla \log \rho_t\) adjusts the drift to steer the distribution toward high-probability regions of \(\rho_t\). It is well known that Langevin dynamics converge to the target distribution as \(\tau \to \infty\).</p> <p>Fully simulating Langevin dynamics would require a double-loop algorithm, where the system must be simulated to equilibrium (\(\tau\to\infty\)) at each time \(t\) before moving to the next time point.</p> <p>In rectified flow, however, the trajectory is already close to \(\rho_t\) at each time step \(t\). Therefore, a single step of Langevin dynamics can be sufficient to reduce the drift. This allows us to directly integrate Langevin corrections into the rectified flow updates, yielding a combined stochastic differential equation (SDE):</p> \[\mathrm{d}\tilde{Z}_t = \underbrace{v_t(\tilde{Z}_t) \mathrm{d} t}_{\text{Rectified Flow}} + \underbrace{\sigma_t^2 \nabla \log \rho_t(\tilde{Z}_t) \mathrm{d} t + \sqrt{2} \sigma_t \mathrm{d}W_t}_{\text{Langevin Dynamics}}, \quad \tilde{Z}_0 = Z_0.\] <p>This combined SDE achieves two key objectives:</p> <ol> <li> <p>The <strong>rectified flow</strong> drives the generative process forward as intended.</p> </li> <li> <p>The <strong>Langevin component</strong> acts as a negative feedback loop, correcting distributional drift without bias when \(\tilde{Z}_t\) and \(\rho_t\) are well aligned.</p> </li> </ol> <p>When the simulation is accurate, Langevin dynamics naturally remain in equilibrium, avoiding unnecessary changes to the distribution. However, if deviations occur, this mechanism guides the estimate back on track, enhancing the robustness of the inference process.</p> <p>The figure below illustrates the score function \(\nabla \log \rho_t\) along the SDE trajectories. We can see that \(\nabla \log \rho_t\) points toward high-density regions, nad hence can guid trajectories back to areas of higher probability whenever deviations occur.</p> <div class="l-body"> <img src="/assets/img/score_function_on_sde_traj.png" alt="cross" style="max-width:70%;"/> </div> <p>The figure below compares the results of two sampling methods. On the left, the Euler sampler is applied to an insufficiently trained $v_t$ (due to early stopping), resulting in a significant presence of outliers. On the right, the stochastic sampler is used, which effectively suppresses the outliers through the feedback mechanism introduced by the score functions.</p> <div class="l-body"> <img src="/assets/img/euler_sde_compare.png" alt="cross" style="max-width:100%;"/> </div> <h2 id="sdes-with-closed-form-score-functions">SDEs with Closed Form Score Functions</h2> <p>In general, it may be necessary to estimate the score function \(\nabla \log \rho_t\) in addition to the RF velocity \(v_t\). However, in certain special cases, the score function can be estimated using \(v_t\), thereby eliminating the need to retrain an additional model. This approach enables a training-free conversion between ODEs and SDEs.</p> <p>Specifically, if the rectified flow is induced by an affine interpolation \(X_t = \alpha_t X_1 + \beta_t X_0\), where \(X_0\) and \(X_1\) are independent (i.e., \(X_0 \perp\!\!\!\perp X_1\)) and \(X_0\) follows a standard Gaussian distribution, then by Tweedie’s formula, we have</p> \[\nabla \log \rho_t(x) = -\frac{1}{\beta_t} \mathbb{E}[X_0 \mid X_t = x].\] <p>On the other hand, the RF velocity is given by</p> \[v_t(x) = \mathbb{E}[\dot{X}_t \mid X_t = x] = \mathbb{E}[\dot{\alpha}_t X_1 + \dot{\beta}_t X_0 \mid X_t = x],\] <p>where \(X_t = \alpha_t X_1 + \beta_t X_0\).</p> <p>Using this, we can express \(\mathbb{E}[X_0 \mid X_t = x]\) in terms of \(v_t(x)\) and obtain</p> \[\nabla \log \rho_t(x) = \frac{1}{\lambda_t \beta_t} \left( \alpha_t v_t(x) - \dot{\alpha}_t x \right),\] <p>where \(\lambda_t = \dot{\alpha}_t \beta_t - \alpha_t \dot{\beta}_t\).</p> <p>As a result, the SDE takes the form</p> \[\mathrm d Z_t = v_t(Z_t)\mathrm d t + \gamma (\alpha_t v_t (x) - \dot \alpha_t x) \mathrm{d} t + \sqrt{2 \lambda_t \beta_t \gamma_t} \mathrm{d} W_t,\] <p>where we set \(\sigma_t^2 = \lambda_t \beta_t \gamma_t\).</p> <p>This formulation recovers both the SDE of DDPM and the score-based SDEs when \(\gamma_t = 1 / \alpha_t\) and \(\alpha^2_t + \beta_t^2 = 1\), yielding</p> \[\mathrm{d} Z_t=2 v_t(Z_t) \, \mathrm{d} t - \frac{\dot{\alpha}_t}{\alpha_t} Z_t \, \mathrm{d} t + \sqrt{2 \frac{\dot \alpha_t}{\alpha_t}} \mathrm{d} W_t.\]]]></content><author><name>Xixi Hu</name></author><category term="tutorial"/><summary type="html"><![CDATA[Deriving stochastic samplers from flow and why it helps]]></summary></entry><entry><title type="html">Rectified Flow: An Introduction</title><link href="https://rectifiedflow.github.io/blog/2024/intro/" rel="alternate" type="text/html" title="Rectified Flow: An Introduction"/><published>2024-12-06T10:00:00+00:00</published><updated>2024-12-06T10:00:00+00:00</updated><id>https://rectifiedflow.github.io/blog/2024/intro</id><content type="html" xml:base="https://rectifiedflow.github.io/blog/2024/intro/"><![CDATA[ <h2 id="overview">Overview</h2> <p>This blog provides a brief introduction to rectified flow, based on Chapter 1 of these <a href="https://github.com/lqiang67/rectified-flow/tree/main/pdf">lecture notes</a>. For more introduction, please refer to the original papers<d-cite key="liu2022flow"></d-cite>, <d-cite key="liu2022rectified"></d-cite> and these <a href="https://www.cs.utexas.edu/~lqiang/rectflow/html/intro.html">blogs</a>.</p> <h2 id="odes">ODEs</h2> <p>Generative modeling can be formulated as finding a computational procedure that transforms a noise distribution, denoted by \(\pi_0\), into an unknown data distribution \(\pi_1\) observed through data. In flow models, this procedure is represented by an ordinary differential equation (ODE):</p> \[\dot{Z}_t = v_t(Z_t), \quad \forall t \in [0,1], \quad \text{starting from } Z_0 \sim \pi_0, \tag{1}\] <p>where \(\dot{Z}_t = \mathrm dZ_t / \mathrm dt\) denotes the time derivative, and the velocity field \(v_t(x) = v(x, t)\) is a learnable function to be estimated to ensure that \(Z_1\) follows the target distribution \(\pi_1\) when starting from \(Z_0 \sim \pi_0\). In this case, we say that the stochastic process \(Z = \{Z_t\}\) provides an (ODE) transport from \(\pi_0\) to \(\pi_1\).</p> <p>It is important to note that, in all but trivial cases, there exist <em>infinitely many</em> ODE transports from \(\pi_0\) to \(\pi_1\), provided that at least one such process exists. Thus, it is essential to be clear about which types of ODEs we should prefer.</p> <p>One option is to favor ODEs that are easy to solve at inference time. In practice, the ODEs are approximated using numerical methods, which typically construct piecewise linear approximations of the ODE trajectories. For instance, a common choice is Euler’s method:</p> \[\hat{Z}_{t+\epsilon} = \hat{Z}_t + \epsilon v_t(\hat{Z}_t), \quad \forall t \in \{0, \epsilon, 2\epsilon, \dots, 1\}, \tag{2}\] <p>where \(\epsilon &gt; 0\) is a step size. Varying the step size \(\epsilon\) introduces a trade-off between accuracy and computational cost: smaller \(\epsilon\) yields high accuracy but incurs a larger number of calculation steps. Therefore, we should seek ODEs that can be approximated accurately even with large step sizes.</p> <div class="l-body"> <figure id="figure-1"> <iframe src="/assets/plotly/intro_euler_approximation_with_arrows.html" frameborder="0" scrolling="no" height="480px" width="100%"> </iframe> <figcaption> <a href="#figure-1">Figure 1</a>. Comparing the true continuous ODE trajectory with its piecewise linear approximation obtained via Euler's method, showing the error introduced by discretization. </figcaption> </figure> </div> <p>The ideal scenario arises when the ODE follows straight-line trajectories, in which case Euler approximation yields zero discretization error regardless of the choice of step sizes. In such cases, the ODE, up to time reparameterization, should satisfy:</p> \[Z_t = t Z_1 + (1 - t) Z_0, \quad \implies \quad \dot{Z}_t = Z_1 - Z_0.\] <p>These ODEs, known as straight transports, enable fast generative models that can be simulated in a single step. We refer to the resulting pair \((Z_0, Z_1)\) as a straight coupling of \(\pi_0\) and \(\pi_1\). In practice, perfect straightness may not be achievable, but a goal we can aim for is to make the ODE trajectories as straight as possible to maximize computational efficiency.</p> <h2 id="rectified-flow">Rectified Flow</h2> <p>To construct a flow transporting \(\pi_0\) to \(\pi_1\), let us assume that we are given an arbitrary coupling \((X_0, X_1)\) of \(\pi_0\) and \(\pi_1\), from which we can obtain empirical draws. This can simply be the independent coupling with law \(\pi_0 \times \pi_1\), as is common in practice when we have access to independent samples from \(\pi_0\) and \(\pi_1\). The idea is that we are going to take \((X_0, X_1)\) and convert it to a better coupling generated by an ODE model, and optionally, we can go further to iteratively repeat this process to further enhance desired properties, such as straightness.</p> <p>Rectified flow works in the following ways:</p> <ul> <li> <p><strong>Build Interpolation:</strong></p> <p>We build an interpolation process \(\{X_t\} = \{X_t : t \in [0, 1]\}\) that smoothly interpolates between \(X_0\) and \(X_1\). Given the perference on straight trajectories, there seems no immediate reason to not use the canonical straight-line interpolation:</p> \[X_t = t X_1 + (1 - t) X_0.\] <p>Here the interpolation \(\{X_t\}\) is a stochastic process generated in an <strong>“anchor-and-bridge”</strong> way: we first sample the endpoints \(X_0\) and \(X_1\) and then sample the intermediate trajectory connecting them. Such processes are also known as bridge processes, where the intermediate values of \(X_t\) smoothly “bridge” the distribution between \(X_0\) and \(X_1\).</p> </li> </ul> <div class="l-body"> <figure id="figure-2"> <iframe src="/assets/plotly/intro_straight_interp.html" frameborder="0" scrolling="no" height="630px" width="100%"> </iframe> <figcaption> <a href="#figure-2">Figure 2</a>. The straight interpolation between \( X_0 \) and \( X_1 \). However, this interpolation process is not "simulatable" because at intermediate crossing points it is unclear in which direction to proceed. </figcaption> </figure> </div> <ul> <li> <p><strong>Marginal Matching:</strong></p> <p>By construction, the marginal distributions of \(X_0\) and \(X_1\) match the target distributions \(\pi_0\) and \(\pi_1\) through the interpolation process \(\{X_t\}\). However, \(\{X_t\}\) is not a causal ODE process like \(\dot{Z}_t = v_t(Z_t)\), which generate the output \(Z_1\) by evolving forward in time from \(Z_0\). Instead, generating \(X_t\) requires knowledge of both \(X_0\) and \(X_1\), rather than evolving solely from \(X_0\) as \(t\) increases.</p> <p>This issue can be resolved if we can convert \(\{X_t\}\) somehow into a causal ODE process while preserving the marginal distributions of \(X_t\) at each time \(t\). Note that since we only care about the output \(X_1\), we only need to match the marginal distributions. There is no need to match the trajectory-wise joint distribution.</p> </li> </ul> <p>Perhaps surprisingly, marginal matching can be achieved by simply training the velocity field \(v_t\) of the ODE model \(\dot{Z}_t = v_t(Z_t)\) to match the slope \(\dot{X}_t\) of the interpolation process via:</p> \[\min_v \int_0^1 \mathbb{E} \left[ \left\| \dot{X}_t - v_t(X_t) \right\|^2 \right] \mathrm dt. \tag{3}\] <p>The theoretical minimum is achieved by:</p> \[v_t^*(x) = \mathbb{E} \left[ \dot{X}_t \mid X_t = x \right],\] <p>which is the condition expectation of the slope \(\dot{X}_t\) for all the interpolation trajectories passing through a given point \(X_t = x\).</p> <blockquote class="theorem"> <p><strong>Expectation Notation.</strong> Recall that a stochastic process \(X_t = X(t, \omega)\) is a measurable function of time \(t\) and a random seed \(\omega\) (with, say, distribution \(\mathbb{P}\)). In the case above, the random seed \(\omega = (X_0, X_1)\) represents the endpoints. The slope is given by \(\dot{X}_t = \partial_t X(t, \omega)\), which is also a function of the same random seed. The expectation in the loss, written in full, is \(\mathbb{E}_{\omega \sim \mathbb{P}} \left[ \left\| \partial_t X(t, \omega) - v_t(X(t, \omega)) \right\|^2 \right].\)</p> <p>In writing, we often omit the random seed. Whenever we take the expectation, it averages out all random sources inside the brackets except for those explicitly included in the conditioning.</p> </blockquote> <p>With the straight interpolation \(X_t = t X_1+(1-t)X_0\), we have \(\dot{X}_t = X_1 - X_0\) by taking the derivative of \(X_t\) with respect to \(t\). It yields:</p> \[\min_v \int_0^1 \mathbb{E} \left[ \| \dot{X}_t - v_t(X_t) \|^2 \right] \mathrm dt, \quad X_t = t X_1 + (1 - t) X_0.\] <blockquote class="definition"> <p><strong>Rectified Flow.</strong> For any time-differential stochastic process \(\{X_t\} = \{X_t : t \in [0, 1]\}\), we call the ODE process:</p> \[\dot{Z}_t = v_t^*(Z_t) \quad \text{with} \quad v_t^*(x) = \mathbb{E} \left[ \dot{X}_t \mid X_t = x \right], \quad Z_0 = X_0\] <p>the <strong>rectified flow</strong> induced by \(\{X_t\}\). We denote it as:</p> \[\{Z_t\} = \texttt{Rectify}(\{X_t\}).\] </blockquote> <p>In practice, the optimization in (3) can be efficiently solved even for large AI models when \(v\) is parameterized as modern deep neural nets. This is achieved by leveraging off-the-shelf optimizers with stochastic gradients, computed by drawing pairs \((X_0, X_1)\) from data, sampling \(t\) uniformly in \([0, 1]\), and then computing the corresponding \((X_t, \dot{X}_t)\) using the interpolation formula.</p> <div class="l-body"> <figure id="figure-3"> <iframe src="/assets/plotly/intro_1rf.html" frameborder="0" scrolling="no" height="630px" width="100%"> </iframe> <figcaption> <a href="#figure-3">Figure 3</a>. In the interpolation process \(\{X_t\}\), different trajectories can intersect, causing multiple possible values of \(\dot{X}_t\) for the same point \(X_t\). In contrast, by defining an ODE \(\dot{Z}_t = v_t^*(Z_t)\), the update direction \(\dot{Z}_t\) at each point \(Z_t\) is uniquely determined by \(Z_t\). Hence, at these intersection points where the direction is otherwise uncertain, the ODE “derandomizes” the update direction by following the conditional expectation \(\displaystyle v_t^*(X_t) = \mathbb{E}[\dot{X}_t \mid X_t]\). </figcaption> </figure> </div> <p>What makes rectified flow \(\{Z_t\}\) useful is that it preserves the marginal distributions of \(\{X_t\}\) at each point while resulting in a “better” coupling \((Z_0, Z_1)\) in terms of optimal transport:</p> <ol> <li> <p><strong>Marginal Preservation</strong></p> <p>The \(\{X_t\}\) and its rectified flow \(\{Z_t\}\) share the same marginal distributions at each time \(t \in [0, 1]\), that is:</p> \[\text{Law}(Z_t) = \text{Law}(X_t), \quad \forall t \in [0, 1],\] <p>where \(\text{Law}(X_t)\) denotes the probability distribution (or law) of random variable \(X_t\).</p> <div class="l-body"> <img src="/assets/img/flow_in_out.png" alt="cross" style="max-width:100%;"/> </div> </li> <li> <p><strong>Transport Cost</strong></p> <p>The start-end pairs \((Z_0, Z_1)\) from the rectified flow \(\{Z_t\}\) guarantee to yield no larger transport cost than \((X_0, X_1)\), simultaneously for all convex cost functions \(c\):</p> \[\mathbb{E} \left[ c(Z_1 - Z_0) \right] \leq \mathbb{E} \left[ c(X_1 - X_0) \right], \quad \forall \text{convex } c : \mathbb{R}^d \to \mathbb{R}.\] </li> </ol> <h2 id="reflow">Reflow</h2> <p>While rectified flows tend to favor straight trajectories, they are not perfectly straight. As shown in Figure, the flow makes turns at intersection points of the interpolation trajectories \(\{X_t\}\). How can we further improve the flow to achieve straighter trajectories and hence speed up inference?</p> <p>A key insight is that the start-end pairs \((Z_0, Z_1)\) generated by rectified flow, called the <strong>rectified coupling</strong> of \((X_0, X_1)\), form a better and “straighter” coupling compared to \((X_0, X_1)\). This is because if we connect \(Z_0\) and \(Z_1\) with a new straight-line interpolation, it would yield fewer intersection points. Hence, training a new rectified flow based on this interpolation would result in straighter trajectories, leading to faster inference.</p> <p>Formally, we apply the \(\texttt{Rectify}(·)\) procedure recursively, yielding a sequence of rectified flows starting from \((Z_0^0, X_1^0) = (X_0, X_1)\):</p> \[\texttt{Reflow:} \quad \quad \{Z_t^{k+1}\} = \texttt{Rectify}(\texttt{Interp}(Z_0^k, Z_1^k)),\] <p>where \(\text{Interp}(Z_0^k, Z_1^k)\) denotes an interpolation process given \((Z_0^k, Z_1^k)\) as the endpoints. We call \(\{Z_t^k\}\) the \(k\)-th rectified flow, or simply the <strong>\(k\)-rectified flow</strong>, induced from \((X_0, X_1)\).</p> <p>This reflow procedure is proved to “straighten” the paths of rectified flows in the following sense: Define the following measure of straightness of \(\{Z_t\}\):</p> \[S(\{Z_t\}) = \int_0^1 \mathbb{E} \left[ \|Z_1 - Z_0 - \dot{Z}_t\|^2 \right] \mathrm dt,\] <p>where \(S(\{Z_t\})\) is a measure of the straightness of \(\{Z_t\}\), with \(S(\{Z_t\}) = 0\) corresponding to straight paths. Then it can be found in paper<d-cite key="liu2022flow"></d-cite> that</p> \[\mathbb{E}_{k \sim \text{Unif}(\{1, \dots, K\})} \left[S(\{Z_t^k\})\right] = \mathcal{O}(1 / K),\] <p>which suggests that the average of \(S(\{Z_t^k\})\) in the first \(K\) steps decay with an \(\mathcal{O}(1 / K)\) rate.</p> <p>Hence, we would obtain perfectly straight-line dynamics in the limit of \(k \to +\infty\). Note that reflow can begin from any coupling \((X_0, X_1)\), so it provides a general procedure for straightening and thus speeding up any given dynamics while preserving the marginals.</p> <div class="l-body"> <figure id="figure-4"> <iframe src="/assets/plotly/intro_2rf.html" frameborder="0" scrolling="no" height="630px" width="100%"> </iframe> <figcaption> <a href="#figure-4">Figure 4</a>. This figure shows the a single-step result of applying reflow to the 1-rf learned by an MLP. Most particles are effectively transported. </figcaption> </figure> </div>]]></content><author><name>Runlong Liao</name></author><category term="tutorial"/><summary type="html"><![CDATA[A First Introduction to Rectified Flow]]></summary></entry></feed>