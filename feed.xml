<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://rectifiedflow.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://rectifiedflow.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-12-13T00:29:13+00:00</updated><id>https://rectifiedflow.github.io/feed.xml</id><title type="html">blank</title><subtitle>Everything should be made as simple as possible, but not simpler. </subtitle><entry><title type="html">All Flows are One Flow</title><link href="https://rectifiedflow.github.io/blog/2024/interpolation/" rel="alternate" type="text/html" title="All Flows are One Flow"/><published>2024-12-10T10:00:00+00:00</published><updated>2024-12-10T10:00:00+00:00</updated><id>https://rectifiedflow.github.io/blog/2024/interpolation</id><content type="html" xml:base="https://rectifiedflow.github.io/blog/2024/interpolation/"><![CDATA[<p>The choice of the interpolation process can significantly impact inference performance and speed, and it may initially seem that this decision must be made during the pre-training phase. In this blog, however, we demonstrate that it is possible to convert between different affine interpolation schemes at inference time, without retraining the model. The <strong>transformations</strong> applied to the interpolation are <strong>exactly the same</strong> as those applied to the rectified flow. For affine interpolation schemes, this can be achieved with a simple rescaling of the time \(t\) and the input \(x\). Building on this, we will show that these interpolations yield essentially <strong>equivalent</strong> rectified flow dynamics and identical rectified couplings.</p> <p>For detailed proofs, please refer to the flow book.</p> <h2 id="point-wisely-transformable-interpolations">Point-wisely Transformable Interpolations</h2> <h3 id="tl-dr">TL; DR</h3> <p>We show that, if two processes \(\{X_t\}\) and \(\{X'_t\}\) are related pointwise by</p> \[X'_t = \phi_t(X_t),\] <p>for some differentiable and invertible maps \(\phi: (t, x) \mapsto \phi_t(x)\) and \(\tau: t \mapsto \tau_t\), then their corresponding rectified flows, \(\{Z_t\}\) and \(\{Z'_t\}\), satisfy the <strong>same</strong> relation:</p> \[Z'_t = \phi_t(Z_{\tau_t}),\] <p>provided that this relation holds at initialization, i.e., \(Z'_0 = \phi_t(Z_0)\).</p> <p>This result suggests that the rectified flows of pointwisely transformable interpolations are essentially the same, up to the same pointwise transform. Furthermore, if two interpolations \(X_t = \texttt I_t(X_0, X_1)\) and \(X'_t = \texttt I_t(X_0, X_1)\) are constructed from the same coupling \((X_0, X_1)\), then they yield that same rectified coupling \((Z_0, Z_1') = (Z_0, Z_1)\).</p> <p>Define \(\{X'_t\} = \texttt{Transform}(\{X_t\})\) as the pointwise transform above. The result suggests that \(\texttt{Rectify}(\cdot)\) is an <strong>equivariant</strong> map under these pointwise transforms:</p> \[\texttt{Rectify}(\texttt{Transform}(\{X_t\})) = \texttt{Transform}(\texttt{Rectify}(\{X_t\})).\] <h3 id="same-transform-on-interpolations-and-rectified-flows">Same Transform on Interpolations and Rectified Flows</h3> <blockquote> <p><strong>Definition 1</strong>: Two stochastic processes \(\{X_t\}\) and \(\{X'_t\}\) are said to be <strong>pointwisely transformable</strong> if</p> \[X'_t = \phi_t(X_{\tau_t}), \quad \forall t \in [0, 1],\] <p>where \(\tau: [0,1] \to [0,1]\) and \(\phi: [0,1] \times \mathbb{R}^d \to \mathbb{R}^d\) for \(t \in [0,1]\) are differentiable maps, and \(\phi_t\) is invertible for all \(t \in [0,1]\).</p> </blockquote> <p>Building upon the notion of pointwise transformability, we have:</p> <blockquote> <p><strong>Theorem 1:</strong> Assume that \(\{X_t\}\) and \(\{X'_t\}\) are pointwise transformable. Let \(\{v_t\}\) and \(\{v'_t\}\) be their respective RF velocity fields, and let $\phi$ and $t$ be the corresponding interpolation transformation maps. Then we have</p> \[v'_t(x) = \partial_t \phi_t(\phi_t^{-1}(x)) + \nabla \phi_t(\phi_t^{-1}(x))^\top v_{\tau_t}(\phi_t^{-1}(x)) \dot{\tau}_t. \tag{1}\] <p>In addition, let \(\{z_t\}\) be a trajectory of the rectified flow of \(\{X_t\}\), satisfying \(\frac{\mathrm d}{\mathrm dt} z_t = v_t(z_t).\) Then a curve \(\{z'_t\}\) satisfies \(z'_t = \phi_t(z_{\tau_t})\), \(\forall t \in [0, 1]\) if and only if it is the trajectory of the rectified flow of \(\{X'_t\}\) initialized from \(z'_0 = \phi_0(z_{\tau_0})\).</p> </blockquote> <p>Furthermore, under the additional requirement that \(\tau(0)=0\), let \(\frac{\mathrm d}{\mathrm dt}Z_t=v_t(Z_t)\) be the rectified flow of \(\{X_t\}\) (initialized with \(Z_0=X_0\) by default). Then \(Z'_t=\phi_t(Z_{\tau_t})\) is the rectified flow of \(\{X_t'\}\) with the specific initialization</p> \[\frac{\mathrm d}{\mathrm dt} Z'_t = v'_t(Z_t'), \quad \forall t \in [0,1], \;\text{and}\; Z_0' = \phi_0(Z_{\tau_0}).\] <p>This result has two implications:</p> <p><strong>Same Transform between Interpolations and Rectified Flows</strong></p> <p>Assume the same conditions as Theorem 1, with the additional assumption that \(\tau(0) = 0\). Let \(\{Z_t\}\) and \(\{Z'_t\}\) be the rectified flows of \(\{X_t\}\) and \(\{X'_t\}\), respectively. Then \(Z'_t = \phi_t(Z_{\tau_t})\) for all \(t \in [0, 1]\).</p> <p><strong>Equivalent Rectified Couplings</strong></p> <p>If \(\{X_t\}\) and \(\{X'_t\}\) are constructed from the same coupling \((X_0, X_1) = (X'_0, X'_1),\) and they satisfy the condition in Theorem 1 with \(\tau(0) = 0\) and \(\tau(1) = 1\), then their rectified flow yields the same coupling, that is, \((Z_0, Z_1) = (Z'_0, Z'_1).\)</p> <h2 id="equivalence-of-affine-interpolations">Equivalence of Affine Interpolations</h2> <p>We now consider a specific class of interpolations called <em>affine interpolations</em>, defined as \(X_t = \alpha_t X_1 + \beta_t X_0\) where \(\alpha_t\) and \(\beta_t\) satisfy the conditions \(\alpha_0 = \beta_1 = 0\) and \(\alpha_1 = \beta_0 = 1\), as well as \(\alpha_t\) is monotonically increasing and \(\beta_t\) monotonically decreasing.</p> <h3 id="straight-spherical-and-ddim-interpolation">Straight, Spherical and DDIM interpolation</h3> <p><strong>Straight Line Interpolation</strong> (<code class="language-plaintext highlighter-rouge">straight</code> or <code class="language-plaintext highlighter-rouge">lerp</code>)</p> \[\begin{aligned} \alpha_t &amp; = t, &amp; \beta_t &amp; = 1 - t \\ \dot{\alpha}_t &amp; = 1, &amp; \dot{\beta}_t &amp; = -1 \end{aligned}\] <ul> <li>This interpolation follows a straight line connecting the source and target distributions with a constant speed.</li> </ul> <p><strong>Spherical Interpolation</strong> (<code class="language-plaintext highlighter-rouge">spherical</code> or <code class="language-plaintext highlighter-rouge">slerp</code>)</p> \[\begin{aligned} \alpha_t &amp; = \sin\left(\frac{\pi}{2} t\right), &amp; \beta_t &amp; = \cos\left(\frac{\pi}{2} t\right) \\ \dot{\alpha}_t &amp; = \frac{\pi}{2} \cos\left(\frac{\pi}{2} t\right), &amp; \dot{\beta}_t &amp; = -\frac{\pi}{2} \sin\left(\frac{\pi}{2} t\right) \end{aligned}\] <ul> <li>Spherical interpolation traces a curved path rather than a straight line.</li> </ul> <p><strong>DDIM / VP ODE Interpolation</strong></p> \[\alpha_t = \exp\left(- \frac{1}{4}a(1-t)^2 - \frac{1}{2}b(1-t)\right), \quad \beta_t = \sqrt{1 - \alpha_t^2}, \quad a=19.9, b=0.1\] <ul> <li>This also yields a spherical trajectory, but with a non-uniform speed defined by \(\alpha_t\).</li> </ul> <h3 id="pointwise-transformability-between-affine-interpolations">Pointwise Transformability Between Affine Interpolations</h3> <p>We now show that <strong>all affine interpolations are pointwise transformable</strong> by appropriately scaling both the time and the input. Then, according to the two corollaries above, their rectified flows can be transformed pointwise using the same mappings as those used between the interpolations, ultimately yielding the same rectified couplings. This is also observed by other authors.</p> <blockquote> <p>Consider two affine interpolation processes of same coupling \((X_0, X_1)\):</p> \[X_t = \alpha_t X_1 + \beta_t X_0 \quad \text{and} \quad X_{t}' = \alpha_{t}' X_1 + \beta_{t}' X_0,\] <p>Then we have</p> \[X_t' = \frac{1}{\omega_t} X_{\tau_t}, \quad \forall t \in [0,1],\] <p>where \(\tau_t\) and \(\omega_t\) are found by solving:</p> \[\frac{\alpha_{\tau_t}}{\beta_{\tau_t}} = \frac{\alpha'_t}{\beta'_t}, \quad \omega_t = \frac{\alpha_{\tau_t}}{\alpha'_t} = \frac{\beta_{\tau_t}}{\beta'_t}, \quad \forall t \in (0, 1) \tag{2}\] <p>with the boundary condition:</p> \[\omega_0 = \omega_1 = 1, \quad \tau_0 = 0, \quad \tau_1 = 1.\] <p>There is one unique solution of \((\tau_t, \omega_t)\) in \((2)\) since \(\alpha'_t / \beta'_t \geq 0\) and \(\alpha_t / \beta_t\) is strictly increasing for \(t \in [0,1]\).</p> </blockquote> <p>In practice, we determine the time scaling function \(\tau_t\) in two ways. For simple cases, \(\tau_t\) can be computed analytically. For more complex scenarios, a numerical approach, such as a <a href="">simple binary search</a>, can be used to find \(\tau_t\) efficiently. Check the notebook for implementation.</p> <div class="l-page" style="display: flex;"> <iframe src="/assets/plotly/interp_tau_ddim_spherical.html" frameborder="0" scrolling="no" height="430px" width="49%"></iframe> <iframe src="/assets/plotly/interp_tau_straight_spherical.html" frameborder="0" scrolling="no" height="430px" width="49%"></iframe> </div> <p>Substituting the notion of \(\tau\) and \(\omega\) into the theorem 1, we have:</p> <blockquote> <p><strong>Theorem 2</strong>: Assume \(\{X_t\}\) and \(\{X'_t\}\) are two affine interpolations:</p> <p>1) Their respective rectified flows \(\{Z_t\}\) and \(\{Z'_t\}\) satisfy:</p> \[Z'_t = \omega_t^{-1} Z_{\tau_t}, \quad \forall t \in [0, 1].\] <p>2) Their rectified couplings are equivalent:</p> \[(Z_0, Z_1) = (Z'_0, Z'_1).\] <p>3) Their RF velocity fields \(v_t\) and \(v'_t\) satisfy:</p> \[v'_t(x) = \frac{1}{\omega_t} \left( \dot{\tau}_t v_{\tau_t}(\omega_t x) - \dot{\omega}_t x \right). \tag{3}\] </blockquote> <p>The figure below shows the conversion between the <code class="language-plaintext highlighter-rouge">straight</code> and <code class="language-plaintext highlighter-rouge">spherical</code> interpolations using a binary search method. Observe that once converted, the trajectory of the original <code class="language-plaintext highlighter-rouge">straight</code> interpolation matches perfectly with the newly derived <code class="language-plaintext highlighter-rouge">straight</code> curve, confirming that these interpolations are indeed pointwise transformable. See the flow book for explicit solution.</p> <div class="l-page"> <iframe src="/assets/plotly/interp_affine_interp_conversion.html" frameborder="0" scrolling="no" height="630px" width="100%"></iframe> </div> <h3 id="converting-pretrained-rf-velocity">Converting Pretrained RF Velocity</h3> <p>Now, let’s take a pretrained straight rectified flow and transform it into a curved trajectory. See the notebook for implementation details.</p> <div class="l-page"> <iframe src="/assets/plotly/interp_1rf_straight_to_spherical.html" frameborder="0" scrolling="no" height="630px" width="100%"></iframe> </div> <p><strong>Trajectory Considerations</strong> As the number of sampling steps increases, the trajectories for \(Z_1\) and \(Z_1'\) should converge to the same points, and the mean squared error between them should also decrease.</p> <p>However, even though different paths theoretically lead to the same rectified endpoint \(Z_1\), the intermediate trajectories \(\{Z_t\}\) they follow are not identical. In practice, when running simulations, we must discretize these trajectories, making perfect solutions unattainable. For this reason, <strong>choosing straighter trajectories is generally preferable</strong>: the straighter the path, the lower the discretization error, and the more faithful the results. Thanks to the transformation relations described above, it is possible to convert the interpolation scheme of a pretrained model without retraining, enabling the identification of a scheme that yields straighter trajectories for \(\{Z_t\}\).</p> <h2 id="implications-on-loss-functions">Implications on Loss Functions</h2> <p>Assume that we have trained a model \(\hat{v}_t\) for the RF velocity field \(v_t\) under an affine interpolation. Using the formulas from the previous section, we can convert it to a model \(\hat{v}'_t\) for \(v'_t\) corresponding to a different interpolation scheme at the post-training stage. This raises the question of what properties the converted model \(\hat{v}'_t\) may have compared to the models trained directly on the same interpolation, and whether it suffers from performance degradation due to the conversion.</p> <p>We show here that using different affine interpolation schemes during training is equivalent to applying <strong>different time-weighting</strong> in the loss function, as well as an affine transform on the parametric model. Unless \(\omega_t\) and \(\tau_t\) are highly singular, the conversion does not necessarily degrade performance.</p> <p>Specifically, assume we have trained a parametric model \(v_t(x; \theta)\) to approximate the RF velocity \(v_t\) of interpolation \(X_t = \alpha_t X_1 + \beta_t X_0\), using the mean square loss:</p> \[\mathcal L(\theta) = \int_0^1 \mathbb E\left[ \eta_t \left \| \dot X_t - v_t(X_t;\theta)\right\|^2 \right] \mathrm dt \tag{4}\] <p>After training, we may convert the obtained model \(v_t(x; \theta)\) to an approximation of \(v'_t\) of a different interpolation \(X'_t = \alpha_t X_1 + \beta_t X_0\) via:</p> \[v'_t(x; \theta) = \frac{\dot{\tau}_t}{\omega_t} v_{\tau_t}(\omega_t x; \theta) - \frac{\dot{\omega}_t}{\omega_t} x,\] <p>On the other hand, if we train \(v'_t(x; \theta)\) directly to approximate \(v'_t\) of interpolation \(X'_t = \alpha'_t X_1 + \beta'_t X_0\), the loss function is:</p> \[\mathcal L'(\theta) = \int_0^1 \mathbb{E} \left[ \eta'_t \left\| \dot{X}'_t - v'_t(X'_t; \theta) \right\|^2 \right] \mathrm dt \tag{5}\] <p>When matching the loss \((4)\) and \((5)\), we find that these two training schemes are identical, except for the following time-weighting and reparametrization relationship:</p> \[\eta'_t = \frac{\omega_t^2}{\dot{\tau}_t} \eta_{\tau_t}, \quad v'_t(x; \theta) = \frac{\dot{\tau}_t}{\omega_t} v_{\tau_t}(\omega_t x; \theta) - \frac{\dot{\omega}_t}{\omega_t} x.\] <p>In other words, <strong>training with different interpolation schemes simply only introduces different training time weights and model parameterizations.</strong></p> <h3 id="straight-vs-spherical-same-train-time-weight">Straight vs Spherical: Same Train Time Weight</h3> <p>In the case where \(X_t = tX_1 + (1-t)\) is the straight interpolation, and \(X_t'=\alpha_t'X_1 + \beta'_t X_0\) is the affine interpolation, when</p> \[\dot \alpha_t' \beta_t' - \alpha_t \beta_t' = \text{const},\] <p>we’ll have \(\text{const} \cdot \eta_t' = \eta_{\tau_t}\), meaning the training time weight scale remains the same across all time.</p> <p>For example, this holds for spherical interpolation</p> \[X'_t = \sin\left(\frac{\pi t}{2}\right) X_1 + \cos\left(\frac{\pi t}{2}\right) X_0,\] <p>where</p> \[\eta'_t = \frac{2}{\pi} \eta_{\tau_t}, \quad \tau_t = \frac{\tan\left(\frac{\pi t}{2}\right)}{\tan\left(\frac{\pi t}{2}\right)+1}.\] <p>In this case, training \(v_t\) with straight interpolation using a uniform weight \(\eta_t = 1\) is equivalent to training \(v'_t\) with spherical interpolation, <strong>also using a uniform weight</strong> \(\eta'_t = 1\), the only difference lies in the model parameterization:</p> \[v'_t(x, \theta) = \frac{\pi \omega_t}{2} \left( v_{\tau_t}(\omega_t x, \theta) + \left( \cos\left(\frac{\pi}{2} t\right) - \sin\left(\frac{\pi}{2} t\right) \right) x \right).\] <p>Given that the variable scaling factor \(\omega_t = (\sin(\frac{\pi}{2} t) + \cos(\frac{\pi}{2} t))^{-1}\) is bounded in \([1/\sqrt{2}, 1]\), this reparameterization may not significantly impact performance. Overall, the choice of using straight or spherical interpolation might have limited impact in terms of training performance.</p> <div class="l-page"> <iframe src="/assets/plotly/interp_straight_spherical_rf.html" frameborder="0" scrolling="no" height="630px" width="100%"></iframe> </div> <p>Here, we independentely trained 2 rectified flow with mlp. Note that the final couplings \((Z_0,Z_1)\) and \((Z_0',Z_1')\) are the same.</p>]]></content><author><name>Rectified Flow Group</name></author><category term="tutorial"/><summary type="html"><![CDATA[Affine Interpolations Result in Equivalent Rectified Flows]]></summary></entry><entry><title type="html">Stochastic Sampler: Langevin as Guardrail</title><link href="https://rectifiedflow.github.io/blog/2024/samplers/" rel="alternate" type="text/html" title="Stochastic Sampler: Langevin as Guardrail"/><published>2024-12-10T10:00:00+00:00</published><updated>2024-12-10T10:00:00+00:00</updated><id>https://rectifiedflow.github.io/blog/2024/samplers</id><content type="html" xml:base="https://rectifiedflow.github.io/blog/2024/samplers/"><![CDATA[<h3 id="stochastic-solvers-guardrails-for-generative-models">Stochastic Solvers: Guardrails for Generative Models</h3> <p>In this blog, we will elaborate on, given a pretrained flow model, how does a stochastic sampler (like DDPM) relate to a deterministic sampler as conducting simple Euler steps in rectified flow. In particular, we will show that one can convert any deterministic sampler to its corresponding stochastic counterparts, and vice versa. The main difference is that the stochastic sampler has an extra Langevin dynamics term, which could potentially help correct the discretization error from cumulative Euler steps. For a more comprehensive and rigorous discussion on this topic, please refer to Chapter 5 in the <a href="">Rectified Flow book</a>.</p> <p>For an introduction to rectified flow and its foundational concepts, check out our earlier post <a href="https://rectifiedflow.github.io/blog/2024/intro/">here</a><d-cite key="Liu2022FlowSA"></d-cite></p> <p>When working with generative models, particularly those using rectified flow, errors can accumulate over time as we solve the ODE $dZ_t = v_t(Z_t) dt$. These errors arise from model approximations and numerical discretization, leading to drift between the estimated distribution $\hat{Z}_t$ and the true distribution $\rho_t$. Here, $\rho_t$ represents the smooth density function of the true distribution $X_t$. This problem is exacerbated in low-density regions rarely sampled during training, where model inaccuracies are more pronounced.</p> <p>To address this, <strong>stochastic solvers</strong> can replace deterministic ODE solvers during inference. By introducing stochastic dynamics, we can dynamically correct these errors, ensuring the estimated distribution stays aligned with the true one.</p> <h4 id="langevin-dynamics-as-a-guardrail">Langevin Dynamics as a Guardrail</h4> <p>One common and promising approach is to use <strong>Langevin dynamics</strong> as a corrective mechanism. At each timestep $t$, a short segment of Langevin dynamics is applied to adjust $\hat{Z}_t$ toward $\rho_t$:</p> \[dZ_{t, \tau} = \sigma_t^2 \nabla \log \rho_t(Z_{t, \tau}) d\tau + \sqrt{2}\sigma_t dW_\tau, \quad \tau \geq 0\] <p>Here, $\sigma_t$ controls the noise level, and $\nabla \log \rho_t$ adjusts the drift toward high-probability regions of $\rho_t$. While simulating Langevin dynamics until equilibrium would align the distribution perfectly, this is often unnecessary. A single step of Langevin dynamics can sufficiently reduce drift when $\hat{Z}_t$ is already close to $\rho_t$.</p> <p>To streamline this process, Langevin corrections can be integrated directly into the rectified flow updates, resulting in a combined stochastic differential equation (SDE):</p> \[d\tilde{Z}_t = \underbrace{v_t(\tilde{Z}_t) dt}_{\text{Rectified Flow}} + \underbrace{\sigma_t^2 \nabla \log \rho_t(\tilde{Z}_t) dt + \sqrt{2} \sigma_t dW_t}_{\text{Langevin Dynamics}}, \quad \tilde{Z}_0 = Z_0\] <p>This combined SDE achieves two goals:</p> <ol> <li>The <strong>rectified flow</strong> drives the generative process forward as intended.</li> <li>The <strong>Langevin component</strong> acts as a negative feedback loop, correcting distributional drift without bias when $\tilde{Z}_t$ and $\rho_t$ are already well aligned.</li> </ol> <h4 id="why-it-works">Why It Works</h4> <p>If the simulation is accurate, Langevin dynamics naturally stay in equilibrium, meaning they won’t alter the distribution unnecessarily. But when deviations occur, this mechanism gently nudges the estimate back on track, providing robustness to the inference process.</p> <p>By incorporating stochastic solvers like these, we create a dynamic correction framework that enhances the stability and accuracy of generative models, ensuring that outputs remain high-quality and faithful to the intended distributions.</p> <p><strong>Score Function Visualization:</strong> In the next toy example, we’ll visualize the score function $\nabla \log \rho_t$. This will help you see how these small corrective forces guide the samples toward the right regions, improving upon what a purely deterministic approach can achieve.</p> <div class="l-body"> <img src="/assets/img/score_function_on_sde_traj.png" alt="cross" style="max-width:100%;"/> </div> <p>As shown here, the score function ($\nabla \log \rho_t$) points samples toward regions of higher density. This corrects the trajectories from the original predicted velocity, providing a drifting force that helps ensure samples converge to the most probable areas of the target distribution.</p> <h3 id="sdes-with-gaussian-initial-distributions">SDEs with Gaussian Initial Distributions</h3> <p>Previously, we demonstrated that for a rectified flow using interpolation $X_t = \alpha_t X_1 + \beta_t X_0$, two processes can achieve the same target distribution $\pi_1$:</p> <ul> <li> <p><strong>The ODE process:</strong></p> \[d Z_t = v_t(Z_t)dt\] </li> <li> <p><strong>The SDE process:</strong></p> \[d Z_t = v_t(Z_t)dt + \sigma_t^2 \nabla \log \rho_t(Z_t) dt + \sqrt{2} \sigma_t d W_t,\] </li> </ul> <p>The <strong>Euler method</strong> is commonly used to discretize the ODE process, yielding the following update rule:</p> \[\hat{Z}_{t + \Delta t} = \hat{Z}_t + \Delta t \cdot v(\tilde{Z}_t)\] <p>Similarly, the SDE process can be discretized. When introducing a noise level $\sigma_t$ at time $t$, the update step becomes:</p> \[\hat{Z}_{t + \Delta t} = \hat{Z}_t + \Delta t \cdot (v(\hat{Z}_t) + \frac{\sigma_t^2}{\beta_t \lambda_t} (\alpha_t v(\hat{Z}_t) - \dot{\alpha}_t \hat{Z}_t)) + \sqrt{2} \sigma_t \xi_t,\] <p>Here:</p> <ul> <li>$\lambda_t = \dot{\alpha}_t \beta_t - \alpha_t \dot{\beta}_t$</li> <li>$\xi$ is random Gaussian noise sampled from $\mathcal{N}(0, I)$.</li> </ul> <p>This update rule explicitly incorporates the Langevin dynamics term, derived in detail in Chapter 5.3 of the <a href="TBD: insert link">Rectified Flow book</a>.</p> <p>In practice, the <code class="language-plaintext highlighter-rouge">AffineInterpSolver</code> in our <a href="https://github.com/lqiang67/rectified-flow">Rectified Flow repository</a> provides an efficient way to compute the score function. This solver supports scenarios where at least two of the variables $(x_0, x_1, x_t, \dot{x}_t)$ are known, enabling the estimation of the others.</p>]]></content><author><name>Qiang Liu</name></author><category term="tutorial"/><summary type="html"><![CDATA[Connections between Deterministic and Stochastic Samplers]]></summary></entry><entry><title type="html">Rectified Flow, An Introduction</title><link href="https://rectifiedflow.github.io/blog/2024/intro/" rel="alternate" type="text/html" title="Rectified Flow, An Introduction"/><published>2024-12-06T10:00:00+00:00</published><updated>2024-12-06T10:00:00+00:00</updated><id>https://rectifiedflow.github.io/blog/2024/intro</id><content type="html" xml:base="https://rectifiedflow.github.io/blog/2024/intro/"><![CDATA[<p>This blog provides a brief introduction to the Rectified Flow idea, which serves as a mainstream algorithm for training deep generative models. For a more comprehensive and rigorous discussion on the introduction, please refer to Chapter 1 in the <a href="">Rectified Flow book</a> and the original paper<d-cite key="Liu2022FlowSA"></d-cite>.</p> <h2 id="overview">Overview</h2> <p>Generative modeling can be formulated as finding a computational procedure that transforms a noise distribution, denoted by \(\pi_0\), into the unknown data distribution \(\pi_1\). In flow models, this procedure is represented by an ordinary differential equation (ODE):</p> \[\dot{Z}_t = v_t(Z_t), \quad \forall t \in [0,1], \quad \text{starting from } Z_0 \sim \pi_0, \tag{1}\] <p>where \(\dot{Z}_t = \mathrm dZ_t / \mathrm dt\) denotes the time derivative, and the velocity field \(v_t(x) = v(x, t)\) is a learnable function to be estimated to ensure that \(Z_1\) follows the target distribution \(\pi_1\) when starting from \(Z_0 \sim \pi_0\). In this case, we say that the stochastic process \(Z = \{Z_t\}\) provides an (ODE) transport from \(\pi_0\) to \(\pi_1\).</p> <p>It is important to note that, in all but trivial cases, there exist <em>infinitely many</em> ODE transports from \(\pi_0\) to \(\pi_1\), provided that at least one such process exists. Thus, it is essential to be clear about which types of ODEs we should prefer.</p> <p>One option is to favor ODEs that are easy to solve at inference time. In practice, the ODEs are approximated using numerical methods, which typically construct piecewise linear approximations of the ODE trajectories. For instance, a common choice is Euler’s method:</p> \[\hat{Z}_{t+\epsilon} = \hat{Z}_t + \epsilon v_t(\hat{Z}_t), \quad \forall t \in \{0, \epsilon, 2\epsilon, \dots, 1\}, \tag{2}\] <p>where \(\epsilon &gt; 0\) is a step size. Varying the step size \(\epsilon\) introduces a trade-off between accuracy and computational cost: smaller \(\epsilon\) yields high accuracy but incurs a larger number of calculation steps. Therefore, we should seek ODEs that can be approximated accurately even with large step sizes.</p> <div class="l-body"> <iframe src="/assets/plotly/intro_euler_approximation_with_arrows.html" frameborder="0" scrolling="no" height="480px" width="100%"></iframe> </div> <p>The ideal scenario arises when the ODE follows straight-line trajectories, in which case Euler approximation yields zero discretization error regardless of the choice of step sizes. In such cases, the ODE, up to time reparameterization, should satisfy:</p> \[Z_t = t Z_1 + (1 - t) Z_0, \quad \implies \quad \dot{Z}_t = Z_1 - Z_0.\] <p>These ODEs, known as straight transports, enable fast generative models that can be simulated in a single step. We refer to the resulting pair \((Z_0, Z_1)\) as a straight coupling of \(\pi_0\) and \(\pi_1\). In practice, perfect straightness may not be achievable, but a goal we can aim for is to make the ODE trajectories as straight as possible to maximize computational efficiency.</p> <p>It is possible to discuss generalized notions of straightness when solvers other than Euler’s method are used.</p> <h2 id="rectified-flow">Rectified Flow</h2> <p>To construct a flow transporting \(\pi_0\) to \(\pi_1\), let us assume that we are given an arbitrary coupling \((X_0, X_1)\) of \(\pi_0\) and \(\pi_1\), from which we can obtain empirical draws. This can be simply the independent coupling with law \(\pi_0 \times \pi_1\), as is common in practice when we have access to independent samples from \(\pi_0\) and \(\pi_1\). The idea is that we are going to take \((X_0, X_1)\) and convert it to a better coupling generated by an ODE model, and optionally, we can go further to iteratively repeat this process to further enhance desired properties, such as straightness.</p> <p>Rectified flow works in the following ways:</p> <ul> <li><strong>Build Interpolation:</strong><br/> We build an interpolation process \(\{X_t\} = \{X_t : t \in [0, 1]\}\) that smoothly interpolates between \(X_0\) and \(X_1\). Although general choices are possible, let us consider the canonical choice of straight-line interpolation: \(X_t = t X_1 + (1 - t) X_0.\) Here \(\{X_t\}\) is a stochastic process generated in a special way: we first sample the endpoints \(X_0\) and \(X_1\) and then sample the intermediate trajectory connecting them. Such processes are also known as bridge processes, where the intermediate values of \(X_t\) smoothly “bridge” the distribution between \(X_0\) and \(X_1\).</li> </ul> <div class="l-page"> <iframe src="/assets/plotly/intro_straight_interp.html" frameborder="0" scrolling="no" height="630px" width="100%"></iframe> </div> <ul> <li><strong>Marginal Matching:</strong><br/> By construction, the marginal distributions of \(X_0\) and \(X_1\) match the target distributions \(\pi_0\) and \(\pi_1\) through the interpolation process \(\{X_t\}\). However, \(\{X_t\}\) is not a causal ODE process like \(\dot{Z}_t = v_t(Z_t)\), which evolves forward from \(Z_0\). Instead, generating \(X_t\) requires knowledge of both \(X_0\) and \(X_1\), rather than evolving solely from \(X_0\) as \(t\) increases.</li> </ul> <p>This issue can be resolved if we can convert \(\{X_t\}\) somehow into a causal ODE process while preserving the marginal distributions of \(X_t\) at each time \(t\). Perhaps surprisingly, this can be achieved by simply training the ODE model \(\dot{Z}_t = v_t(Z_t)\) to match the slope \(\dot{X}_t\) of the interpolation process via:</p> \[\min_v \int_0^1 \mathbb{E} \left[ \left\| \dot{X}_t - v_t(X_t) \right\|^2 \right] \mathrm dt. \tag{3}\] <p>The theoretical minimum is achieved by:</p> \[v_t^*(x) = \mathbb{E} \left[ \dot{X}_t \mid X_t = x \right],\] <p>which denotes the expectation of the slope \(\dot{X}_t\) of the interpolation process passing through a given point \(X_t = x\).</p> <blockquote> <p><strong>Definition: Rectified Flow.</strong></p> <p>For any time-differential stochastic process \(\{X_t\} = \{X_t : t \in [0, 1]\}\), we call the ODE process:</p> \[\dot{Z}_t = v_t^*(Z_t) \quad \text{with} \quad v_t^*(x) = \mathbb{E} \left[ \dot{X}_t \mid X_t = x \right],\] <p>and \(Z_0 = X_0\) the <strong>rectified flow</strong> induced by \(\{X_t\}\). We denote it as:</p> \[\{Z_t\} = \text{RectFlow}(\{X_t\}).\] </blockquote> <p>With the canonical straight interpolation, we have \(\dot{X}_t = X_1 - X_0\) by taking the derivative of \(X_t\) with respect to \(t\). It yields:</p> \[\min_v \int_0^1 \mathbb{E} \left[ \| \dot{X}_t - v_t(X_t) \|^2 \right] \mathrm dt, \quad X_t = t X_1 + (1 - t) X_0.\] <p>In practice, the optimization in (3) can be efficiently solved even for large AI models when \(v\) is parameterized as modern deep neural nets. This is achieved by leveraging off-the-shelf optimizers with stochastic gradients, computed by drawing pairs \((X_0, X_1)\) from data, sampling \(t\) uniformly in \([0, 1]\), and then computing the corresponding \((X_t, \dot{X}_t)\) using the interpolation formula.</p> <div class="l-page"> <iframe src="/assets/plotly/intro_1rf.html" frameborder="0" scrolling="no" height="630px" width="100%"></iframe> </div> <p>This figure illustrates the intuition. In the interpolation process \(\{X_t\}\), different trajectories may have intersecting points, resulting in multiple possible values of \(\dot{X}_t\) associated with the same point \(X_t\) due to uncertainty about the originating trajectory (see the straight interpolation figure). However, by the definition of an ODE \(\dot{Z}_t = v_t^*(Z_t)\), the update direction \(\dot{Z}_t\) at each point \(Z_t\) is uniquely determined by \(Z_t\), making it impossible for different trajectories of \(\{Z_t\}\) to intersect and then diverge. At these intersection points of \(\{X_t\}\), where \(\dot{X}_t\) is stochastic and non-unique, \(Z_t\) “derandomizes” the update direction by following the conditional expectation:</p> \[v_t^*(X_t) = \mathbb{E} \left[ \dot{X}_t \mid X_t \right],\] <p>thus providing the unique update direction required by ODEs.</p> <p>What makes rectified flow \(\{Z_t\}\) useful is that it preserves the marginal distributions of \(\{X_t\}\) at each point while resulting in a “better” coupling \((Z_0, Z_1)\) in terms of optimal transport:</p> <p><strong>[Marginal Preservation]</strong></p> <p>The \(\{X_t\}\) and its rectified flow \(\{Z_t\}\) share the same marginal distributions at each time \(t \in [0, 1]\), that is:</p> \[\text{Law}(Z_t) = \text{Law}(X_t), \quad \forall t \in [0, 1].\] <div class="l-page"> <img src="/assets/img/flow_in_out.png" alt="cross" style="max-width:100%;"/> </div> <p><strong>[Transport Cost]</strong></p> <p>The start-end pairs \((Z_0, Z_1)\) from the rectified flow \(\{Z_t\}\) guarantee to yield no larger transport cost than \((X_0, X_1)\), simultaneously for all convex cost functions \(c\):</p> \[\mathbb{E} \left[ c(Z_1 - Z_0) \right] \leq \mathbb{E} \left[ c(X_1 - X_0) \right], \quad \forall \text{convex } c : \mathbb{R}^d \to \mathbb{R}.\] <h2 id="reflow">Reflow</h2> <p>While rectified flows tend to favor straight trajectories, they are not perfectly straight. As shown in Figure, the flow makes turns at intersection points of the interpolation trajectories \(\{X_t\}\). How can we further improve the flow to achieve straighter trajectories and hence speed up inference?</p> <p>A key insight is that the start-end pairs \((Z_0, Z_1)\) generated by rectified flow, called the <strong>rectified coupling</strong> of \((X_0, X_1)\), form a better and “straighter” coupling compared to \((X_0, X_1)\). This is because if we connect \(Z_0\) and \(Z_1\) with a new straight-line interpolation, it would yield fewer intersection points. Hence, training a new rectified flow based on this interpolation would result in straighter trajectories, leading to faster inference.</p> <p>Formally, we apply the RectFlow(·) procedure recursively, yielding a sequence of rectified flows starting from \(\{Z_t^0\} = \{X_t^0\}\):</p> <p><strong>Reflow:</strong></p> \[\{Z_t^{k+1}\} = \texttt{RectFlow}(\texttt{Interp}(Z_0^k, Z_1^k)), \tag{4}\] <p>where \(\text{Interp}(Z_0^k, Z_1^k)\) denotes an interpolation process given \((Z_0^k, Z_1^k)\) as the endpoints. We call \(\{Z_t^k\}\) the k-th rectified flow, or simply <strong>k-rectified flow</strong>, induced from \((X_0, X_1)\).</p> <p>This reflow procedure is proved to “straighten” the paths of rectified flows in the following sense: Define the following measure of straightness of \(\{Z_t\}\):</p> \[S(\{Z_t\}) = \int_0^1 \mathbb{E} \left[ \|Z_1 - Z_0 - \dot{Z}_t\|^2 \right] \mathrm dt,\] <p>where \(S(\{Z_t\})\) is a measure of the straightness of \(\{Z_t\}\), with \(S(\{Z_t\}) = 0\) corresponding to straight paths. Then we have the following for reflow:</p> \[\mathbb{E}_{k \sim \text{Unif}(\{1, \dots, K\})} \left[S(\{Z_t^k\})\right] = \mathcal{O}(1 / K), \tag{5}\] <p>Hence, we would obtain perfectly straight-line dynamics in the limit of \(k \to +\infty\). Note that reflow can begin from any coupling \((X_0, X_1)\), so it provides a general procedure for straightening and thus speeding up any given dynamics while preserving the marginals.</p> <div class="l-page"> <iframe src="/assets/plotly/intro_2rf.html" frameborder="0" scrolling="no" height="630px" width="100%"></iframe> </div>]]></content><author><name>Qiang Liu</name></author><category term="introduction"/><summary type="html"><![CDATA[A Brief Introduction to the Rectified Flow Model]]></summary></entry></feed>