<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://rectifiedflow.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://rectifiedflow.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-12-12T01:26:16+00:00</updated><id>https://rectifiedflow.github.io/feed.xml</id><title type="html">blank</title><subtitle>Everything should be made as simple as possible, but not simpler. </subtitle><entry><title type="html">All Flows are One Flow</title><link href="https://rectifiedflow.github.io/blog/2024/interpolation/" rel="alternate" type="text/html" title="All Flows are One Flow"/><published>2024-12-10T10:00:00+00:00</published><updated>2024-12-10T10:00:00+00:00</updated><id>https://rectifiedflow.github.io/blog/2024/interpolation</id><content type="html" xml:base="https://rectifiedflow.github.io/blog/2024/interpolation/"><![CDATA[<p>In this blog post, we will first demonstrate that all <em>affine interpolations</em> are point-wise transformable. We will then explain how transformations between these interpolations can be performed. Building upon this, we will show that these interpolations yield essentially <strong>equivalent</strong> rectified flow dynamics and identical rectified couplings. The key insight is that the transformations applied to the interpolation are <strong>exactly the same</strong> as those applied to the rectified flow.</p> <p>Before diving deeper, let’s quickly review the core concepts of Rectified Flow.</p> <p>See this <a href="">notebook</a> for implementation.</p> <h2 id="recap-rectified-flow">Recap: Rectified Flow</h2> <h3 id="affine-interpolation">Affine Interpolation</h3> <p>Given observed samples \(X_0 \sim \pi_0\) from a source distribution and \(X_1 \sim \pi_1\) from a target distribution, we consider a class of <em>affine interpolations</em> \(X_t\):</p> \[X_t = \alpha_t \cdot X_0 + \beta_t \cdot X_1, \tag{1}\] <p>where \(\alpha_t\) and \(\beta_t\) are time-dependent functions satisfying:</p> \[\alpha_0 = \beta_1 = 0 \quad \text{and} \quad \alpha_1 = \beta_0 = 1. \tag{2}\] <p>This form of interpolation is referred to as <strong>affine interpolation</strong>. In practice, it is desirable for \(\alpha_t\) to be monotonically increasing and \(\beta_t\) to be monotonically decreasing over the interval \([0,1]\).</p> <p>The collection \(\{X_t\} = \{X_t : t \in [0,1]\}\) defines an <strong>interpolation process</strong>, which smoothly transitions the distribution from \(X_0\) at \(t=0\) to \(X_1\) at \(t=1\).</p> <p>While this process effectively creates a “bridge” between \(X_0\) and \(X_1\), it has a notable limitation: it is not “simulatable” using only the source data. To generate \(X_t\) for some \(t \in (0,1)\), one needs direct access to both \(X_0\) and \(X_1\), making it impossible to produce new target samples without having the target distribution already in hand.</p> <div class="l-page"> <iframe src="/assets/plotly/interp_affine_interpolation.html" frameborder="0" scrolling="no" height="630px" width="100%"></iframe> </div> <h3 id="rectified-flow-velocity">Rectified Flow Velocity</h3> <p>To overcome this limitation and make the process “simulatable,” we can train an Ordinary Differential Equation (ODE) model. The idea is to model the dynamics with an ODE defined as \(\dot{Z}_t = v_t(Z_t)\), where \(v_t\) is a time-dependent velocity field. We train \(v_t\) to match the slope \(\dot{X}_t\) of the interpolation process:</p> \[\min_v \int_0^1 \mathbb{E}\left[\| \dot{X}_t - v_t(X_t) \|^2\right] \,\mathrm{d}t. \tag{3}\] <p>The theoretical optimum is given by:</p> \[v_t^*(x) = \mathbb{E}[\dot{X}_t \mid X_t = x], \tag{4}\] <p>which is the <strong>conditional average</strong> of all slopes \(\dot{X}_t\) of the interpolation process at a specific point \(X_t = x\).</p> <p>This conditional average ensures that the model preserves the marginal distributions. Intuitively, the ODE acts like a “rectifier,” ensuring that the mass passing through small regions remains the same after the transformation. As a result, the distributions \(\{Z_t\}_t\), obtained by simulating the ODE, match the distributions \(\{X_t\}_t\) derived from the interpolation.</p> <div class="l-body"> <img src="/assets/img/flow_in_out.png" alt="cross" style="max-width:100%;"/> </div> <p>We refer to the process \(\{Z_t\}\) as the <strong>rectified flow</strong>, which is induced by the interpolation \(\{X_t\}\). The rectified flow follows:</p> \[Z_t = Z_0 + \int_0^t v(Z_s, s) \,\mathrm{d}s, \quad \forall t \in [0,1], \quad Z_0 = X_0, \tag{5}\] <p>or more compactly,</p> \[\{Z_t\} = \texttt{RectFlow}(\{X_t\}).\] <h3 id="example-straight-interpolation">Example: Straight Interpolation</h3> <p>The <code class="language-plaintext highlighter-rouge">straight</code> interpolation, with coefficients \(\alpha_t = 1 - t\) and \(\beta_t = t\) yield:</p> \[X_t = tX_1 + (1 - t)X_0, \quad \dot{X}_t = X_1 - X_0. \tag{6}\] <div class="l-page"> <iframe src="/assets/plotly/interp_1rf_straight.html" frameborder="0" scrolling="no" height="630px" width="100%"></iframe> </div> <h2 id="interpolation-converter">Interpolation Converter</h2> <p>However, \(\alpha_t\) and \(\beta_t\) are not limited to this specific choice. They can be <strong>any</strong> time-dependent functions, as long as they satisfy the conditions \(\alpha_0 = \beta_1 = 0\) and \(\alpha_1 = \beta_0 = 1\) (and maintain monotonicity). This implies there are infinitely many possible interpolation processes \(\{X_t\}\) that can be used to induce rectified flows.</p> <h3 id="straight-spherical-and-ddim-interpolation">Straight, Spherical and DDIM interpolation</h3> <p><strong>Straight Line Interpolation</strong> (<code class="language-plaintext highlighter-rouge">straight</code> or <code class="language-plaintext highlighter-rouge">lerp</code>)</p> \[\begin{aligned} \alpha_t &amp; = t, &amp; \beta_t &amp; = 1 - t \\ \dot{\alpha}_t &amp; = 1, &amp; \dot{\beta}_t &amp; = -1 \end{aligned} \tag{7}\] <ul> <li>This interpolation follows a straight line connecting the source and target distributions with a constant speed.</li> </ul> <p><strong>Spherical Interpolation</strong> (<code class="language-plaintext highlighter-rouge">spherical</code> or <code class="language-plaintext highlighter-rouge">slerp</code>)</p> \[\begin{aligned} \alpha_t &amp; = \sin\left(\frac{\pi}{2} t\right), &amp; \beta_t &amp; = \cos\left(\frac{\pi}{2} t\right) \\ \dot{\alpha}_t &amp; = \frac{\pi}{2} \cos\left(\frac{\pi}{2} t\right), &amp; \dot{\beta}_t &amp; = -\frac{\pi}{2} \sin\left(\frac{\pi}{2} t\right) \end{aligned} \tag{8}\] <ul> <li>Spherical interpolation traces a curved path rather than a straight line.</li> </ul> <p><strong>DDIM / VP ODE Interpolation</strong></p> <p>\(\alpha_t = \exp\left(- \frac{1}{4}a(1-t)^2 - \frac{1}{2}b(1-t)\right), \quad \beta_t = \sqrt{1 - \alpha_t^2}, \quad a=19.9, b=0.1 \tag{9}\)</p> <ul> <li>This also yields a spherical trajectory, but with a non-uniform speed defined by \(\alpha_t\).</li> </ul> <h3 id="pointwise-transformability-between-affine-interpolations">Pointwise Transformability Between Affine Interpolations</h3> <p>Consider two affine interpolation processes defined with same coupling \((X_0, X_1)\):</p> \[X_t = \alpha_t X_1 + \beta_t X_0 \quad \text{and} \quad X_{t}' = \alpha_{t}' X_1 + \beta_{t}' X_0,\] <p>we show that one can be smoothly transformed into the other, and vice versa.</p> <p><strong>1. Matching Time</strong></p> <p>Note that</p> \[\dot{\alpha}_t &gt; 0, \quad \dot{\beta}_t &lt; 0, \quad \alpha_t, \beta_t \in [0,1], \quad \forall t \in [0,1].\] <p>These constraints imply that the ratio \(\alpha_t / \beta_t\) is <strong>strictly increasing</strong> in \([0,1]\). Consequently, for any \(t\) in the process \(\{X_t'\}\), there exists a unique \(t'\) in \(\{X_t\}\) such that the ratio matches:</p> \[\frac{\alpha_{t'}}{\beta_{t'}} = \frac{\alpha_t'}{\beta_t'}.\] <p>Similarly, for any given \(t'\) in \(\{X_t\}\), we can find a unique \(t\) in \(\{X_t'\}\). This establishes a <strong>bijective time mapping</strong> \(\tau: t \mapsto t'\).</p> <p><strong>2. Matching Scales</strong></p> <p>Once the times are matched, consider the ratio of the interpolations:</p> \[\frac{X_{t'}}{X_t'} = \frac{\alpha_{t'}X_1 + \beta_{t'}X_0}{\alpha_t'X_1 + \beta_t'X_0}.\] <p>Rewriting this ratio:</p> \[\frac{X_{t'}}{X_t'} = \frac{\alpha_{t'}}{\alpha_t'} \cdot \frac{X_1 + \frac{\beta_{t'}}{\alpha_{t'}} X_0}{X_1 + \frac{\beta_t'}{\alpha_t'} X_0} = \frac{\alpha_{t'}}{\alpha_t'}.\] <p>This shows that the scaling factor:</p> \[\omega_t := \frac{\alpha_{t'}}{\alpha_t'} = \frac{\beta_{t'}}{\beta_t'} = \frac{X_{t'}}{X_t'},\] <p>is well-defined and independent of \(X_0\) and \(X_1\).</p> <blockquote> <p><strong>Definition: Pointwise Transformability</strong></p> <p>We say that two interpolation processes \(\{X_t\}\) and \(\{X_t'\}\) are <strong>pointwise transformable</strong> if:</p> \[X_t' = \phi_t(X_{\tau_t}), \quad \forall t \in [0,1],\] <p>where \(\tau: t \mapsto \tau_t\) is a monotonic (hence invertible) time transformation, and \(\phi: (t, x) \mapsto \phi_t(x)\) is an invertible transformation.</p> </blockquote> <p>In the affine interpolations case:</p> <ul> <li>The time transformation is \(\tau_t = t'\).</li> <li>The scaling transformation is \(\phi_t(X_t) = X_{\tau_t}/\omega_t\).</li> </ul> <p>We can determine the time scaling function \(\tau_t\) in two ways. For simple cases, \(\tau_t\) can be computed analytically. For more complex scenarios, a numerical approach, such as a <a href="">simple binary search</a>, can be used to find \(\tau_t\) efficiently.</p> <div class="l-page" style="display: flex;"> <iframe src="/assets/plotly/interp_tau_ddim_spherical.html" frameborder="0" scrolling="no" height="430px" width="49%"></iframe> <iframe src="/assets/plotly/interp_tau_straight_spherical.html" frameborder="0" scrolling="no" height="430px" width="49%"></iframe> </div> <p>The figure below demonstrates the conversion between the <code class="language-plaintext highlighter-rouge">straight</code> and <code class="language-plaintext highlighter-rouge">spherical</code> interpolations using a binary search method. Observe that once converted, the trajectory of the original <code class="language-plaintext highlighter-rouge">straight</code> interpolation matches perfectly with the newly derived <code class="language-plaintext highlighter-rouge">straight</code> curve, confirming that these interpolations are indeed pointwise transformable.</p> <div class="l-page"> <iframe src="/assets/plotly/interp_affine_interp_conversion.html" frameborder="0" scrolling="no" height="630px" width="100%"></iframe> </div> <h2 id="rectified-flow-converter">Rectified Flow Converter</h2> <h3 id="equivariance-of-rectified-flow">Equivariance of Rectified Flow</h3> <p>Interestingly, the very same transformation applied to the interpolation process \(\{X_t\}\) can also be applied to the corresponding rectified flows. This observation leads us to the following theorem:</p> <blockquote> <p><strong>Theorem: Equivariance of Rectified Flow</strong></p> <p>Suppose two processes \(\{X_t\}\) and \(\{X'_t\}\) are related pointwise by \(X'_t = \phi_t(X_{\tau_t}),\)</p> <p>where \(\phi : (t, x) \mapsto \phi_t(x)\) and \(\tau : t \mapsto \tau_t\) are differentiable, invertible mappings. If their corresponding rectified flows are denoted by \(\{Z_t\}\) and \(\{Z'_t\}\), then they satisfy the analogous relationship</p> \[Z'_t = \phi_t(Z_{\tau_t}),\] <p>provided that this relationship holds at initialization (i.e., \(Z'_0 = \phi_0(Z_0)\)).</p> </blockquote> <p><strong>Implications</strong></p> <p>This result demonstrates that the rectified flows associated with pointwise transformable interpolations are essentially <strong>equivalent</strong>, differing only by the same pointwise transformation. Moreover, if \(X_t = \mathcal{I}_t(X_0, X_1)\) and \(X'_t = \mathcal{I}'_t(X_0, X_1)\) are constructed from the same initial coupling \((X_0, X_1)\), they induce identical rectified couplings: \((Z'_0, Z'_1) = (Z_0, Z_1)\).</p> <p>In short, if we define \(\{X'_t\} = \texttt{Transform}(\{X_t\})\) as above, then the rectification operation \(\texttt{Rectify}(\cdot)\) is <strong>equivariant</strong> under such transformations. Formally:</p> \[\texttt{Rectify}(\texttt{Transform}(\{X_t\})) = \texttt{Transform}(\texttt{Rectify}(\{X_t\})).\] <p>For a more detailed derivation, please refer to Chapter 3 of the flow book.</p> <h3 id="converting-pretrained-rf-velocity">Converting Pretrained RF Velocity</h3> <p>Now, let’s take a pretrained straight rectified flow and transform it into a curved trajectory. The idea is to leverage our existing velocity predictions from the straight path and re-apply them to a new, curved interpolation. Here’s the general approach:</p> <ol> <li> <p><strong>Mapping to the New Trajectory</strong>:<br/> First, we find the corresponding position on the straight trajectory \(\{Z_t\}\) for any given point \(Z'_t\) on the curved trajectory \(\{Z'_t\}\). This ensures we can reuse the pre-trained velocity field, which is defined along the straight path.</p> </li> <li> <p><strong>Velocity Predictions</strong>:<br/> With the mapping established, we can now use the trained velocity model on \(\{Z_t\}\) to obtain predictions \(\hat{X}_0\) and \(\hat{X}_1\). These predictions are crucial for ensuring that our curved interpolation still respects the underlying distributions.</p> </li> <li> <p><strong>Updating the Trajectory</strong>:<br/> Finally, we advance the state along the curved trajectory using the updated interpolation \(\mathcal{I}(\hat{X}_0, \hat{X}_1)\). This step integrates our predictions and ensures the resulting flow truly follows the curved path we’ve chosen.</p> </li> </ol> <p>By following these steps, we effectively “re-route” a rectified flow—originally trained on a straight interpolation—onto a different curve, all without needing to retrain the underlying model.</p> <div class="l-page"> <iframe src="/assets/plotly/interp_1rf_straight_to_spherical.html" frameborder="0" scrolling="no" height="630px" width="100%"></iframe> </div> <p><strong>Trajectory Considerations</strong></p> <p>Looking at the figure above, we see that as the number of sampling steps increases, the trajectories for \(Z_1\) and \(Z_1'\) converge to the same points, and the mean squared error between them decreases, thereby validating the theorem.</p> <p>However, even though different paths can lead to the same rectified endpoints \(Z_1\), the intermediate trajectories \(\{Z_t\}\) they follow are not the same. In practice, we must discretize these trajectories when running simulations, making perfect solutions unattainable. For this reason, choosing straighter trajectories is generally preferable: the straighter the path, the lower the discretization errors, and the more faithful the results.</p> <h3 id="train-two-rectified-flows-equivalent-rectified-couplings">Train Two Rectified Flows: Equivalent Rectified Couplings</h3> <p>When two pointwise transformable interpolation processes are derived from the same coupling \((X_0, X_1)\), they will produce the same rectified coupling. In other words, no matter what interpolation you choose—provided it starts and ends at the same distributions—the rectified flow will align their endpoints.</p> <blockquote> <p><strong>Theorem. Equivalence of Rectified Couplings</strong></p> <p>Suppose we have two interpolation processes, \(\{X_t\}\) and \(\{X'_t\}\), that share the same initial and final conditions:</p> \[(X_0, X_1) = (X'_0, X'_1),\] <p>and suppose that their time transformation \(\tau\) satisfies \(\tau(0) = 0\) and \(\tau(1) = 1\). Under these conditions, their corresponding rectified flows yield the same coupling:</p> \[(Z_0, Z_1) = (Z'_0, Z'_1).\] </blockquote> <p>To illustrate this result, let’s consider a simple 2D example and verify the theorem in action.</p> <div class="l-page"> <iframe src="/assets/plotly/interp_straight_spherical_rf.html" frameborder="0" scrolling="no" height="630px" width="100%"></iframe> </div> <p>This figure shows that when we independently train two rectified flows using the same data coupling \((X_0, X_1)\) but employ different interpolation schemes, the resulting couplings \((Z_0,Z_1)\) and \((Z_0',Z_1')\) are the same. Check the notebook for more details.</p>]]></content><author><name>Rectified Flow Research Group</name></author><category term="tutorial"/><summary type="html"><![CDATA[Affine Interpolations Result in Equivalent Rectified Flows]]></summary></entry><entry><title type="html">Stochastic Sampler: Langevin as Guardrail</title><link href="https://rectifiedflow.github.io/blog/2024/samplers/" rel="alternate" type="text/html" title="Stochastic Sampler: Langevin as Guardrail"/><published>2024-12-10T10:00:00+00:00</published><updated>2024-12-10T10:00:00+00:00</updated><id>https://rectifiedflow.github.io/blog/2024/samplers</id><content type="html" xml:base="https://rectifiedflow.github.io/blog/2024/samplers/"><![CDATA[<p>Rectified Flow learns ODE trajectories from the initial distribution $X_0 \sim \pi_0$ to target distribution $X_1 \sim \pi_1$. In the special case where $(X_0, X_1) \sim \pi_0 \times \pi_1$ is an independent coupling and $\pi_0$ is a Gaussian distribution, we can use a <strong>stochastic solver</strong> instead of a deterministic ODE solver during inference. This approach can lead to improved sample quality.</p> <p>In this section, we will introduce how to apply stochastic solvers to rectified flow models. We will: <d-cite key="Liu2022FlowSA"></d-cite></p> <ul> <li>Understand why using a stochastic sampler might sometimes yield better results than a deterministic sampler (like Euler).</li> <li>Understand how to use the different samplers in <a href="https://github.com/lqiang67/rectified-flow">Rectified Flow repo</a></li> </ul> <h2 id="deterministic-and-stochastic-sampler">Deterministic and Stochastic Sampler</h2> <h3 id="why-use-stochastic-sampling">Why use stochastic sampling?</h3> <p>For rectified flow models, a stochastic sampler sometimes produces better results than a deterministic one. For example, in diffusion models, people find that DDPM (stochastic) works better than DDIM (deterministic) for large-scale text-to-image tasks. Similarly, our <a href="https://arxiv.org/abs/2411.19415">recent work</a> have shown that using a stochastic sampler with rectified flow can improve sample quality, particularly when it comes to rendering complex details like text.</p> <p>Below, we will compare results generated using an Euler sampler (deterministic) and an SDE sampler (stochastic). By visually comparing these results, you can see the qualitative improvements that a stochastic sampler can bring.</p> <div class="l-body"> <img src="/assets/img/euler_sde_compare.png" alt="cross" style="max-width:100%;"/> </div> <p>From the visualization above, we see that the Euler samples do not align perfectly with the target distribution $\pi_1$. In contrast, the SDE sampler brings the generated samples closer to $\pi_1$.</p> <h3 id="why-can-a-stochastic-sampler-be-better">Why Can a Stochastic Sampler Be Better?</h3> <p>You might wonder: what makes a stochastic sampler (one that adds randomness at inference) better than a deterministic sampler (one that follows a fixed path)?</p> <p>To understand this, let’s think about <strong>Langevin dynamics</strong>, which is a way of adding small random “pushes” that help samples move in the right direction when evolving from the initial distribution $\pi_0$ to the target distribution $\pi_1$.</p> <p><strong>Key Idea:</strong></p> <p>Rectified flow models learn a <strong>velocity field</strong> $v_t(\cdot)$ that describes how to move points from $\pi_0$ to $\pi_1$. Without noise, we have an ODE:</p> \[d \tilde{Z}_t = v_t(\tilde{Z}_t)dt\] <p>Here:</p> <ul> <li>$\tilde{Z}_t$ is the sample on ODE at time $t$</li> <li>$v_t$ is the learned velocity at time $t$</li> </ul> <p>However, we can also consider a stochastic version by adding a noise-driven term. This leads to an SDE (Stochastic Differential Equation):</p> \[d \tilde{Z}_t = \underbrace{v_t(\tilde{Z}_t)dt}_{\text{Rectified Flow term}} + \underbrace{ \sigma_t^2 \nabla \log \rho_t(\tilde{Z}_t) dt + \sqrt{2} \sigma_t d W_t}_{\text{Langevin dynamics term}},\] <p>Let’s break down the additional terms:</p> <ul> <li> <p>$\rho_t$ is the probability density of the samples at time $t$</p> </li> <li> <p>$\nabla \log \rho_t(\tilde{Z}_t)$ is known as the <strong>score function</strong>. It points in the direction where density is higher. In other words, it tells us how to “correct” the trajectory so that samples move toward higher probability regions of the target distribution.</p> </li> <li> <p>$\sigma_t$ is a noise scale that can vary with time. It controls how strong the random pushes are.</p> </li> <li> <p>$W_t$ represents a Wiener process (or Brownian motion), which is a source of randomness.</p> </li> </ul> <p><strong>What does this achieve?</strong></p> <ul> <li> <p>The <strong>rectified flow term</strong> $v_t(\tilde{Z}_t$ ties to move samples from $\pi_0$ to $\pi_1$ along a smoothly learned path.</p> </li> <li> <p>The <strong>Langevin dynamics term</strong> $\sigma_t^2 \nabla \log \rho_t(\tilde{Z}_t) dt + \sqrt{2} \sigma_t d W_t$ add controlled randomness. The $\nabla \log \rho_t$ term pushes samples toward regions of higher density, while the $d W_t$ term injects noise that preserves the marginal distribution of $\tilde{Z}_t$.</p> </li> </ul> <p>By combining these two effects, the stochastic sampler often finds a better overall solution than a purely deterministic one. It can “correct” the path that samples take, making sure they end up where $\pi_1$ actually has mass, resulting in more accurate and higher-quality samples.</p> <p>Score Function Visualization: In the next toy example, we’ll visualize the score function $\nabla \log \rho_t$. This will help you see how these small corrective forces guide the samples toward the right regions, improving upon what a purely deterministic approach can achieve.</p> <div class="l-body"> <img src="/assets/img/score_function_on_sde_traj.png" alt="cross" style="max-width:100%;"/> </div> <p>As shown here, the score function ($\nabla \log \rho_t$) points samples toward regions of higher density. This corrects the trajectories from the original predicted velocity, providing a drifting force that helps ensure samples converge to the most probable areas of the target distribution.</p> <h2 id="use-different-samplers-in-rectified-flow">Use Different Samplers in Rectified Flow</h2> <p>In the Rectified Flow repository, we provide several built-in sampler options. These samplers make it easy to experiment with different ways of generating samples from the learned velocity field. Each sampler follows a different rule for updating particles from the initial distribution $\pi_0$ (a known Gaussian) toward the target distribution $\pi_1$.</p> <h3 id="euler-sampler">Euler Sampler</h3> <p>The <strong>Euler Sampler</strong> is a simple, deterministic method. It updates each sample $X_t$ by moving along the direction of the velocity field $v(X_t, t)$:</p> \[X_{t + \Delta t} = X_t + \Delta t \cdot v(X_t, t)\] <p>This means we are directly integrating the learned velocity field over time.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">rectified_flow.samplers</span> <span class="kn">import</span> <span class="n">EulerSampler</span>

<span class="n">euler_sampler</span> <span class="o">=</span> <span class="nc">EulerSampler</span><span class="p">(</span>
    <span class="n">rectified_flow</span><span class="o">=</span><span class="n">rectflow</span><span class="p">,</span>
    <span class="n">num_steps</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">num_samples</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">euler_sampler</span><span class="p">.</span><span class="nf">sample_loop</span><span class="p">()</span>

</code></pre></div></div> <div class="l-body"> <img src="/assets/img/euler_sample_result.png" alt="cross" style="max-width:100%;"/> </div> <h3 id="curved-euler-sampler">Curved Euler Sampler</h3> <p>The <strong>Curved Euler Sampler</strong> uses interpolation to trace a curved path rather than a straight line. It works as follows:</p> <ul> <li>Starting from the current state $(X_t, t)$</li> <li>Use the velocity model to predict the next velocities and generate two reference points $\hat{X}_0$ and $\hat{X}_1$.</li> <li>Interpolate between $\hat{X}_0$ and $\hat{X}_1$ using functions $\alpha(t)$ and $\beta(t)$ to get the next state:</li> </ul> \[X_{t + \Delta_t} = \alpha(t + \Delta t) \cdot \hat{X}_1 + \beta(t + \Delta t) \cdot \hat{X}_0\] <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">rectified_flow.samplers</span> <span class="kn">import</span> <span class="n">CurvedEulerSampler</span>

<span class="n">curved_euler_sampler</span> <span class="o">=</span> <span class="nc">CurvedEulerSampler</span><span class="p">(</span>
    <span class="n">rectified_flow</span><span class="o">=</span><span class="n">rectflow</span><span class="p">,</span>
    <span class="n">num_steps</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">num_samples</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">curved_euler_sampler</span><span class="p">.</span><span class="nf">sample_loop</span><span class="p">()</span>

</code></pre></div></div> <div class="l-body"> <img src="/assets/img/curved_euler_sample_result.png" alt="cross" style="max-width:100%;"/> </div> <h3 id="sdesampler">SDESampler</h3> <p>The SDESampler introduces stochasticity (randomness) into the sampling process. we control the noise at time $t$ using the following hyperparameters:</p> <ul> <li> <p>noise_scale: Controls the amount of noise added at each step.</p> </li> <li> <p>noise_decay_rate: Controls how the noise changes over time. A decay rate of 0 means noise level stays the same, while a decay rate of 1.0 means noise decreases over time.</p> </li> </ul> <p>Mathematically, the effective noise is something like:</p> <p>$\text{Effective Noise at time t} = \text{step_size} * \text{noise_scale} * \beta_t ^ \text{noise_decay_rate}$</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">rectified_flow.samplers</span> <span class="kn">import</span> <span class="n">SDESampler</span>

<span class="n">sde_sampler</span> <span class="o">=</span> <span class="nc">SDESampler</span><span class="p">(</span>
    <span class="n">rectified_flow</span><span class="o">=</span><span class="n">rectflow</span><span class="p">,</span>
    <span class="n">num_steps</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">num_samples</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span>
    <span class="n">noise_scale</span><span class="o">=</span><span class="mf">15.0</span><span class="p">,</span>      <span class="c1"># Increase noise
</span>    <span class="n">noise_decay_rate</span><span class="o">=</span><span class="mf">0.0</span>   <span class="c1"># Keep noise level constant
</span><span class="p">)</span>

<span class="n">sde_sampler</span><span class="p">.</span><span class="nf">sample_loop</span><span class="p">()</span>
</code></pre></div></div> <div class="l-body"> <img src="/assets/img/sde_sample_result.png" alt="cross" style="max-width:100%;"/> </div> <h3 id="overshootingsampler">OvershootingSampler</h3> <p>The OverShootingSampler, introduced in <a href="(https://arxiv.org/abs/2411.19415)">our AMO Sampler paper</a>, adds an extra “overshoot” step during sampling. This means that at each step, it doesn’t just move forward along the trajectory, but goes a bit beyond the next point and then comes back, adding more stochasticity and potentially finding better paths. We can control the amount of noise added by:</p> <ul> <li>c: A parameter controlling how far we overshoot.</li> <li>overshooting_method: Determines the exact method used to overshoot (e.g., “t+dt”).</li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">rectified_flow.samplers</span> <span class="kn">import</span> <span class="n">OverShootingSampler</span>


<span class="n">sde_sampler</span> <span class="o">=</span> <span class="nc">OverShootingSampler</span><span class="p">(</span>
  <span class="n">rectified_flow</span><span class="o">=</span><span class="n">rectflow</span><span class="p">,</span>
	<span class="n">num_steps</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
	<span class="n">num_samples</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span>
  <span class="n">c</span><span class="o">=</span><span class="mf">15.0</span><span class="p">,</span>
  <span class="n">overshooting_method</span><span class="o">=</span><span class="sh">"</span><span class="s">t+dt</span><span class="sh">"</span>
<span class="p">)</span>

<span class="n">sde_sampler</span><span class="p">.</span><span class="nf">sample_loop</span><span class="p">()</span>
</code></pre></div></div> <div class="l-body"> <img src="/assets/img/overshooting_sample_result.png" alt="cross" style="max-width:100%;"/> </div>]]></content><author><name>RectifiedFlow Group</name></author><category term="tutorial"/><summary type="html"><![CDATA[Connections between Deterministic and Stochastic Samplers]]></summary></entry><entry><title type="html">Rectified Flow, An Introduction</title><link href="https://rectifiedflow.github.io/blog/2024/intro/" rel="alternate" type="text/html" title="Rectified Flow, An Introduction"/><published>2024-12-06T10:00:00+00:00</published><updated>2024-12-06T10:00:00+00:00</updated><id>https://rectifiedflow.github.io/blog/2024/intro</id><content type="html" xml:base="https://rectifiedflow.github.io/blog/2024/intro/"><![CDATA[<h2 id="overview">Overview</h2> <p>Generative modeling can be formulated as finding a computational procedure that transforms a noise distribution, denoted by \(\pi_0\), into the unknown data distribution \(\pi_1\). In flow models, this procedure is represented by an ordinary differential equation (ODE):</p> \[\dot{Z}_t = v_t(Z_t), \quad \forall t \in [0,1], \quad \text{starting from } Z_0 \sim \pi_0, \tag{1}\] <p>where \(\dot{Z}_t = \mathrm dZ_t / \mathrm dt\) denotes the time derivative, and the velocity field \(v_t(x) = v(x, t)\) is a learnable function to be estimated to ensure that \(Z_1\) follows the target distribution \(\pi_1\) when starting from \(Z_0 \sim \pi_0\). In this case, we say that the stochastic process \(Z = \{Z_t\}\) provides an (ODE) transport from \(\pi_0\) to \(\pi_1\).</p> <p>It is important to note that, in all but trivial cases, there exist <em>infinitely many</em> ODE transports from \(\pi_0\) to \(\pi_1\), provided that at least one such process exists. Thus, it is essential to be clear about which types of ODEs we should prefer.</p> <p>One option is to favor ODEs that are easy to solve at inference time. In practice, the ODEs are approximated using numerical methods, which typically construct piecewise linear approximations of the ODE trajectories. For instance, a common choice is Euler’s method:</p> \[\hat{Z}_{t+\epsilon} = \hat{Z}_t + \epsilon v_t(\hat{Z}_t), \quad \forall t \in \{0, \epsilon, 2\epsilon, \dots, 1\}, \tag{2}\] <p>where \(\epsilon &gt; 0\) is a step size. Varying the step size \(\epsilon\) introduces a trade-off between accuracy and computational cost: smaller \(\epsilon\) yields high accuracy but incurs a larger number of calculation steps. Therefore, we should seek ODEs that can be approximated accurately even with large step sizes.</p> <div class="l-body"> <iframe src="/assets/plotly/intro_euler_approximation_with_arrows.html" frameborder="0" scrolling="no" height="480px" width="100%"></iframe> </div> <p>The ideal scenario arises when the ODE follows straight-line trajectories, in which case Euler approximation yields zero discretization error regardless of the choice of step sizes. In such cases, the ODE, up to time reparameterization, should satisfy:</p> \[Z_t = t Z_1 + (1 - t) Z_0, \quad \implies \quad \dot{Z}_t = Z_1 - Z_0.\] <p>These ODEs, known as straight transports, enable fast generative models that can be simulated in a single step. We refer to the resulting pair \((Z_0, Z_1)\) as a straight coupling of \(\pi_0\) and \(\pi_1\). In practice, perfect straightness may not be achievable, but a goal we can aim for is to make the ODE trajectories as straight as possible to maximize computational efficiency.</p> <p>It is possible to discuss generalized notions of straightness when solvers other than Euler’s method are used.</p> <h2 id="rectified-flow">Rectified Flow</h2> <p>To construct a flow transporting \(\pi_0\) to \(\pi_1\), let us assume that we are given an arbitrary coupling \((X_0, X_1)\) of \(\pi_0\) and \(\pi_1\), from which we can obtain empirical draws. This can be simply the independent coupling with law \(\pi_0 \times \pi_1\), as is common in practice when we have access to independent samples from \(\pi_0\) and \(\pi_1\). The idea is that we are going to take \((X_0, X_1)\) and convert it to a better coupling generated by an ODE model, and optionally, we can go further to iteratively repeat this process to further enhance desired properties, such as straightness.</p> <p>Rectified flow works in the following ways:</p> <ul> <li> <p><strong>Build Interpolation:</strong><br/> We build an interpolation process \(\{X_t\} = \{X_t : t \in [0, 1]\}\) that smoothly interpolates between \(X_0\) and \(X_1\). Although general choices are possible, let us consider the canonical choice of straight-line interpolation: \(X_t = t X_1 + (1 - t) X_0.\)</p> <p>Here \(\{X_t\}\) is a stochastic process generated in a special way: we first sample the endpoints \(X_0\) and \(X_1\) and then sample the intermediate trajectory connecting them. Such processes are also known as bridge processes, where the intermediate values of \(X_t\) smoothly “bridge” the distribution between \(X_0\) and \(X_1\).</p> </li> </ul> <div class="l-page"> <iframe src="/assets/plotly/intro_straight_interp.html" frameborder="0" scrolling="no" height="630px" width="100%"></iframe> </div> <ul> <li> <p><strong>Marginal Matching:</strong><br/> By construction, the marginal distributions of \(X_0\) and \(X_1\) match the target distributions \(\pi_0\) and \(\pi_1\) through the interpolation process \(\{X_t\}\). However, \(\{X_t\}\) is not a causal ODE process like \(\dot{Z}_t = v_t(Z_t)\), which evolves forward from \(Z_0\). Instead, generating \(X_t\) requires knowledge of both \(X_0\) and \(X_1\), rather than evolving solely from \(X_0\) as \(t\) increases.</p> <p>This issue can be resolved if we can convert \(\{X_t\}\) somehow into a causal ODE process while preserving the marginal distributions of \(X_t\) at each time \(t\). Perhaps surprisingly, this can be achieved by simply training the ODE model \(\dot{Z}_t = v_t(Z_t)\) to match the slope \(\dot{X}_t\) of the interpolation process via:</p> \[\min_v \int_0^1 \mathbb{E} \left[ \left\| \dot{X}_t - v_t(X_t) \right\|^2 \right] \mathrm dt. \tag{3}\] <p>The theoretical minimum is achieved by:</p> \[v_t^*(x) = \mathbb{E} \left[ \dot{X}_t \mid X_t = x \right],\] <p>which denotes the expectation of the slope \(\dot{X}_t\) of the interpolation process passing through a given point \(X_t = x\).</p> </li> </ul> <blockquote> <p><strong>Definition: Rectified Flow.</strong></p> <p>For any time-differential stochastic process \(\{X_t\} = \{X_t : t \in [0, 1]\}\), we call the ODE process:</p> \[\dot{Z}_t = v_t^*(Z_t) \quad \text{with} \quad v_t^*(x) = \mathbb{E} \left[ \dot{X}_t \mid X_t = x \right],\] <p>and \(Z_0 = X_0\) the <strong>rectified flow</strong> induced by \(\{X_t\}\). We denote it as:</p> \[\{Z_t\} = \text{RectFlow}(\{X_t\}).\] </blockquote> <p>With the canonical straight interpolation, we have \(\dot{X}_t = X_1 - X_0\) by taking the derivative of \(X_t\) with respect to \(t\). It yields:</p> \[\min_v \int_0^1 \mathbb{E} \left[ \| \dot{X}_t - v_t(X_t) \|^2 \right] \mathrm dt, \quad X_t = t X_1 + (1 - t) X_0.\] <p>In practice, the optimization in (3) can be efficiently solved even for large AI models when \(v\) is parameterized as modern deep neural nets. This is achieved by leveraging off-the-shelf optimizers with stochastic gradients, computed by drawing pairs \((X_0, X_1)\) from data, sampling \(t\) uniformly in \([0, 1]\), and then computing the corresponding \((X_t, \dot{X}_t)\) using the interpolation formula.</p> <div class="l-page"> <iframe src="/assets/plotly/intro_1rf.html" frameborder="0" scrolling="no" height="630px" width="100%"></iframe> </div> <p>This figure illustrates the intuition. In the interpolation process \(\{X_t\}\), different trajectories may have intersecting points, resulting in multiple possible values of \(\dot{X}_t\) associated with the same point \(X_t\) due to uncertainty about the originating trajectory (see the straight interpolation figure). However, by the definition of an ODE \(\dot{Z}_t = v_t^*(Z_t)\), the update direction \(\dot{Z}_t\) at each point \(Z_t\) is uniquely determined by \(Z_t\), making it impossible for different trajectories of \(\{Z_t\}\) to intersect and then diverge. At these intersection points of \(\{X_t\}\), where \(\dot{X}_t\) is stochastic and non-unique, \(Z_t\) “derandomizes” the update direction by following the conditional expectation:</p> \[v_t^*(X_t) = \mathbb{E} \left[ \dot{X}_t \mid X_t \right],\] <p>thus providing the unique update direction required by ODEs.</p> <p>What makes rectified flow \(\{Z_t\}\) useful is that it preserves the marginal distributions of \(\{X_t\}\) at each point while resulting in a “better” coupling \((Z_0, Z_1)\) in terms of optimal transport:</p> <p><strong>[Marginal Preservation]</strong></p> <p>The \(\{X_t\}\) and its rectified flow \(\{Z_t\}\) share the same marginal distributions at each time \(t \in [0, 1]\), that is:</p> \[\text{Law}(Z_t) = \text{Law}(X_t), \quad \forall t \in [0, 1].\] <div class="l-page"> <img src="/assets/img/flow_in_out.png" alt="cross" style="max-width:100%;"/> </div> <p><strong>[Transport Cost]</strong></p> <p>The start-end pairs \((Z_0, Z_1)\) from the rectified flow \(\{Z_t\}\) guarantee to yield no larger transport cost than \((X_0, X_1)\), simultaneously for all convex cost functions \(c\):</p> \[\mathbb{E} \left[ c(Z_1 - Z_0) \right] \leq \mathbb{E} \left[ c(X_1 - X_0) \right], \quad \forall \text{convex } c : \mathbb{R}^d \to \mathbb{R}.\] <h2 id="reflow">Reflow</h2> <p>While rectified flows tend to favor straight trajectories, they are not perfectly straight. As shown in Figure, the flow makes turns at intersection points of the interpolation trajectories \(\{X_t\}\). How can we further improve the flow to achieve straighter trajectories and hence speed up inference?</p> <p>A key insight is that the start-end pairs \((Z_0, Z_1)\) generated by rectified flow, called the <strong>rectified coupling</strong> of \((X_0, X_1)\), form a better and “straighter” coupling compared to \((X_0, X_1)\). This is because if we connect \(Z_0\) and \(Z_1\) with a new straight-line interpolation, it would yield fewer intersection points. Hence, training a new rectified flow based on this interpolation would result in straighter trajectories, leading to faster inference.</p> <p>Formally, we apply the RectFlow(·) procedure recursively, yielding a sequence of rectified flows starting from \(\{Z_t^0\} = \{X_t^0\}\):</p> <p><strong>Reflow:</strong></p> \[\{Z_t^{k+1}\} = \texttt{RectFlow}(\texttt{Interp}(Z_0^k, Z_1^k)), \tag{4}\] <p>where \(\text{Interp}(Z_0^k, Z_1^k)\) denotes an interpolation process given \((Z_0^k, Z_1^k)\) as the endpoints. We call \(\{Z_t^k\}\) the k-th rectified flow, or simply <strong>k-rectified flow</strong>, induced from \((X_0, X_1)\).</p> <p>This reflow procedure is proved to “straighten” the paths of rectified flows in the following sense: Define the following measure of straightness of \(\{Z_t\}\):</p> \[S(\{Z_t\}) = \int_0^1 \mathbb{E} \left[ \|Z_1 - Z_0 - \dot{Z}_t\|^2 \right] \mathrm dt,\] <p>where \(S(\{Z_t\})\) is a measure of the straightness of \(\{Z_t\}\), with \(S(\{Z_t\}) = 0\) corresponding to straight paths. Then we have the following for reflow:</p> \[\mathbb{E}_{k \sim \text{Unif}(\{1, \dots, K\})} \left[S(\{Z_t^k\})\right] = \mathcal{O}(1 / K), \tag{5}\] <p>Hence, we would obtain perfectly straight-line dynamics in the limit of \(k \to +\infty\). Note that reflow can begin from any coupling \((X_0, X_1)\), so it provides a general procedure for straightening and thus speeding up any given dynamics while preserving the marginals.</p> <div class="l-page"> <iframe src="/assets/plotly/intro_2rf.html" frameborder="0" scrolling="no" height="630px" width="100%"></iframe> </div>]]></content><author><name>RectifiedFlow Group</name></author><category term="introduction"/><summary type="html"><![CDATA[A Brief Introduction to the Rectified Flow Model]]></summary></entry></feed>