<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://rectifiedflow.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://rectifiedflow.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-12-16T19:59:16+00:00</updated><id>https://rectifiedflow.github.io/feed.xml</id><title type="html">blank</title><subtitle>Everything should be made as simple as possible, but not simpler. </subtitle><entry><title type="html">Natural Euler Samplers</title><link href="https://rectifiedflow.github.io/blog/2024/discretization/" rel="alternate" type="text/html" title="Natural Euler Samplers"/><published>2024-12-10T11:00:00+00:00</published><updated>2024-12-10T11:00:00+00:00</updated><id>https://rectifiedflow.github.io/blog/2024/discretization</id><content type="html" xml:base="https://rectifiedflow.github.io/blog/2024/discretization/"><![CDATA[<div class="hero"> <img src="/assets/img/teaser_post4.png" alt="Rectified Flow Overview" style="width: 100%; max-height: 500px; object-fit: cover; border-radius: 10px; margin-bottom: 20px;"/> </div> <h2 id="equivariance-of-natural-euler-samplers">Equivariance of Natural Euler Samplers</h2> <p>The Euler method can be viewed as approximating ODE trajectories piecewise by straight segments, where each step uses the tangent line at the current point to approximate the local curve. This local straight-line approximation is a natural choice for rectified flow induced by straight interpolation. However, if the rectified flow is induced by a curved interpolation scheme, it may be more natural to use local curve segments—derived from the same interpolation scheme—instead of straight lines. We refer to such approximation schemes as <strong>natural Euler samplers</strong>. The term “natural” is taken from natural gradient descent, to reflect the point that its equivariant under reparameterizations, we describe below.</p> <p>This blog will first introduce the general idea of <strong>natural Euler samplers</strong> and then show that the trajectories of natural Euler samplers are equivariant for pointwise transformable interpolations:</p> <blockquote> <p>If two interpolation processes are pointwise transformable into one another, then the discrete trajectories of their rectified flow (RF) using their corresponding natural Euler samplers are also pointwise transformable using the same mapping functions, provided their time grids are related by a time scaling function \(\tau_t\).</p> </blockquote> <p>This result implies that, when natural Euler samplers are employed, during inference time, <strong>changing the affine interpolation scheme is essentially equivalent to altering the time grid</strong>. Note that this equivalence is <strong>beyond</strong> the continuous-time limit of ODE trajectories. Even after discretization via Euler steps, once the sampled points are transformed accordingly, the resulting discrete points will match numerically — we literally get the same results.</p> <p>For a more comprehensive and rigorous discussion on this topic, please refer to Chapter 5 in the <a href="https://github.com/lqiang67/rectified-flow/tree/main/pdf">Rectified Flow Lecture Notes</a>.</p> <h3 id="natural-euler-samplers">Natural Euler Samplers</h3> <p>Consider an <a href="/blog/2024/interpolation/#general-interpolation-function">interpolation</a> process \(X_t=\texttt I_t(X_0, X_1)\) with a rectified flow velocity field \(v_t\). In the vanilla Euler method, the trajectories of the flow are approximated on a discrete time gird \(\{t_i\}_i\) as:</p> \[\hat z_{t_{i+1}} = \hat z_{t_i} + (t_{i+1} - t_i) v_t(\hat z_{t_i}),\] <p>Here, the solution at each step is locally approxiamated by the straight line tangent to the rectified flow curve at point $\hat z_{t_i}$.</p> <p>In the natural Euler method, we replace the straight line with an <strong>interpolation curve</strong> that is tangent at \(\hat z_{t_i}\). The update rule becomes:</p> \[\hat z_{t_{i+1}} = \texttt I_{t_{i+1}}(\hat x_{0 \mid t_i}, \hat x_{1\mid t_i}),\] <p>where $\hat x_{0 \mid t_i}$ and $\hat x_{1 \mid t_i}$ are derived through equations from the specific interpolation $\texttt I$:</p> \[\begin{cases} \texttt I_{t_i}\bigl(\hat{x}_{0\mid t_i},\hat{x}_{1\mid t_i}\bigr) = \hat{z}_{t_{i+1}}, \\[6pt] \displaystyle \left.\frac{\partial}{\partial t} \texttt I_{t}\bigl(\hat{x}_{0\mid t_i},\hat{x}_{1\mid t_i}\bigr)\right|_{t=t_i} = v_{t_i}\bigl(\hat{z}_{t_i}\bigr). \end{cases}\] <p>This two equations identifies the endpoints \(\hat{x}_{0 \mid t_i}\) and \(\hat{x}_{1\mid t_i}\) of the interpolation curve that passes through \(\hat{z}_{t_i}\) and has a slope \(\partial \hat{z}_{t_i} = v_{t_i}(\hat{z}_{t_i})\) at time \(t_i\), i.e. the interpolation curve is chosen so that it is tangent to the rectified flow at \(\hat{z}_{t_i}\). In the case of affine interpolation, the solution takes a simple closed-form, as it reduces to solving a linear system in two variables.</p> <blockquote> <p>Example 1. Natural Euler Sampler for Spherical Interpolation</p> \[\hat z_{t + \epsilon} =\cos\left(\frac{\pi}{2} \cdot\epsilon\right) \hat z_{t} + \frac{2}{\pi} \sin \left(\frac{\pi}{2} \cdot\epsilon\right) v_t(\hat z_t)\] </blockquote> <blockquote> <p>Example 2. Natural Euler Sampler for DDIM</p> <table> <tbody> <tr> <td>The discretized inference scheme of DDIM is the instance of natural Euler sampler for spherical interpolations satisfying \(\alpha_t^2 + \beta_t^2 = 1\). Note that the inference update of DDIM is written in terms of the expected noise \(\hat{x}_0\vert_t(x) = \mathbb{E}[X_0\vert X_t = x]\). Hence, we also rewrite the update in terms of $$\hat{x}_{0</td> <td>t}$$:</td> </tr> </tbody> </table> \[\begin{aligned} \hat{z}_{t+\epsilon} &amp;= \alpha_{t+\epsilon} \cdot\hat{x}_{1\vert t}(\hat{z}_t) + \beta_{t+\epsilon} \cdot \hat{x}_{0\vert t}(\hat{z}_t) \\ &amp;\overset{*}{=} \alpha_{t+\epsilon} \left( \frac{\hat{z}_t - \beta_t \cdot\hat{x}_{0\vert t}(\hat{z}_t)}{\alpha_t} \right) + \beta_{t+\epsilon} \cdot \hat{x}_{0\vert t}(\hat{z}_t) \\ &amp;= \frac{\alpha_{t+\epsilon}}{\alpha_t} \hat{z}_t + \left( \beta_{t+\epsilon} - \frac{\alpha_{t+\epsilon} \beta_t}{\alpha_t} \right) \hat{x}_{0\vert t}(\hat{z}_t) \end{aligned}\] <p>where in \(\overset{*}{=}\) we used \(\alpha_t \cdot \hat{x}_{1\vert t}(\hat{z}_t) + \beta_t\cdot \hat{x}_{0\vert t}(\hat{z}_t) = \hat{z}_t\). We can slightly rewrite the update as:</p> \[\frac{\hat{z}_{t+\epsilon}}{\alpha_{t+\epsilon}} = \frac{\hat{z}_t}{\alpha_t} + \left( \frac{\beta_{t+\epsilon}}{\alpha_{t+\epsilon}} - \frac{\beta_t}{\alpha_t} \right) \hat{x}_{0\vert t}(\hat{z}_t),\] <p>which exactly matches Equation 13 of <strong>Song et al. [2020a]</strong>.</p> </blockquote> <h3 id="equivalence-of-natural-euler-trajectories">Equivalence of Natural Euler Trajectories</h3> <p>The trajectories obtained from natural Euler samplers are equivariant under pointwise transformations.</p> <blockquote> <p><strong>Theorem 1.</strong> Equivalence of Natural Euler Trajectories</p> <p>Suppose we have two interpolation processes \(\{X_t\}\) and \(\{X_t'\}\) that are contructed from the same couping and related by a pointwise transform \(X_t' = \phi_t(X_{\tau_t})\). Consider the trajectories \(\{\hat{z}_{t_i}\}_i\) and \(\{\hat{z}_{t_i'}'\}_i\), which are generated by applying the natural Euler method to the rectified flows induced by \(\{X_t\}\) and \(\{X_t'\}\), respectively, using time grids \(\{t_i\}\) and \(\{t_i'\}\).</p> <p>If the time grids satisfy \(\tau(t_i') = t_i\) for all \(i\), and the initial conditions align via \(\hat{z}_{t_0}' = \phi(\hat{z}_{t_0})\), then the <strong>discrete</strong> trajectories match under the same transform:</p> \[\hat{z}_{t_i'}' = \phi_{t_i}(\hat{z}_{t_i}) \quad \forall i = 0,1,\ldots\] <p>In particular, applying the natural Euler method to the rectified flow induced by an affine interpolation \(\{X_t'\}\) on a uniform grid \(t_i' = i/n\) is equivalent to applying the standard Euler method to the rectified flow induced by the corresponding straight interpolation \(\{X_t\}\), but using a non-uniform time grid \(t_i = \tau(i/n)\).</p> </blockquote> <p>This theorem strengthens the equivariance result of the rectified flow ODE given in the interpolation blog, as the ODE result can be viewed as the limiting case of the natural Euler method when the step size approaches zero.</p> <p>Let \(\{X_t'\} = T(\{X_t\})\) denote the pointwise transformation, and let \(\texttt{NaturalEuler}(\{Z_t\})\) represent the mapping from a rectified flow ODE to its discrete trajectories produced by the natural Euler sampler. The <strong>equivariance</strong> property can be expressed as:</p> \[\texttt{NaturalEulerRF}(\texttt{Transform}(\{X_t\})) = \texttt{Transform}(\texttt{NaturalEulerRF}(\{X_t\})).\] <p><em>In other words, the natural Euler sampler commutes with pointwise transformations in the same manner as the underlying rectified flow ODE does, providing a stronger, discrete-level form of the equivariance established in continuous time.</em></p> <blockquote> <p>Example 3. Equivalence of Straight Euler and DDIM sampler</p> <p>Since DDIM is the natural Euler sampler under spherical interpolation, and the vanllia Euler method is the natural Euler under the straight interpolation, they yield the same results under proper transform on the time grid. Specifically, the natural Euler sampler on an affine interpolation \(X_t' = \alpha'_t X_1 + \beta'_t X_0\) using a uniform time grid \(t'_i = i/n\) is equivalent to applying the vanilla (straight) Euler method to the straight RF (induced from \(X_t = tX_1 + (1 - t)X_0\)) but with a non-uniform time grid:</p> \[t_i = \frac{\alpha'_{i/n}}{\alpha'_{i/n}+\beta'_{i/n}}\] <p>Conversely, starting from the straight RF and using a vanilla Euler sampler on the time grid \(\{t_i\}\), one can recover the DDIM sampler by finding a time grid \(\{t'_i\}\) that satisfies:</p> \[t_i = \frac{\alpha'_{t_{i'}}}{\alpha_{t_{i'}}'+\beta'_{t_i'}}\] </blockquote> <p>Show Converted</p> <ul> <li>Straight / Spherical with Euler 不一样</li> <li> <p>Num step 足够大，得到相同 coupling</p> </li> <li>Each with natural Euler 是一样的</li> </ul>]]></content><author><name>Runlong Liao</name></author><category term="tutorial"/><summary type="html"><![CDATA[A Pointwise-Transformable Discretization of Flows]]></summary></entry><entry><title type="html">All Flows are One Flow</title><link href="https://rectifiedflow.github.io/blog/2024/interpolation/" rel="alternate" type="text/html" title="All Flows are One Flow"/><published>2024-12-10T10:00:00+00:00</published><updated>2024-12-10T10:00:00+00:00</updated><id>https://rectifiedflow.github.io/blog/2024/interpolation</id><content type="html" xml:base="https://rectifiedflow.github.io/blog/2024/interpolation/"><![CDATA[<div class="hero"> <img src="/assets/img/teaser_post2.png" alt="Rectified Flow Overview" style="width: 100%; max-height: 500px; object-fit: cover; border-radius: 10px; margin-bottom: 20px;"/> </div> <p>This blog introduces the equivalent relationships between rectified flows induced from different affine interpolations, based on Chapter 3 of these <a href="https://github.com/lqiang67/rectified-flow/tree/main/pdf">lecture notes</a>. Related observations and discussion can also be found in <d-cite key="karras2022elucidating,kingma2024understanding,shaulbespoke,gao2025diffusionmeetsflow"></d-cite>.</p> <h2 id="overview">Overview</h2> <p>Given an arbitrary coupling \((X_0, X_1)\) of source distribution \(X_0\sim \pi_0\) and target unknown data distribution \(X_1 \sim \pi_1\), recall that rectified flow learns a ODE</p> \[\mathrm d Z_t = v_t(Z_t) \mathrm d t,\] <p>which, starts from the noise \(Z_0=X_0\), leads to generated data \(Z_1\). This velocity is learned by minimizing the mean square loss from the slope of an interpolation process:</p> \[\min_v \int _0 ^1 \mathbb E \left[\left\| \dot X_t - v_t(X_t)\right\|^2 \right] \mathrm d t,\] <p>where \(\{X_t\} = \{X_t: t\in [0,1]\}\) is an interpolation process connecting \(X_0\) and \(X_1\), and \(\dot X_t\) denotes its time derivative.</p> <p>Theoretically, \(\{X_t\}\) can be any smooth interpolation between source and target distributions. Here, we go over three types of interpolations:</p> <ol> <li> <p><em>Straight interpolation</em>, as used in <d-cite key="liu2022flow,lipman2022flow,albergo2023stochastic"></d-cite>:</p> \[X_t = tX_1 + (1-t) X_0.\] <p>This yields straight lines connecting \(\pi_0\) and \(\pi_1\) at a constant speed \(\dot X_t = X_1 - X_0.\)</p> </li> <li> <p><em>Spherical linear interpolation</em> (<em>slerp</em>), employed by iDDPM <d-cite key="nichol2021improved"></d-cite>:</p> \[X_t = \sin\left(\frac{\pi}{2} t\right)X_1 + \cos\left(\frac{\pi}{2} t\right)X_0,\] <p>which travels along the shortest great-circle arc on a sphere at a constant speed.</p> </li> <li> <p><em>DDIM interpolation</em>,<d-cite key="song2020denoising"></d-cite> a spherical interpolation satisfying \(\alpha_t^2 + \beta_^2 = 1\) but with a non-uniform speed defined by $\alpha_t$:</p> \[X_t = \alpha_t X_1 + \sqrt{1-\alpha_t^2} X_0,\] <p>where \(\alpha_t = \exp\bigl(-\frac{1}{4}a(1-t)^2 - \tfrac{1}{2}b(1-t)\bigr)\), and \(a=19.9,b=0.1\) by default.</p> </li> </ol> <p>Different methods employ these or other interpolation schemes. One might suspect that such choices, by influencing the learned RF velocity, must be finalized during training, because the velocity field could significantly affect inference performance and speed. However, this need not be the case.</p> <p>In this blog, we show that if two interpolation processes are pointwise transformable in a suitable sense, then they would induce essentially <em>equivalent</em> rectified flow dynamics and identical couplings. In particular, all affine interpolations are pointwise transformable to one other. Thus, it suffices to adopt a simple interpolation, such as the straight line \(X_t = t X_1 + (1-t) X_0\), and later recover all affine interpolation through simple transformations. This flexibility shifts our attention to the sampling stage, where different interpolation schemes can be freely adopted, while their differences remain relatively minor during training.</p> <h2 id="point-wisely-transformable-interpolations">Point-wisely Transformable Interpolations</h2> <p>Generally, for any interpolation, we can define pointwise transformability:</p> <blockquote> <p><strong>Definition 1</strong>. Consider any two interpolation processes \(\{X_t : t \in [0,1]\}\) and \(\{X'_t : t \in [0,1]\}\). We say they are <strong>pointwise transformable</strong> if there exist differentiable maps \(\tau: [0,1] \to [0,1]\) and \(\phi: [0,1] \times \mathbb{R}^d \to \mathbb{R}^d\) such that \(\phi_t\) is invertible for every \(t \in [0,1]\) and</p> \[X'_t = \phi_t(X_{\tau_t}) \quad \text{for all } t \in [0,1].\] </blockquote> <p>For Rectified Flows induced from those pointwise transformable interpolations, we have:</p> <blockquote> <p><strong>Theorem 1</strong>. Suppose two interpolations \(\{X_t\}\) and \(\{X'_t\}\) are pointwise transformable and constructed from the same coupling \((X_0, X_1) = (X'_0, X'_1)\). Let \(\{v_t\}\) and \(\{v'_t\}\) be their corresponding Rectified Flow velocity fields, and \(\{Z_t\}\) and \(\{Z'_t\}\) their Rectified Flows, respectively. Let \(\phi\) and \(\tau\) be the transformation maps between \(\{X_t\}\) and \(\{X_t'\}\) with \(\tau_0 = 0\) and \(\tau_1 = 1\). Then:</p> <ol> <li> <p>The same pointwise transformation that maps their interpolations \(\{X_t\} \to\{X'_t\}\) also maps their Recitied Flows \(\{Z_t\}\to\{Z'_t\}\):</p> \[Z'_t = \phi_t(Z_{\tau_t}) \quad \text{for all } t \in [0,1].\] </li> <li> <p>The two rectified flows produce the same coupling:</p> \[(Z_0, Z_1) = (Z'_0, Z'_1).\] </li> <li> <p>Their velocity fields are related by:</p> \[v'_t(x) = \partial_t \phi_t(\phi_t^{-1}(x)) + \bigl(\nabla \phi_t(\phi_t^{-1}(x))\bigr)^\top v_{\tau_t}(\phi_t^{-1}(x)) \dot{\tau}_t. \tag{1}\] </li> </ol> </blockquote> <p>In other words, define \(\{X'_t\} := \texttt{Transform}(\{X_t\})\) to represent the pointwise transformation of the interpolation. The operation \(\texttt{Rectify}(\cdot)\), which maps an interpolation \(\{X_t\}\) to its corresponding rectified flow \(\{Z_t\}\), is <strong>equivariant</strong> under pointwise transformations:</p> \[\texttt{Rectify}(\texttt{Transform}(\{X_t\})) = \texttt{Transform}(\texttt{Rectify}(\{X_t\})).\] <h3 id="equivalence-of-affine-interpolations">Equivalence of Affine Interpolations</h3> <p>In practice, one often considers interpolations of the form</p> \[X_t = \alpha_t X_1 + \beta_t X_0,\] <p>where $\alpha_t$ and $\beta_t$ are monotonic on $t\in[0,1]$ and satisfy the boundary conditions:</p> \[\alpha_0=\beta_1=0, \quad \alpha_1 = \beta_0 = 1.\] <p>All such interpolations are <em>affine</em>. For this class of interpolations, the transformation maps \(\phi\) and \(\tau\) reduce to scalar transformations. In fact, <strong>all affine interpolations are pointwise transformable</strong> by appropriately scaling both time and the input. Consequently, their corresponding rectified flows can also be related through the same pointwise transformations, ultimately producing the same rectified couplings. This result aligns with observations made by other authors<d-cite key="karras2022elucidating,kingma2024understanding,shaulbespoke,gao2025diffusionmeetsflow"></d-cite>.</p> <blockquote> <p><strong>Proposition 1</strong>. Consider two affine interpolation processes derived from the same coupling \((X_0, X_1)\): \(X_t = \alpha_t X_1 + \beta_t X_0 \quad \text{and} \quad X_t' = \alpha_t' X_1 + \beta_t' X_0.\)</p> <p>Then there exist scalar functions \(\tau_t\) and \(\omega_t\) such that</p> \[X_t' = \frac{1}{\omega_t} X_{\tau_t}, \quad \forall t \in [0,1],\] <p>where \(\tau_t\) and \(\omega_t\) are determined by solving</p> \[\frac{\alpha_{\tau_t}}{\beta_{\tau_t}} = \frac{\alpha'_t}{\beta'_t}, \quad \omega_t = \frac{\alpha_{\tau_t}}{\alpha'_t} = \frac{\beta_{\tau_t}}{\beta'_t}, \quad \forall t \in (0, 1) \tag{2}\] <p>under the boundary conditions</p> \[\omega_0 = \omega_1 = 1, \quad \tau_0 = 0, \quad \tau_1 = 1.\] <p>Uniqueness of the solution \((\tau_t, \omega_t)\) follows because \(\alpha'_t/\beta'_t \geq 0\) and \(\alpha_t/\beta_t\) is strictly increasing for \(t \in [0,1]\). Thus, for any two affine interpolations of the same coupling, there is a unique pointwise transformation that relates them.</p> </blockquote> <p>In practice, the time scaling function \(\tau_t\) can be determined in two ways. For simpler cases, \(\tau_t\) can be derived analytically. For more complex scenarios, a <a href="https://github.com/lqiang67/rectified-flow/blob/main/rectified_flow/flow_components/interpolation_convertor.py">simple binary search</a> can be employed to approximate \(\tau_t\). The figure below illustrates the \(\tau\) and \(\phi\) transformations that convert DDIM to spherical interpolation, and straight interpolation to spherical. Note that when converting DDIM to spherical interpolation, the only difference is in the time scaling—\(\omega_t\) remains constant at \(1\).</p> <div class="l-body-outset" style="display: flex;"> <iframe src="/assets/plotly/interp_tau_ddim_spherical.html" frameborder="0" scrolling="no" height="430px" width="49%"></iframe> <iframe src="/assets/plotly/interp_tau_straight_spherical.html" frameborder="0" scrolling="no" height="430px" width="49%"></iframe> </div> <p>Substituting the notion of \(\tau\) and \(\omega\) into Theorem 1, we have:</p> <blockquote> <p><strong>Example 1.</strong> Converting straight interpolation into affine one.</p> <p>Consider the straight interpolation \(X_t=tX_1 + (1-t)X_0\) for which \(\alpha_t=t\) and \(\beta_t=1-t\). We seek to transform this interpolation into another affine interpolation \(X'_t = \alpha'_t X_1 + \beta'_t X_0.\) Solving the equations</p> \[\omega_t = \frac{\tau_t}{\alpha'_t} = \frac{1-\tau_t}{\beta'_t}\] <p>yields</p> \[\tau_t = \frac{\alpha'_t}{\alpha'_t + \beta_t'}, \quad \omega_t = \frac{1}{\alpha_t' + \beta_t'}\] <p>Substituting these into the velocity fields, we have</p> \[v'_t(x) = \frac{\dot{\alpha}'_t \beta'_t - \alpha'_t \dot{\beta}'_t}{\alpha'_t + \beta'_t} \cdot v_{\tau_t}(\omega_t x) \;+\; \frac{\dot{\alpha}'_t + \dot{\beta}'_t}{\alpha'_t + \beta'_t} \cdot x.\] </blockquote> <h3 id="converting-pretrained-rf-velocity">Converting Pretrained RF Velocity</h3> <blockquote> <p><strong>Proposition 2</strong>. Assume \(\{X_t\}\) and \(\{X'_t\}\) are two affine interpolations:</p> <ul> <li>Their respective rectified flows \(\{Z_t\}\) and \(\{Z'_t\}\) satisfy:</li> </ul> \[Z'_t = \omega_t^{-1} Z_{\tau_t}, \quad \forall t \in [0, 1].\] <ul> <li>Their rectified couplings are equivalent:</li> </ul> \[(Z_0, Z_1) = (Z'_0, Z'_1).\] <ul> <li>Their RF velocity fields \(v_t\) and \(v'_t\) satisfy:</li> </ul> \[v'_t(x) = \frac{1}{\omega_t} \left( \dot{\tau}_t v_{\tau_t}(\omega_t x) - \dot{\omega}_t x \right). \tag{3}\] </blockquote> <div class="l-body-outset"> <iframe src="/assets/plotly/interp_convert_200step.html" frameborder="0" scrolling="no" height="630px" width="100%"></iframe> </div> <p>In the figure above, we start with a pretrained RF model that uses a straight interpolation and convert it into a spherical RF. We then apply Euler sampling to both RFs. Although the two RFs follow entirely different trajectories, they both reach the same endpoint \(Z_1\).</p> <div class="l-body-outset"> <iframe src="/assets/plotly/interp_convert_10step.html" frameborder="0" scrolling="no" height="630px" width="100%"></iframe> </div> <p>However, as the number of sampling steps decreases to as few as \(10\), the endpoints \(Z_1\) and \(Z_1'\) begin to diverge, the diffences between them becomes more pronounced with fewer steps. This indicates that, although different affine interpolation schemes theoretically produce the same rectified coupling \((Z_0, Z_1)\), their intermediate trajectories \(\{Z_t\}\) are not the same. When solving the ODEs, discretization errors accumulate along these trajectories. <strong>Straighter trajectories are generally preferable</strong> because they tend to reduce discretization errors and yield more accurate results.</p> <p>Owing to the transformation relationships described above, it is possible to change the interpolation scheme of a pretrained model without retraining. This approach allows one to select a scheme that produces straighter trajectories \(\{Z_t\}\), thus improving the performance of sampling.</p> <h2 id="implications-on-loss-functions">Implications on Loss Functions</h2> <p>Assume that we have trained a model \(\hat{v}_t\) for the RF velocity field \(v_t\) under an affine interpolation. Using the formulas from the previous section, we can convert it to a model \(\hat{v}'_t\) for \(v'_t\) corresponding to a different interpolation scheme at the post-training stage. This raises the question of what properties the converted model \(\hat{v}'_t\) may have compared to the models trained directly on the same interpolation, and whether it suffers from performance degradation due to the conversion.</p> <p>We show here that using different affine interpolation schemes during training is equivalent to applying <strong>different time-weighting</strong> in the loss function, as well as an affine transform on the parametric model. Unless \(\omega_t\) and \(\tau_t\) are highly singular, the conversion does not necessarily degrade performance.</p> <p>Specifically, assume we have trained a parametric model \(v_t(x; \theta)\) to approximate the RF velocity \(v_t\) of interpolation \(X_t = \alpha_t X_1 + \beta_t X_0\), using the mean square loss:</p> \[\mathcal L(\theta) = \int_0^1 \mathbb E\left[ \eta_t \left \| \dot X_t - v_t(X_t;\theta)\right\|^2 \right] \mathrm dt \tag{4}\] <p>After training, we may convert the obtained model \(v_t(x; \theta)\) to an approximation of \(v'_t\) of a different interpolation \(X'_t = \alpha_t' X_1 + \beta_t' X_0\) via:</p> \[v'_t(x; \theta) = \frac{\dot{\tau}_t}{\omega_t} v_{\tau_t}(\omega_t x; \theta) - \frac{\dot{\omega}_t}{\omega_t} x,\] <p>On the other hand, if we train \(v'_t(x; \theta)\) directly to approximate \(v'_t\) of interpolation \(X'_t = \alpha'_t X_1 + \beta'_t X_0\), the loss function is:</p> \[\mathcal L'(\theta) = \int_0^1 \mathbb{E} \left[ \eta'_t \left\| \dot{X}'_t - v'_t(X'_t; \theta) \right\|^2 \right] \mathrm dt \tag{5}\] <p>When matching the loss \((4)\) and \((5)\), we find that these two training schemes are identical, except for the following time-weighting and reparametrization relationship:</p> \[\eta'_t = \frac{\omega_t^2}{\dot{\tau}_t} \eta_{\tau_t}, \quad v'_t(x; \theta) = \frac{\dot{\tau}_t}{\omega_t} v_{\tau_t}(\omega_t x; \theta) - \frac{\dot{\omega}_t}{\omega_t} x. \tag{6}\] <p>In other words, <strong>training with different interpolation schemes simply only introduces different training time weights and model parameterizations.</strong></p> <blockquote> <p><strong>Example 2. Loss from Straight to Affine</strong></p> <p>Consider the straight interpolation \(X_t = t X_1 + (1 - t) X_0\) with \(\alpha_t = t\) and \(\beta_t = 1 - t\), alongside another affine interpolation \(X_t' = \alpha_t' X_1 + \beta_t' X_0\).</p> <p>Suppose we have trained the \(v_t\) for \(X_t\) with a time weight \(\eta_t\), then \(v_t'\) converted from \(v_t\) is equivalent to the RF trained with the parametrization in \((6)\), and another time weight:</p> \[\eta_t' = \frac{\omega_t^2}{\tau_t'} \eta_{\tau_t} = \frac{1}{\dot{\alpha}_t' \beta_t' - \alpha_t' \dot{\beta}_t'} \eta_{\tau_t},\] <p>Here, we substitute the relationships derived in Example 1 into \((6)\).</p> </blockquote> <h3 id="straight-vs-spherical-same-train-time-weight">Straight vs Spherical: Same Train Time Weight</h3> <p>Consider the straight interpolation \(X_t = tX_1 + (1 - t)X_0\) and an affine interpolation \(X_t' = \alpha_t' X_1 + \beta_t' X_0\). If</p> \[\dot \alpha_t' \beta_t' - \alpha_t \beta_t' = \text{const},\] <p>then we have \(\eta_t' \propto \eta_{\tau_t}\), meaning that the training time weighting remains constant scale across the time.</p> <p>For example, spherical interpolation satisfies these conditions:</p> <blockquote> <p><strong>Example 3.</strong> Losses for Straight vs. Spherical Interpolation</p> <p>Consider the spherical interpolation \(X'_t = \sin\left(\frac{\pi t}{2}\right)X_1 + \cos\left(\frac{\pi t}{2}\right)X_0\), we have</p> \[\eta'_t = \frac{2}{\pi} \eta_{\tau_t}, \quad \tau_t = \frac{\tan\left(\frac{\pi t}{2}\right)}{\tan\left(\frac{\pi t}{2}\right)+1}.\] <p>In this case, training \(v_t\) with the straight interpolation using a uniform weight \(\eta_t = 1\) is equivalent to training \(v'_t\) with the spherical interpolation, also with a uniform weight \(\eta'_t = 2 /\pi\). The sole difference is a reparameterization of the model:</p> \[v'_t(x, \theta) = \frac{\pi \omega_t}{2} \left( v_{\tau_t}(\omega_t x; \theta) + \left( \cos\left(\frac{\pi t}{2}\right) - \sin\left(\frac{\pi t}{2}\right) \right) x \right),\] <p>where \(\omega_t = (\sin(\frac{\pi t}{2}) + \cos(\frac{\pi t}{2}))^{-1}\) is bounded within \([1/\sqrt{2}, 1]\). This reparameterization does not significantly influence performance. As we’ll see in practice, choosing between straight or spherical interpolation makes <strong>little difference</strong> in training outcomes.</p> </blockquote> <div class="l-body-outset"> <iframe src="/assets/plotly/interp_convert_double_rf.html" frameborder="0" scrolling="no" height="630px" width="100%"></iframe> </div> <p>In the figure above, we compare two RF models: one trained with straight interpolation and another with spherical interpolation. We then convert the straight RF into the spherical one. As Example 3 suggests, we can see that the two trajectories are nearly identical, except for minor divergence near \(t=1\) due to accumulated numerical errors.</p> <div class="l-body-outset"> <iframe src="/assets/plotly/interp_match_time_weight.html" frameborder="0" scrolling="no" height="630px" width="100%"></iframe> </div> <p>In this figure, we reparameterize the straight RF into \(v'_t\) and train it with spherical interpolation. This time, we find that the resulting trajectories align almost perfectl, since the weight and parametrization match exactly.</p>]]></content><author><name>Runlong Liao</name></author><category term="tutorial"/><summary type="html"><![CDATA[Affine Interpolations Result in Equivalent Rectified Flows]]></summary></entry><entry><title type="html">Stochastic Sampler: Langevin as Guardrail</title><link href="https://rectifiedflow.github.io/blog/2024/samplers/" rel="alternate" type="text/html" title="Stochastic Sampler: Langevin as Guardrail"/><published>2024-12-10T10:00:00+00:00</published><updated>2024-12-10T10:00:00+00:00</updated><id>https://rectifiedflow.github.io/blog/2024/samplers</id><content type="html" xml:base="https://rectifiedflow.github.io/blog/2024/samplers/"><![CDATA[<div class="hero"> <img src="/assets/img/teaser_post3.png" alt="Rectified Flow Overview" style="width: 100%; max-height: 500px; object-fit: cover; border-radius: 10px; margin-bottom: 20px;"/> </div> <h2 id="overview">Overview</h2> <p>In this blog, we will elaborate on, given a pretrained flow model, how does a stochastic sampler (like DDPM) relate to a deterministic sampler as conducting simple Euler steps in rectified flow. In particular, we will show that one can convert any deterministic sampler to its corresponding stochastic counterparts, and vice versa. The main difference is that the stochastic sampler has an extra Langevin dynamics term, which could potentially help correct the discretization error from cumulative Euler steps. For a more comprehensive and rigorous discussion on this topic, please refer to Chapter 5 in the <a href="https://github.com/lqiang67/rectified-flow/tree/main/pdf">Rectified Flow Lecture Notes</a>.</p> <h2 id="stochastic-solvers-guardrails-for-generative-models">Stochastic Solvers: Guardrails for Generative Models</h2> <p>For an introduction to rectified flow and its foundational concepts, check out our earlier post <a href="https://rectifiedflow.github.io/blog/2024/intro/">here</a><d-cite key="Liu2022FlowSA"></d-cite></p> <p>When working with generative models, particularly those using rectified flow, errors can accumulate over time as we solve the ODE $dZ_t = v_t(Z_t) dt$. These errors arise from model approximations and numerical discretization, leading to drift between the estimated distribution $\hat{Z}_t$ and the true distribution $\rho_t$. Here, $\rho_t$ represents the smooth density function of the true distribution $X_t$. This problem is exacerbated in low-density regions rarely sampled during training, where model inaccuracies are more pronounced.</p> <p>To address this, <strong>stochastic solvers</strong> can replace deterministic ODE solvers during inference. By introducing stochastic dynamics, we can dynamically correct these errors, ensuring the estimated distribution stays aligned with the true one.</p> <h4 id="langevin-dynamics-as-a-guardrail">Langevin Dynamics as a Guardrail</h4> <p>One common and promising approach is to use <strong>Langevin dynamics</strong> as a corrective mechanism. At each timestep $t$, a short segment of Langevin dynamics is applied to adjust $\hat{Z}_t$ toward $\rho_t$:</p> \[dZ_{t, \tau} = \sigma_t^2 \nabla \log \rho_t(Z_{t, \tau}) d\tau + \sqrt{2}\sigma_t dW_\tau, \quad \tau \geq 0\] <p>Here, $\sigma_t$ controls the noise level, and $\nabla \log \rho_t$ adjusts the drift toward high-probability regions of $\rho_t$. While simulating Langevin dynamics until equilibrium would align the distribution perfectly, this is often unnecessary. A single step of Langevin dynamics can sufficiently reduce drift when $\hat{Z}_t$ is already close to $\rho_t$.</p> <p>To streamline this process, Langevin corrections can be integrated directly into the rectified flow updates, resulting in a combined stochastic differential equation (SDE):</p> \[d\tilde{Z}_t = \underbrace{v_t(\tilde{Z}_t) dt}_{\text{Rectified Flow}} + \underbrace{\sigma_t^2 \nabla \log \rho_t(\tilde{Z}_t) dt + \sqrt{2} \sigma_t dW_t}_{\text{Langevin Dynamics}}, \quad \tilde{Z}_0 = Z_0\] <p>This combined SDE achieves two goals:</p> <ol> <li>The <strong>rectified flow</strong> drives the generative process forward as intended.</li> <li>The <strong>Langevin component</strong> acts as a negative feedback loop, correcting distributional drift without bias when $\tilde{Z}_t$ and $\rho_t$ are already well aligned.</li> </ol> <h4 id="why-it-works">Why It Works</h4> <p>If the simulation is accurate, Langevin dynamics naturally stay in equilibrium, meaning they won’t alter the distribution unnecessarily. But when deviations occur, this mechanism gently nudges the estimate back on track, providing robustness to the inference process.</p> <p>By incorporating stochastic solvers like these, we create a dynamic correction framework that enhances the stability and accuracy of generative models, ensuring that outputs remain high-quality and faithful to the intended distributions.</p> <p><strong>Score Function Visualization:</strong> In the next toy example, we’ll visualize the score function $\nabla \log \rho_t$. This will help you see how these small corrective forces guide the samples toward the right regions, improving upon what a purely deterministic approach can achieve.</p> <div class="l-body"> <img src="/assets/img/score_function_on_sde_traj.png" alt="cross" style="max-width:100%;"/> </div> <p>As shown here, the score function ($\nabla \log \rho_t$) points samples toward regions of higher density. This corrects the trajectories from the original predicted velocity, providing a drifting force that helps ensure samples converge to the most probable areas of the target distribution.</p> <h2 id="sdes-with-gaussian-initial-distributions">SDEs with Gaussian Initial Distributions</h2> <p>Previously, we demonstrated that for a rectified flow using interpolation $X_t = \alpha_t X_1 + \beta_t X_0$, two processes can achieve the same target distribution $\pi_1$:</p> <ul> <li> <p><strong>The ODE process:</strong></p> \[d Z_t = v_t(Z_t)dt\] </li> <li> <p><strong>The SDE process:</strong></p> \[d Z_t = v_t(Z_t)dt + \sigma_t^2 \nabla \log \rho_t(Z_t) dt + \sqrt{2} \sigma_t d W_t,\] </li> </ul> <p>The <strong>Euler method</strong> is commonly used to discretize the ODE process, yielding the following update rule:</p> \[\hat{Z}_{t + \Delta t} = \hat{Z}_t + \Delta t \cdot v(\tilde{Z}_t)\] <p>Similarly, the SDE process can be discretized. When introducing a noise level $\sigma_t$ at time $t$, the update step becomes:</p> \[\hat{Z}_{t + \Delta t} = \hat{Z}_t + \Delta t \cdot (v(\hat{Z}_t) + \frac{\sigma_t^2}{\beta_t \lambda_t} (\alpha_t v(\hat{Z}_t) - \dot{\alpha}_t \hat{Z}_t)) + \sqrt{2} \sigma_t \xi_t,\] <p>Here:</p> <ul> <li>$\lambda_t = \dot{\alpha}_t \beta_t - \alpha_t \dot{\beta}_t$</li> <li>$\xi$ is random Gaussian noise sampled from $\mathcal{N}(0, I)$.</li> </ul> <p>This update rule explicitly incorporates the Langevin dynamics term, derived in detail in Chapter 5.3 of the <a href="TBD: insert link">Rectified Flow Lecture Notes</a>.</p> <p>In practice, the <code class="language-plaintext highlighter-rouge">AffineInterpSolver</code> in our <a href="https://github.com/lqiang67/rectified-flow">Rectified Flow repository</a> provides an efficient way to compute the score function. This solver supports scenarios where at least two of the variables $(x_0, x_1, x_t, \dot{x}_t)$ are known, enabling the estimation of the others.</p>]]></content><author><name>Xixi Hu</name></author><category term="tutorial"/><summary type="html"><![CDATA[Connections between Deterministic and Stochastic Samplers]]></summary></entry><entry><title type="html">Rectified Flow: An Introduction</title><link href="https://rectifiedflow.github.io/blog/2024/intro/" rel="alternate" type="text/html" title="Rectified Flow: An Introduction"/><published>2024-12-06T10:00:00+00:00</published><updated>2024-12-06T10:00:00+00:00</updated><id>https://rectifiedflow.github.io/blog/2024/intro</id><content type="html" xml:base="https://rectifiedflow.github.io/blog/2024/intro/"><![CDATA[<div class="hero"> <img src="/assets/img/teaser_post1.png" alt="Rectified Flow Overview" style="width: 100%; max-height: 500px; object-fit: cover; border-radius: 10px; margin-bottom: 20px;"/> </div> <h2 id="overview">Overview</h2> <p>This blog provides a brief introduction to rectified flow, based on Chapter 1 of these <a href="https://github.com/lqiang67/rectified-flow/tree/main/pdf">lecture notes</a>. For more introduction, please refer to the original papers<d-cite key="liu2022flow"></d-cite>, <d-cite key="liu2022rectified"></d-cite> and these <a href="https://www.cs.utexas.edu/~lqiang/rectflow/html/intro.html">blogs</a>.</p> <h2 id="odes">ODEs</h2> <p>Generative modeling can be formulated as finding a computational procedure that transforms a noise distribution, denoted by \(\pi_0\), into an unknown data distribution \(\pi_1\) observed through data. In flow models, this procedure is represented by an ordinary differential equation (ODE):</p> \[\dot{Z}_t = v_t(Z_t), \quad \forall t \in [0,1], \quad \text{starting from } Z_0 \sim \pi_0, \tag{1}\] <p>where \(\dot{Z}_t = \mathrm dZ_t / \mathrm dt\) denotes the time derivative, and the velocity field \(v_t(x) = v(x, t)\) is a learnable function to be estimated to ensure that \(Z_1\) follows the target distribution \(\pi_1\) when starting from \(Z_0 \sim \pi_0\). In this case, we say that the stochastic process \(Z = \{Z_t\}\) provides an (ODE) transport from \(\pi_0\) to \(\pi_1\).</p> <p>It is important to note that, in all but trivial cases, there exist <em>infinitely many</em> ODE transports from \(\pi_0\) to \(\pi_1\), provided that at least one such process exists. Thus, it is essential to be clear about which types of ODEs we should prefer.</p> <p>One option is to favor ODEs that are easy to solve at inference time. In practice, the ODEs are approximated using numerical methods, which typically construct piecewise linear approximations of the ODE trajectories. For instance, a common choice is Euler’s method:</p> \[\hat{Z}_{t+\epsilon} = \hat{Z}_t + \epsilon v_t(\hat{Z}_t), \quad \forall t \in \{0, \epsilon, 2\epsilon, \dots, 1\}, \tag{2}\] <p>where \(\epsilon &gt; 0\) is a step size. Varying the step size \(\epsilon\) introduces a trade-off between accuracy and computational cost: smaller \(\epsilon\) yields high accuracy but incurs a larger number of calculation steps. Therefore, we should seek ODEs that can be approximated accurately even with large step sizes.</p> <div class="l-body"> <iframe src="/assets/plotly/intro_euler_approximation_with_arrows.html" frameborder="0" scrolling="no" height="480px" width="100%"></iframe> </div> <p>The ideal scenario arises when the ODE follows straight-line trajectories, in which case Euler approximation yields zero discretization error regardless of the choice of step sizes. In such cases, the ODE, up to time reparameterization, should satisfy:</p> \[Z_t = t Z_1 + (1 - t) Z_0, \quad \implies \quad \dot{Z}_t = Z_1 - Z_0.\] <p>These ODEs, known as straight transports, enable fast generative models that can be simulated in a single step. We refer to the resulting pair \((Z_0, Z_1)\) as a straight coupling of \(\pi_0\) and \(\pi_1\). In practice, perfect straightness may not be achievable, but a goal we can aim for is to make the ODE trajectories as straight as possible to maximize computational efficiency.</p> <h2 id="rectified-flow">Rectified Flow</h2> <p>To construct a flow transporting \(\pi_0\) to \(\pi_1\), let us assume that we are given an arbitrary coupling \((X_0, X_1)\) of \(\pi_0\) and \(\pi_1\), from which we can obtain empirical draws. This can be simply the independent coupling with law \(\pi_0 \times \pi_1\), as is common in practice when we have access to independent samples from \(\pi_0\) and \(\pi_1\). The idea is that we are going to take \((X_0, X_1)\) and convert it to a better coupling generated by an ODE model, and optionally, we can go further to iteratively repeat this process to further enhance desired properties, such as straightness.</p> <p>Rectified flow works in the following ways:</p> <ul> <li> <p><strong>Build Interpolation:</strong></p> <p>We build an interpolation process \(\{X_t\} = \{X_t : t \in [0, 1]\}\) that smoothly interpolates between \(X_0\) and \(X_1\). Given the perference on straight trajectories, there seems no immediate reason to not use the canonical straight-line interpolation: \(X_t = t X_1 + (1 - t) X_0.\)</p> <p>Here the interpolation \(\{X_t\}\) is a stochastic process generated in an <strong>“anchor-and-bridge”</strong> way: we first sample the endpoints \(X_0\) and \(X_1\) and then sample the intermediate trajectory connecting them. Such processes are also known as bridge processes, where the intermediate values of \(X_t\) smoothly “bridge” the distribution between \(X_0\) and \(X_1\).</p> </li> </ul> <div class="l-body"> <iframe src="/assets/plotly/intro_straight_interp.html" frameborder="0" scrolling="no" height="630px" width="100%"></iframe> </div> <ul> <li> <p><strong>Marginal Matching:</strong></p> <p>By construction, the marginal distributions of \(X_0\) and \(X_1\) match the target distributions \(\pi_0\) and \(\pi_1\) through the interpolation process \(\{X_t\}\). However, \(\{X_t\}\) is not a causal ODE process like \(\dot{Z}_t = v_t(Z_t)\), which generate the output \(Z_1\) by evolving forward in time from \(Z_0\). Instead, generating \(X_t\) requires knowledge of both \(X_0\) and \(X_1\), rather than evolving solely from \(X_0\) as \(t\) increases.</p> <p>This issue can be resolved if we can convert \(\{X_t\}\) somehow into a causal ODE process while preserving the marginal distributions of \(X_t\) at each time \(t\). Note that since we only care about the output \(X_1\), we only need to match the marginal distributions. There is no need to match the trajectory-wise joint distribution.</p> </li> </ul> <p>Perhaps surprisingly, marginal matching can be achieved by simply training the velocity field \(v_t\) of the ODE model \(\dot{Z}_t = v_t(Z_t)\) to match the slope \(\dot{X}_t\) of the interpolation process via:</p> \[\min_v \int_0^1 \mathbb{E} \left[ \left\| \dot{X}_t - v_t(X_t) \right\|^2 \right] \mathrm dt. \tag{3}\] <p>The theoretical minimum is achieved by:</p> \[v_t^*(x) = \mathbb{E} \left[ \dot{X}_t \mid X_t = x \right],\] <p>which is the condition expectation of the slope \(\dot{X}_t\) for all the interpolation trajectories passing through a given point \(X_t = x\).</p> <h3 id="expectation-notation">Expectation Notation</h3> <p>Recall that a stochastic process \(X_t = X(t, \omega)\) is a measurable function of time \(t\) and a random seed \(\omega\) (with, say, distribution \(\mathbb{P}\)). In the case above, the random seed \(\omega = (X_0, X_1)\) represents the endpoints. The slope is given by \(\dot{X}_t = \partial_t X(t, \omega)\), which is also a function of the same random seed. The expectation in the loss, written in full, is</p> \[\mathbb{E}_{\omega \sim \mathbb{P}} \left[ \left\| \partial_t X(t, \omega) - v_t(X(t, \omega)) \right\|^2 \right].\] <p>In writing, we often omit the random seed. Whenever we take the expectation, it averages out all random sources inside the brackets except for those explicitly included in the conditioning.</p> <h3 id="definition-rectified-flow">Definition: Rectified Flow</h3> <p>For any time-differential stochastic process \(\{X_t\} = \{X_t : t \in [0, 1]\}\), we call the ODE process:</p> \[\dot{Z}_t = v_t^*(Z_t) \quad \text{with} \quad v_t^*(x) = \mathbb{E} \left[ \dot{X}_t \mid X_t = x \right],\] <p>and initialization \(Z_0 = X_0\) the <strong>rectified flow</strong> induced by \(\{X_t\}\). We denote it as:</p> \[\{Z_t\} = \text{RectFlow}(\{X_t\}).\] <p>With the straight interpolation \(X_t = t X_1+(1-t)X_0\), we have \(\dot{X}_t = X_1 - X_0\) by taking the derivative of \(X_t\) with respect to \(t\). It yields:</p> \[\min_v \int_0^1 \mathbb{E} \left[ \| \dot{X}_t - v_t(X_t) \|^2 \right] \mathrm dt, \quad X_t = t X_1 + (1 - t) X_0.\] <p>In practice, the optimization in (3) can be efficiently solved even for large AI models when \(v\) is parameterized as modern deep neural nets. This is achieved by leveraging off-the-shelf optimizers with stochastic gradients, computed by drawing pairs \((X_0, X_1)\) from data, sampling \(t\) uniformly in \([0, 1]\), and then computing the corresponding \((X_t, \dot{X}_t)\) using the interpolation formula.</p> <div class="l-body"> <iframe src="/assets/plotly/intro_1rf.html" frameborder="0" scrolling="no" height="630px" width="100%"></iframe> </div> <p>This figure illustrates the intuition. In the interpolation process \(\{X_t\}\), different trajectories may have intersecting points, resulting in multiple possible values of \(\dot{X}_t\) associated with the same point \(X_t\) due to uncertainty about the originating trajectory (see the straight interpolation figure). However, by the definition of an ODE \(\dot{Z}_t = v_t^*(Z_t)\), the update direction \(\dot{Z}_t\) at each point \(Z_t\) is uniquely determined by \(Z_t\), making it impossible for different trajectories of \(\{Z_t\}\) to intersect and then diverge. At these intersection points of \(\{X_t\}\), where \(\dot{X}_t\) is stochastic and non-unique, \(Z_t\) “derandomizes” the update direction by following the conditional expectation:</p> \[v_t^*(X_t) = \mathbb{E} \left[ \dot{X}_t \mid X_t \right],\] <p>thus providing the unique update direction required by ODEs.</p> <p>What makes rectified flow \(\{Z_t\}\) useful is that it preserves the marginal distributions of \(\{X_t\}\) at each point while resulting in a “better” coupling \((Z_0, Z_1)\) in terms of optimal transport:</p> <h3 id="1-marginal-preservation">1. Marginal Preservation</h3> <p>The \(\{X_t\}\) and its rectified flow \(\{Z_t\}\) share the same marginal distributions at each time \(t \in [0, 1]\), that is:</p> \[\text{Law}(Z_t) = \text{Law}(X_t), \quad \forall t \in [0, 1],\] <p>where \(\text{Law}(X_t)\) denotes the probability distribution (or law) of random variable \(X_t\).</p> <div class="l-body"> <img src="/assets/img/flow_in_out.png" alt="cross" style="max-width:100%;"/> </div> <h3 id="2-transport-cost">2. Transport Cost</h3> <p>The start-end pairs \((Z_0, Z_1)\) from the rectified flow \(\{Z_t\}\) guarantee to yield no larger transport cost than \((X_0, X_1)\), simultaneously for all convex cost functions \(c\):</p> \[\mathbb{E} \left[ c(Z_1 - Z_0) \right] \leq \mathbb{E} \left[ c(X_1 - X_0) \right], \quad \forall \text{convex } c : \mathbb{R}^d \to \mathbb{R}.\] <h2 id="reflow">Reflow</h2> <p>While rectified flows tend to favor straight trajectories, they are not perfectly straight. As shown in Figure, the flow makes turns at intersection points of the interpolation trajectories \(\{X_t\}\). How can we further improve the flow to achieve straighter trajectories and hence speed up inference?</p> <p>A key insight is that the start-end pairs \((Z_0, Z_1)\) generated by rectified flow, called the <strong>rectified coupling</strong> of \((X_0, X_1)\), form a better and “straighter” coupling compared to \((X_0, X_1)\). This is because if we connect \(Z_0\) and \(Z_1\) with a new straight-line interpolation, it would yield fewer intersection points. Hence, training a new rectified flow based on this interpolation would result in straighter trajectories, leading to faster inference.</p> <p>Formally, we apply the \(\texttt{RectFlow}(·)\) procedure recursively, yielding a sequence of rectified flows starting from \((Z_0^0, X_1^0) = (X_0, X_1)\):</p> \[\texttt{Reflow:} \quad \quad \{Z_t^{k+1}\} = \texttt{RectFlow}(\texttt{Interp}(Z_0^k, Z_1^k)),\] <p>where \(\text{Interp}(Z_0^k, Z_1^k)\) denotes an interpolation process given \((Z_0^k, Z_1^k)\) as the endpoints. We call \(\{Z_t^k\}\) the \(k\)-th rectified flow, or simply the <strong>\(k\)-rectified flow</strong>, induced from \((X_0, X_1)\).</p> <p>This reflow procedure is proved to “straighten” the paths of rectified flows in the following sense: Define the following measure of straightness of \(\{Z_t\}\):</p> \[S(\{Z_t\}) = \int_0^1 \mathbb{E} \left[ \|Z_1 - Z_0 - \dot{Z}_t\|^2 \right] \mathrm dt,\] <p>where \(S(\{Z_t\})\) is a measure of the straightness of \(\{Z_t\}\), with \(S(\{Z_t\}) = 0\) corresponding to straight paths. Then it can be found in paper<d-cite key="liu2022flow"></d-cite> that</p> \[\mathbb{E}_{k \sim \text{Unif}(\{1, \dots, K\})} \left[S(\{Z_t^k\})\right] = \mathcal{O}(1 / K),\] <p>which suggests that the average of \(S(\{Z_t^k\})\) in the first \(K\) steps decay with an \(\mathcal{O}(1 / K)\) rate.</p> <p>Hence, we would obtain perfectly straight-line dynamics in the limit of \(k \to +\infty\). Note that reflow can begin from any coupling \((X_0, X_1)\), so it provides a general procedure for straightening and thus speeding up any given dynamics while preserving the marginals.</p> <div class="l-body"> <iframe src="/assets/plotly/intro_2rf.html" frameborder="0" scrolling="no" height="630px" width="100%"></iframe> </div>]]></content><author><name>Runlong Liao</name></author><category term="introduction"/><summary type="html"><![CDATA[A First Introduction to Rectified Flow]]></summary></entry></feed>