<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://rectifiedflow.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://rectifiedflow.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-12-13T18:04:37+00:00</updated><id>https://rectifiedflow.github.io/feed.xml</id><title type="html">blank</title><subtitle>Everything should be made as simple as possible, but not simpler. </subtitle><entry><title type="html">Natural Euler Samplers</title><link href="https://rectifiedflow.github.io/blog/2024/discretization/" rel="alternate" type="text/html" title="Natural Euler Samplers"/><published>2024-12-10T11:00:00+00:00</published><updated>2024-12-10T11:00:00+00:00</updated><id>https://rectifiedflow.github.io/blog/2024/discretization</id><content type="html" xml:base="https://rectifiedflow.github.io/blog/2024/discretization/"><![CDATA[<h1 id="equivariance-of-natural-euler-samplers">Equivariance of Natural Euler Samplers</h1> <p>The Euler method can be viewed as approximating ODE trajectories piecewise by straight segments, where each step uses the tangent line at the current point to approximate the local curve. This local straight-line approximation is a natural choice for rectified flow induced by straight interpolation. However, if the rectified flow is induced by a curved interpolation scheme, it may be more natural to use local curve segments—derived from the same interpolation scheme—instead of straight lines. We refer to such approximation schemes as <strong>natural Euler samplers</strong>. The term “natural” is taken from natural gradient descent, to reflect the point that its equivariant under reparameterizations, we describe below.</p> <p>This blog will first introduce the general idea of <strong>natural Euler samplers</strong> and then show that the trajectories of natural Euler samplers are equivariant for pointwise transformable interpolations:</p> <blockquote> <p>If two interpolation processes are pointwise transformable into one another, then the discrete trajectories of their rectified flow (RF) using their corresponding natural Euler samplers are also pointwise transformable using the same mapping functions, provided their time grids are related by a time scaling function \(\tau_t\).</p> </blockquote> <p>This result implies that, when natural Euler samplers are employed, during inference time, <strong>changing the affine interpolation scheme is essentially equivalent to altering the time grid</strong>. Note that this equivalence is <strong>beyond</strong> the continuous-time limit of ODE trajectories. Even after discretization via Euler steps, once the sampled points are transformed accordingly, the resulting discrete points will match numerically — we literally get the same results.</p> <h2 id="natural-euler-samplers">Natural Euler Samplers</h2> <p>Consider an <a href="/blog/2024/interpolation/#general-interpolation-function">interpolation</a> process \(X_t=\texttt I_t(X_0, X_1)\) with a rectified flow velocity field \(v_t\). In the vanilla Euler method, the trajectories of the flow are approximated on a discrete time gird \(\{t_i\}_i\) as:</p> \[\hat z_{t_{i+1}} = \hat z_{t_i} + (t_{i+1} - t_i) v_t(\hat z_{t_i}),\] <p>Here, the solution at each step is locally approxiamated by the straight line tangent to the rectified flow curve at point $\hat z_{t_i}$.</p> <p>In the natural Euler method, we replace the straight line with an <strong>interpolation curve</strong> that is tangent at \(\hat z_{t_i}\). The update rule becomes:</p> \[\hat z_{t_{i+1}} = \texttt I_{t_{i+1}}(\hat x_{0 \mid t_i}, \hat x_{1\mid t_i}),\] <p>where $\hat x_{0 \mid t_i}$ and $\hat x_{1 \mid t_i}$ are derived through equations from the specific interpolation $\texttt I$:</p> \[\begin{cases} \texttt I_{t_i}\bigl(\hat{x}_{0\mid t_i},\hat{x}_{1\mid t_i}\bigr) = \hat{z}_{t_{i+1}}, \\[6pt] \displaystyle \left.\frac{\partial}{\partial t} \texttt I_{t}\bigl(\hat{x}_{0\mid t_i},\hat{x}_{1\mid t_i}\bigr)\right|_{t=t_i} = v_{t_i}\bigl(\hat{z}_{t_i}\bigr). \end{cases}\] <p>This two equations identifies the endpoints \(\hat{x}_{0 \mid t_i}\) and \(\hat{x}_{1\mid t_i}\) of the interpolation curve that passes through \(\hat{z}_{t_i}\) and has a slope \(\partial \hat{z}_{t_i} = v_{t_i}(\hat{z}_{t_i})\) at time \(t_i\), i.e. the interpolation curve is chosen so that it is tangent to the rectified flow at \(\hat{z}_{t_i}\). In the case of affine interpolation, the solution takes a simple closed-form, as it reduces to solving a linear system in two variables.</p> <blockquote> <p>Example 1. Natural Euler Sampler for Spherical Interpolation</p> \[\hat z_{t + \epsilon} =\cos\left(\frac{\pi}{2} \cdot\epsilon\right) \hat z_{t} + \frac{2}{\pi} \sin \left(\frac{\pi}{2} \cdot\epsilon\right) v_t(\hat z_t)\] </blockquote> <blockquote> <p>Example 2. Natural Euler Sampler for DDIM</p> <table> <tbody> <tr> <td>The discretized inference scheme of DDIM is the instance of natural Euler sampler for spherical interpolations satisfying \(\alpha_t^2 + \beta_t^2 = 1\). Note that the inference update of DDIM is written in terms of the expected noise \(\hat{x}_0\vert_t(x) = \mathbb{E}[X_0\vert X_t = x]\). Hence, we also rewrite the update in terms of $$\hat{x}_{0</td> <td>t}$$:</td> </tr> </tbody> </table> \[\begin{aligned} \hat{z}_{t+\epsilon} &amp;= \alpha_{t+\epsilon} \cdot\hat{x}_{1\vert t}(\hat{z}_t) + \beta_{t+\epsilon} \cdot \hat{x}_{0\vert t}(\hat{z}_t) \\ &amp;\overset{*}{=} \alpha_{t+\epsilon} \left( \frac{\hat{z}_t - \beta_t \cdot\hat{x}_{0\vert t}(\hat{z}_t)}{\alpha_t} \right) + \beta_{t+\epsilon} \cdot \hat{x}_{0\vert t}(\hat{z}_t) \\ &amp;= \frac{\alpha_{t+\epsilon}}{\alpha_t} \hat{z}_t + \left( \beta_{t+\epsilon} - \frac{\alpha_{t+\epsilon} \beta_t}{\alpha_t} \right) \hat{x}_{0\vert t}(\hat{z}_t) \end{aligned}\] <p>where in \(\overset{*}{=}\) we used \(\alpha_t \cdot \hat{x}_{1\vert t}(\hat{z}_t) + \beta_t\cdot \hat{x}_{0\vert t}(\hat{z}_t) = \hat{z}_t\). We can slightly rewrite the update as:</p> \[\frac{\hat{z}_{t+\epsilon}}{\alpha_{t+\epsilon}} = \frac{\hat{z}_t}{\alpha_t} + \left( \frac{\beta_{t+\epsilon}}{\alpha_{t+\epsilon}} - \frac{\beta_t}{\alpha_t} \right) \hat{x}_{0\vert t}(\hat{z}_t),\] <p>which exactly matches Equation 13 of <strong>Song et al. [2020a]</strong>.</p> </blockquote> <h2 id="equivalence-of-natural-euler-trajectories">Equivalence of Natural Euler Trajectories</h2> <p>The trajectories obtained from natural Euler samplers are equivariant under pointwise transformations.</p> <blockquote> <p><strong>Theorem 1.</strong> Equivalence of Natural Euler Trajectories</p> <p>Suppose we have two interpolation processes \(\{X_t\}\) and \(\{X_t'\}\) that are contructed from the same couping and related by a pointwise transform \(X_t' = \phi_t(X_{\tau_t})\). Consider the trajectories \(\{\hat{z}_{t_i}\}_i\) and \(\{\hat{z}_{t_i'}'\}_i\), which are generated by applying the natural Euler method to the rectified flows induced by \(\{X_t\}\) and \(\{X_t'\}\), respectively, using time grids \(\{t_i\}\) and \(\{t_i'\}\).</p> <p>If the time grids satisfy \(\tau(t_i') = t_i\) for all \(i\), and the initial conditions align via \(\hat{z}_{t_0}' = \phi(\hat{z}_{t_0})\), then the <strong>discrete</strong> trajectories match under the same transform:</p> \[\hat{z}_{t_i'}' = \phi_{t_i}(\hat{z}_{t_i}) \quad \forall i = 0,1,\ldots\] <p>In particular, applying the natural Euler method to the rectified flow induced by an affine interpolation \(\{X_t'\}\) on a uniform grid \(t_i' = i/n\) is equivalent to applying the standard Euler method to the rectified flow induced by the corresponding straight interpolation \(\{X_t\}\), but using a non-uniform time grid \(t_i = \tau(i/n)\).</p> </blockquote> <p>This theorem strengthens the equivariance result of the rectified flow ODE given in the interpolation blog, as the ODE result can be viewed as the limiting case of the natural Euler method when the step size approaches zero.</p> <p>Let \(\{X_t'\} = T(\{X_t\})\) denote the pointwise transformation, and let \(\texttt{NaturalEuler}(\{Z_t\})\) represent the mapping from a rectified flow ODE to its discrete trajectories produced by the natural Euler sampler. The <strong>equivariance</strong> property can be expressed as:</p> \[\texttt{NaturalEulerRF}(\texttt{Transform}(\{X_t\})) = \texttt{Transform}(\texttt{NaturalEulerRF}(\{X_t\})).\] <p><em>In other words, the natural Euler sampler commutes with pointwise transformations in the same manner as the underlying rectified flow ODE does, providing a stronger, discrete-level form of the equivariance established in continuous time.</em></p> <blockquote> <p>Example 3. Equivalence of Straight Euler and DDIM sampler</p> <p>Since DDIM is the natural Euler sampler under spherical interpolation, and the vanllia Euler method is the natural Euler under the straight interpolation, they yield the same results under proper transform on the time grid. Specifically, the natural Euler sampler on an affine interpolation \(X_t' = \alpha'_t X_1 + \beta'_t X_0\) using a uniform time grid \(t'_i = i/n\) is equivalent to applying the vanilla (straight) Euler method to the straight RF (induced from \(X_t = tX_1 + (1 - t)X_0\)) but with a non-uniform time grid:</p> \[t_i = \frac{\alpha'_{i/n}}{\alpha'_{i/n}+\beta'_{i/n}}\] <p>Conversely, starting from the straight RF and using a vanilla Euler sampler on the time grid \(\{t_i\}\), one can recover the DDIM sampler by finding a time grid \(\{t'_i\}\) that satisfies:</p> \[t_i = \frac{\alpha'_{t_{i'}}}{\alpha_{t_{i'}}'+\beta'_{t_i'}}\] </blockquote>]]></content><author><name>Qiang Liu</name></author><category term="tutorial"/><summary type="html"><![CDATA[A Pointwise-Transformable Discretization of Flows]]></summary></entry><entry><title type="html">All Flows are One Flow</title><link href="https://rectifiedflow.github.io/blog/2024/interpolation/" rel="alternate" type="text/html" title="All Flows are One Flow"/><published>2024-12-10T10:00:00+00:00</published><updated>2024-12-10T10:00:00+00:00</updated><id>https://rectifiedflow.github.io/blog/2024/interpolation</id><content type="html" xml:base="https://rectifiedflow.github.io/blog/2024/interpolation/"><![CDATA[<p>The choice of interpolation process can significantly affect inference performance and speed, and it may initially appear that such a decision must be made during the pre-training stage. In this blog, however, we show that it is possible to convert between different affine interpolation schemes at inference time, without retraining the model. The <strong>transformations</strong> applied to the interpolation \(\{X_t\}\) are <strong>exactly the same</strong> as those applied to the rectified flow \(\{Z_t\}\). For affine interpolation schemes, this can be achieved by simply rescaling the time $t$ and the input \(x\). Building on this, we will demonstrate that these interpolations yield essentially <strong>equivalent</strong> rectified flow dynamics and identical rectified couplings. Consequently, it suffices to adopt a simple form—such as the straight-line interpolation \(X_t = tX_1 + (1-t)X_0\)—while maintaining the flexibility to recover all affine interpolations through appropriate adjustments in time and parameterization.</p> <p>For a more comprehensive and rigorous discussion on this topic, please refer to Chapter 3 in the <a href="">Rectified Flow book</a>.</p> <h2 id="point-wisely-transformable-interpolations">Point-wisely Transformable Interpolations</h2> <h3 id="tl-dr">TL; DR</h3> <p>Assume that we are given an arbitrary coupling $(X_0, X_1)$ of source distribution $\pi_0$ and target distribution$\pi_1$. With a time-differentialble interpolation process \(X_t = \texttt I_t(X_0, X_1)\), the Rectified Flow \(\{Z_t\}\) induced by \(\{X_t\}\) is given by</p> \[\mathrm d Z_t = v_t(Z_t), \quad \forall t \in [0,1], \quad \text{starting from } Z_0 = X_0,\] <p>where \(v_t\) is obtained by matching the slope \(\dot X_t\) of the interpolation process:</p> \[\min_v \int_0 ^1 \mathbb E\left[ \left\| \dot X_t - v_t(X_t) \right\|^2 \right] \mathrm d t.\] <p>The theoretical minimum is achieved by \(v^*_t(x) = \mathbb E[\dot X_t \mid X_t = x]\).</p> <p>We show that, if two processes \(\{X_t\}\) and \(\{X'_t\}\), generated with different interpolation schemes, are related pointwise by</p> \[X'_t = \phi_t(X_t),\] <p>for some differentiable and invertible maps \(\phi: (t, x) \mapsto \phi_t(x)\) and \(\tau: t \mapsto \tau_t\), then their corresponding rectified flows \(\{Z_t\}\) and \(\{Z'_t\}\) satisfy the <strong>same</strong> relationship:</p> \[Z'_t = \phi_t(Z_{\tau_t}),\] <p>provided that this relation holds at initialization, i.e., \(Z'_0 = \phi_t(Z_0)\).</p> <p>This result implies that the rectified flows of pointwisely transformable interpolations are <strong>essentially the same</strong>, up to the same pointwise transformation. Furthermore, if two interpolations \(X_t = \texttt I_t(X_0, X_1)\) and \(X'_t = \texttt I'_t(X_0, X_1)\) are constructed from the same coupling \((X_0, X_1)\), they yield same rectified coupling \((Z_0, Z_1') = (Z_0, Z_1)\).</p> <p>Define \(\{X'_t\} = \texttt{Transform}(\{X_t\})\) as the aforementioned pointwise transformation. The result then suggests that the rectification operation \(\texttt{Rectify}(\cdot)\) is <strong>equivariant</strong> under these pointwise transforms:</p> \[\texttt{Rectify}(\texttt{Transform}(\{X_t\})) = \texttt{Transform}(\texttt{Rectify}(\{X_t\})).\] <h3 id="same-transform-on-interpolations-and-rectified-flows">Same Transform on Interpolations and Rectified Flows</h3> <blockquote> <p><strong>Definition 1</strong>. Two interpolation processes \(\{X_t\}\) and \(\{X'_t\}\) are said to be <strong>pointwisely transformable</strong> if \(X'_t = \phi_t(X_{\tau_t}), \quad \forall t \in [0, 1],\)</p> <p>where \(\tau: [0,1] \to [0,1]\) and \(\phi: [0,1] \times \mathbb{R}^d \to \mathbb{R}^d\) for \(t \in [0,1]\) are differentiable maps, and \(\phi_t\) is invertible for all \(t \in [0,1]\).</p> </blockquote> <p>Building upon the notion of pointwise transformability, we have:</p> <blockquote> <p><strong>Theorem 1</strong>. Assume that \(\{X_t\}\) and \(\{X'_t\}\) are pointwise transformable. Let \(\{v_t\}\) and \(\{v'_t\}\) be their respective RF velocity fields, and let $\phi$ and $t$ be the corresponding interpolation transformation maps. Then we have \(v'_t(x) = \partial_t \phi_t(\phi_t^{-1}(x)) + \nabla \phi_t(\phi_t^{-1}(x))^\top v_{\tau_t}(\phi_t^{-1}(x)) \dot{\tau}_t. \tag{1}\)</p> <p>In addition, let \(\{z_t\}\) be a trajectory of the rectified flow of \(\{X_t\}\), satisfying \(\frac{\mathrm d}{\mathrm dt} z_t = v_t(z_t).\) Then a curve \(\{z'_t\}\) satisfies \(z'_t = \phi_t(z_{\tau_t})\), \(\forall t \in [0, 1]\) if and only if it is the trajectory of the rectified flow of \(\{X'_t\}\) initialized from \(z'_0 = \phi_0(z_{\tau_0})\).</p> </blockquote> <p>Furthermore, under the additional requirement that \(\tau(0)=0\), let \(\frac{\mathrm d}{\mathrm dt}Z_t=v_t(Z_t)\) be the rectified flow of \(\{X_t\}\) (initialized with \(Z_0=X_0\) by default). Then \(Z'_t=\phi_t(Z_{\tau_t})\) is the rectified flow of \(\{X_t'\}\) with the specific initialization</p> \[\frac{\mathrm d}{\mathrm dt} Z'_t = v'_t(Z_t'), \quad \forall t \in [0,1], \;\text{and}\; Z_0' = \phi_0(Z_{\tau_0}).\] <p>This result has two implications:</p> <ol> <li> <p><em>Identical Transformations for Interpolations and Rectified Flows:</em><br/> Under the same conditions as Theorem 1, and assuming \(\tau(0) = 0\), let \(\{Z_t\}\) and \(\{Z'_t\}\) be the rectified flows corresponding to \(\{X_t\}\) and \(\{X'_t\}\), respectively. Then we have:</p> \[Z'_t = \phi_t(Z_{\tau_t}) \quad \text{for all } t \in [0,1].\] <p>In other words, the transformation applied to \(\{X_t\}\) is exactly the same transformation that applies to \(\{Z_t\}\).</p> </li> <li> <p><em>Equivalent Rectified Couplings:</em><br/> If \(\{X_t\}\) and \(\{X'_t\}\) are constructed from the same coupling \((X_0, X_1) = (X'_0, X'_1)\) and meet the conditions of Theorem 1 with \(\tau(0) = 0\) and \(\tau(1) = 1\), then their rectified flows produce the same coupling. Specifically:</p> \[(Z_0, Z_1) = (Z'_0, Z'_1).\] </li> </ol> <h2 id="equivalence-of-affine-interpolations">Equivalence of Affine Interpolations</h2> <h3 id="general-interpolation-function">General Interpolation Function</h3> <blockquote> <p><strong>Definition 2.</strong> Consider a function</p> \[\mathtt{I} : [0, 1] \times \mathbb{R}^d \times \mathbb{R}^d \to \mathbb{R}^d,\] <p>denoted by \(\mathtt{I}_t(x_0, x_1)\). We say \(\mathtt{I}\) is an <em>interpolation function</em> if it satisfies:</p> \[\mathtt{I}_0(x_0, x_1) = x_0 \quad \text{and} \quad \mathtt{I}_1(x_0, x_1) = x_1 \quad \text{for all } x_0, x_1 \in \mathbb{R}^d.\] <p>Given an interpolation function \(\mathtt{I}\) and a coupling \((X_0, X_1)\), the associated interpolation process \(\{X_t\}\) is defined by:</p> \[X_t = \mathtt{I}_t(X_0, X_1).\] </blockquote> <h3 id="straight-spherical-and-ddim-interpolation">Straight, Spherical and DDIM interpolation</h3> <p>We now consider a specific class of interpolations called <em>affine interpolations</em>, defined as \(X_t = \alpha_t X_1 + \beta_t X_0\) where \(\alpha_t\) and \(\beta_t\) satisfy the conditions \(\alpha_0 = \beta_1 = 0\) and \(\alpha_1 = \beta_0 = 1\), as well as \(\alpha_t\) is monotonically increasing and \(\beta_t\) monotonically decreasing.</p> <p><strong>Straight Line Interpolation</strong> (<code class="language-plaintext highlighter-rouge">straight</code> or <code class="language-plaintext highlighter-rouge">lerp</code>)</p> \[\begin{aligned} \alpha_t &amp; = t, &amp; \beta_t &amp; = 1 - t \\ \dot{\alpha}_t &amp; = 1, &amp; \dot{\beta}_t &amp; = -1 \end{aligned}\] <ul> <li>This interpolation follows a straight line connecting the source and target distributions with a constant speed.</li> </ul> <p><strong>Spherical Interpolation</strong> (<code class="language-plaintext highlighter-rouge">spherical</code> or <code class="language-plaintext highlighter-rouge">slerp</code>)</p> \[\begin{aligned} \alpha_t &amp; = \sin\left(\frac{\pi}{2} t\right), &amp; \beta_t &amp; = \cos\left(\frac{\pi}{2} t\right) \\ \dot{\alpha}_t &amp; = \frac{\pi}{2} \cos\left(\frac{\pi}{2} t\right), &amp; \dot{\beta}_t &amp; = -\frac{\pi}{2} \sin\left(\frac{\pi}{2} t\right) \end{aligned}\] <ul> <li>Spherical interpolation traces a curved path rather than a straight line.</li> </ul> <p><strong>DDIM / VP ODE Interpolation</strong></p> \[\alpha_t = \exp\left(- \frac{1}{4}a(1-t)^2 - \frac{1}{2}b(1-t)\right), \quad \beta_t = \sqrt{1 - \alpha_t^2}, \quad a=19.9, b=0.1\] <ul> <li>DDIM interpolation also takes a spherical trajectory, but with a non-uniform speed defined by \(\alpha_t\).</li> </ul> <h3 id="pointwise-transformability-between-affine-interpolations">Pointwise Transformability Between Affine Interpolations</h3> <p>We now show that <strong>all affine interpolations are pointwise transformable</strong> by appropriately scaling both the time and the input. Then, according to the two corollaries above, their rectified flows can be transformed pointwise using the same mappings as those used between the interpolations, ultimately yielding the same rectified couplings. This is also observed by other authors.</p> <blockquote> <p>Consider two affine interpolation processes of same coupling \((X_0, X_1)\):</p> \[X_t = \alpha_t X_1 + \beta_t X_0 \quad \text{and} \quad X_{t}' = \alpha_{t}' X_1 + \beta_{t}' X_0,\] <p>Then we have</p> \[X_t' = \frac{1}{\omega_t} X_{\tau_t}, \quad \forall t \in [0,1],\] <p>where \(\tau_t\) and \(\omega_t\) are found by solving:</p> \[\frac{\alpha_{\tau_t}}{\beta_{\tau_t}} = \frac{\alpha'_t}{\beta'_t}, \quad \omega_t = \frac{\alpha_{\tau_t}}{\alpha'_t} = \frac{\beta_{\tau_t}}{\beta'_t}, \quad \forall t \in (0, 1) \tag{2}\] <p>with the boundary condition:</p> \[\omega_0 = \omega_1 = 1, \quad \tau_0 = 0, \quad \tau_1 = 1.\] <p>There is one unique solution of \((\tau_t, \omega_t)\) in \((2)\) since \(\alpha'_t / \beta'_t \geq 0\) and \(\alpha_t / \beta_t\) is strictly increasing for \(t \in [0,1]\).</p> </blockquote> <p>In practice, we determine the time scaling function \(\tau_t\) in two ways. For simple cases, \(\tau_t\) can be computed analytically. For more complex scenarios, a numerical approach, such as a <a href="">simple binary search</a>, can be used to find \(\tau_t\) efficiently.</p> <div class="l-body-outset" style="display: flex;"> <iframe src="/assets/plotly/interp_tau_ddim_spherical.html" frameborder="0" scrolling="no" height="430px" width="49%"></iframe> <iframe src="/assets/plotly/interp_tau_straight_spherical.html" frameborder="0" scrolling="no" height="430px" width="49%"></iframe> </div> <p>The figure below shows the conversion between the <code class="language-plaintext highlighter-rouge">straight</code> and <code class="language-plaintext highlighter-rouge">spherical</code> interpolations using a binary search method. Observe that once converted, the trajectory of the original <code class="language-plaintext highlighter-rouge">straight</code> interpolation matches <em>perfectly</em> with the newly derived <code class="language-plaintext highlighter-rouge">straight</code> curve, confirming that these interpolations are indeed pointwise transformable.</p> <div class="l-body-outset"> <iframe src="/assets/plotly/interp_affine_interp_conversion.html" frameborder="0" scrolling="no" height="630px" width="100%"></iframe> </div> <p>Substituting the notion of \(\tau\) and \(\omega\) into the theorem 1, we have:</p> <blockquote> <p><strong>Example 1.</strong> Converting straight interpolation into affine ones.</p> <p>Consider the straight interpolation \(X_t=tX_1 + (1-t)X_0\) with \(\alpha_t=t\) and \(\beta_t=1-t\). We aim to transform this interpolation into another affine interpolation \(X_t'=\alpha_t' X_1 + \beta_t' X_0\). By Solving the equations:</p> \[\omega_t = \frac{\tau_t}{\alpha_t'} = \frac{1 - \tau_t}{\beta_t'},\] <p>we obtain:</p> \[\tau_t = \frac{\alpha'_t}{\alpha'_t + \beta_t'}, \quad \omega_t = \frac{1}{\alpha_t' + \beta_t'}\] <p>The velocity field \(v_t(x)\) is transformed into \(v'_t(x)\) as follows:</p> \[v'_t(x) = \frac{\dot \alpha_t' \beta_t' - \alpha'_t \dot \beta_t'}{\alpha_t' + \beta_t'} \cdot v_{\tau_t}(\omega_t x) + \frac{\dot \alpha_t' + \dot \beta_t'}{\alpha_t' + \beta_t'} \cdot x\] </blockquote> <h3 id="converting-pretrained-rf-velocity">Converting Pretrained RF Velocity</h3> <p>Now, let’s take a pretrained straight rectified flow and transform it into a curved trajectory. See the notebook for implementation details.</p> <blockquote> <p><strong>Theorem 2</strong>. Assume \(\{X_t\}\) and \(\{X'_t\}\) are two affine interpolations:</p> <ul> <li>Their respective rectified flows \(\{Z_t\}\) and \(\{Z'_t\}\) satisfy:</li> </ul> \[Z'_t = \omega_t^{-1} Z_{\tau_t}, \quad \forall t \in [0, 1].\] <ul> <li>Their rectified couplings are equivalent:</li> </ul> \[(Z_0, Z_1) = (Z'_0, Z'_1).\] <ul> <li>Their RF velocity fields \(v_t\) and \(v'_t\) satisfy:</li> </ul> \[v'_t(x) = \frac{1}{\omega_t} \left( \dot{\tau}_t v_{\tau_t}(\omega_t x) - \dot{\omega}_t x \right). \tag{3}\] </blockquote> <div class="l-body-outset"> <iframe src="/assets/plotly/interp_1rf_straight_to_spherical.html" frameborder="0" scrolling="no" height="630px" width="100%"></iframe> </div> <p><strong>Trajectory Considerations</strong> As the number of sampling steps increases, the trajectories for \(Z_1\) and \(Z_1'\) should converge to the same points, and the mean squared error between them should also decrease.</p> <p>However, even though different paths theoretically lead to the same rectified endpoint \(Z_1\), the intermediate trajectories \(\{Z_t\}\) they follow are not identical. In practice, when running simulations, we must discretize these trajectories, making perfect solutions unattainable. For this reason, <strong>choosing straighter trajectories is generally preferable</strong>: the straighter the path, the lower the discretization error, and the more faithful the results. Thanks to the transformation relations described above, it is possible to convert the interpolation scheme of a pretrained model without retraining, enabling the identification of a scheme that yields straighter trajectories for \(\{Z_t\}\).</p> <h2 id="implications-on-loss-functions">Implications on Loss Functions</h2> <p>Assume that we have trained a model \(\hat{v}_t\) for the RF velocity field \(v_t\) under an affine interpolation. Using the formulas from the previous section, we can convert it to a model \(\hat{v}'_t\) for \(v'_t\) corresponding to a different interpolation scheme at the post-training stage. This raises the question of what properties the converted model \(\hat{v}'_t\) may have compared to the models trained directly on the same interpolation, and whether it suffers from performance degradation due to the conversion.</p> <p>We show here that using different affine interpolation schemes during training is equivalent to applying <strong>different time-weighting</strong> in the loss function, as well as an affine transform on the parametric model. Unless \(\omega_t\) and \(\tau_t\) are highly singular, the conversion does not necessarily degrade performance.</p> <p>Specifically, assume we have trained a parametric model \(v_t(x; \theta)\) to approximate the RF velocity \(v_t\) of interpolation \(X_t = \alpha_t X_1 + \beta_t X_0\), using the mean square loss:</p> \[\mathcal L(\theta) = \int_0^1 \mathbb E\left[ \eta_t \left \| \dot X_t - v_t(X_t;\theta)\right\|^2 \right] \mathrm dt \tag{4}\] <p>After training, we may convert the obtained model \(v_t(x; \theta)\) to an approximation of \(v'_t\) of a different interpolation \(X'_t = \alpha_t X_1 + \beta_t X_0\) via:</p> \[v'_t(x; \theta) = \frac{\dot{\tau}_t}{\omega_t} v_{\tau_t}(\omega_t x; \theta) - \frac{\dot{\omega}_t}{\omega_t} x,\] <p>On the other hand, if we train \(v'_t(x; \theta)\) directly to approximate \(v'_t\) of interpolation \(X'_t = \alpha'_t X_1 + \beta'_t X_0\), the loss function is:</p> \[\mathcal L'(\theta) = \int_0^1 \mathbb{E} \left[ \eta'_t \left\| \dot{X}'_t - v'_t(X'_t; \theta) \right\|^2 \right] \mathrm dt \tag{5}\] <p>When matching the loss \((4)\) and \((5)\), we find that these two training schemes are identical, except for the following time-weighting and reparametrization relationship:</p> \[\eta'_t = \frac{\omega_t^2}{\dot{\tau}_t} \eta_{\tau_t}, \quad v'_t(x; \theta) = \frac{\dot{\tau}_t}{\omega_t} v_{\tau_t}(\omega_t x; \theta) - \frac{\dot{\omega}_t}{\omega_t} x. \tag{6}\] <p>In other words, <strong>training with different interpolation schemes simply only introduces different training time weights and model parameterizations.</strong></p> <blockquote> <p><strong>Example 2. Loss from Straight to Affine</strong></p> <p>Consider the straight interpolation \(X_t = t X_1 + (1 - t) X_0\) with \(\alpha_t = t\) and \(\beta_t = 1 - t\), alongside another affine interpolation \(X_t' = \alpha_t' X_1 + \beta_t' X_0\).</p> <p>Suppose we have trained the \(v_t\) for \(X_t\) with a time weight \(\eta_t\), then \(v_t'\) converted from \(v_t\) is equivalent to the RF trained with the parametrization in \((6)\), and another time weight:</p> \[\eta_t' = \frac{\omega_t^2}{\tau_t'} \eta_{\tau_t} = \frac{1}{\dot{\alpha}_t' \beta_t' - \alpha_t' \dot{\beta}_t'} \eta_{\tau_t},\] <p>Here, we substitute the relationships derived in Example 1 into \((6)\).</p> </blockquote> <h3 id="straight-vs-spherical-same-train-time-weight">Straight vs Spherical: Same Train Time Weight</h3> <p>Consider the straight interpolation \(X_t = tX_1 + (1 - t)X_0\) and an affine interpolation \(X_t' = \alpha_t' X_1 + \beta_t' X_0\). If</p> \[\dot \alpha_t' \beta_t' - \alpha_t \beta_t' = \text{const},\] <p>then we have \(\eta_t' \propto \eta_{\tau_t}\), meaning that the training time weighting remains constant scale across the time.</p> <p>For example, this condition holds in the case of spherical interpolation:</p> <blockquote> <p><strong>Example 3.</strong> Losses for Straight vs. Spherical Interpolation</p> <p>Consider the spherical interpolation \(X'_t = \sin\left(\frac{\pi t}{2}\right)X_1 + \cos\left(\frac{\pi t}{2}\right)X_0\), we have</p> \[\eta'_t = \frac{2}{\pi} \eta_{\tau_t}, \quad \tau_t = \frac{\tan\left(\frac{\pi t}{2}\right)}{\tan\left(\frac{\pi t}{2}\right)+1}.\] <p>In this case, training \(v_t\) with the straight interpolation using a uniform weight \(\eta_t = 1\) is equivalent to training \(v'_t\) with the spherical interpolation, also with a uniform weight \(\eta'_t = 2 /\pi\). The sole difference lies in the model’s parameterization:</p> \[v'_t(x, \theta) = \frac{\pi \omega_t}{2} \left( v_{\tau_t}(\omega_t x, \theta) + \left( \cos\left(\frac{\pi t}{2}\right) - \sin\left(\frac{\pi t}{2}\right) \right) x \right),\] <p>where \(\omega_t = (\sin(\frac{\pi t}{2}) + \cos(\frac{\pi t}{2}))^{-1}\) is bounded within \([1/\sqrt{2}, 1]\). Thus, this reparameterization may not significantly affect performance. Overall, choosing between straight or spherical interpolation seems to have <strong>limited practical impact</strong> on training outcomes.</p> </blockquote> <div class="l-body-outset"> <iframe src="/assets/plotly/interp_straight_spherical_rf.html" frameborder="0" scrolling="no" height="630px" width="100%"></iframe> </div> <p>In our experiments, we independently trained two rectified flows using MLPs. Since both used the equivalent time-weighting scheme, the resulting couplings were nearly identical.</p>]]></content><author><name>Qiang Liu</name></author><category term="tutorial"/><summary type="html"><![CDATA[Affine Interpolations Result in Equivalent Rectified Flows]]></summary></entry><entry><title type="html">Stochastic Sampler: Langevin as Guardrail</title><link href="https://rectifiedflow.github.io/blog/2024/samplers/" rel="alternate" type="text/html" title="Stochastic Sampler: Langevin as Guardrail"/><published>2024-12-10T10:00:00+00:00</published><updated>2024-12-10T10:00:00+00:00</updated><id>https://rectifiedflow.github.io/blog/2024/samplers</id><content type="html" xml:base="https://rectifiedflow.github.io/blog/2024/samplers/"><![CDATA[<h2 id="overview">Overview</h2> <p>In this blog, we will elaborate on, given a pretrained flow model, how does a stochastic sampler (like DDPM) relate to a deterministic sampler as conducting simple Euler steps in rectified flow. In particular, we will show that one can convert any deterministic sampler to its corresponding stochastic counterparts, and vice versa. The main difference is that the stochastic sampler has an extra Langevin dynamics term, which could potentially help correct the discretization error from cumulative Euler steps. For a more comprehensive and rigorous discussion on this topic, please refer to Chapter 5 in the <a href="">Rectified Flow book</a>.</p> <h2 id="stochastic-solvers-guardrails-for-generative-models">Stochastic Solvers: Guardrails for Generative Models</h2> <p>For an introduction to rectified flow and its foundational concepts, check out our earlier post <a href="https://rectifiedflow.github.io/blog/2024/intro/">here</a><d-cite key="Liu2022FlowSA"></d-cite></p> <p>When working with generative models, particularly those using rectified flow, errors can accumulate over time as we solve the ODE $dZ_t = v_t(Z_t) dt$. These errors arise from model approximations and numerical discretization, leading to drift between the estimated distribution $\hat{Z}_t$ and the true distribution $\rho_t$. Here, $\rho_t$ represents the smooth density function of the true distribution $X_t$. This problem is exacerbated in low-density regions rarely sampled during training, where model inaccuracies are more pronounced.</p> <p>To address this, <strong>stochastic solvers</strong> can replace deterministic ODE solvers during inference. By introducing stochastic dynamics, we can dynamically correct these errors, ensuring the estimated distribution stays aligned with the true one.</p> <h4 id="langevin-dynamics-as-a-guardrail">Langevin Dynamics as a Guardrail</h4> <p>One common and promising approach is to use <strong>Langevin dynamics</strong> as a corrective mechanism. At each timestep $t$, a short segment of Langevin dynamics is applied to adjust $\hat{Z}_t$ toward $\rho_t$:</p> \[dZ_{t, \tau} = \sigma_t^2 \nabla \log \rho_t(Z_{t, \tau}) d\tau + \sqrt{2}\sigma_t dW_\tau, \quad \tau \geq 0\] <p>Here, $\sigma_t$ controls the noise level, and $\nabla \log \rho_t$ adjusts the drift toward high-probability regions of $\rho_t$. While simulating Langevin dynamics until equilibrium would align the distribution perfectly, this is often unnecessary. A single step of Langevin dynamics can sufficiently reduce drift when $\hat{Z}_t$ is already close to $\rho_t$.</p> <p>To streamline this process, Langevin corrections can be integrated directly into the rectified flow updates, resulting in a combined stochastic differential equation (SDE):</p> \[d\tilde{Z}_t = \underbrace{v_t(\tilde{Z}_t) dt}_{\text{Rectified Flow}} + \underbrace{\sigma_t^2 \nabla \log \rho_t(\tilde{Z}_t) dt + \sqrt{2} \sigma_t dW_t}_{\text{Langevin Dynamics}}, \quad \tilde{Z}_0 = Z_0\] <p>This combined SDE achieves two goals:</p> <ol> <li>The <strong>rectified flow</strong> drives the generative process forward as intended.</li> <li>The <strong>Langevin component</strong> acts as a negative feedback loop, correcting distributional drift without bias when $\tilde{Z}_t$ and $\rho_t$ are already well aligned.</li> </ol> <h4 id="why-it-works">Why It Works</h4> <p>If the simulation is accurate, Langevin dynamics naturally stay in equilibrium, meaning they won’t alter the distribution unnecessarily. But when deviations occur, this mechanism gently nudges the estimate back on track, providing robustness to the inference process.</p> <p>By incorporating stochastic solvers like these, we create a dynamic correction framework that enhances the stability and accuracy of generative models, ensuring that outputs remain high-quality and faithful to the intended distributions.</p> <p><strong>Score Function Visualization:</strong> In the next toy example, we’ll visualize the score function $\nabla \log \rho_t$. This will help you see how these small corrective forces guide the samples toward the right regions, improving upon what a purely deterministic approach can achieve.</p> <div class="l-body"> <img src="/assets/img/score_function_on_sde_traj.png" alt="cross" style="max-width:100%;"/> </div> <p>As shown here, the score function ($\nabla \log \rho_t$) points samples toward regions of higher density. This corrects the trajectories from the original predicted velocity, providing a drifting force that helps ensure samples converge to the most probable areas of the target distribution.</p> <h2 id="sdes-with-gaussian-initial-distributions">SDEs with Gaussian Initial Distributions</h2> <p>Previously, we demonstrated that for a rectified flow using interpolation $X_t = \alpha_t X_1 + \beta_t X_0$, two processes can achieve the same target distribution $\pi_1$:</p> <ul> <li> <p><strong>The ODE process:</strong></p> \[d Z_t = v_t(Z_t)dt\] </li> <li> <p><strong>The SDE process:</strong></p> \[d Z_t = v_t(Z_t)dt + \sigma_t^2 \nabla \log \rho_t(Z_t) dt + \sqrt{2} \sigma_t d W_t,\] </li> </ul> <p>The <strong>Euler method</strong> is commonly used to discretize the ODE process, yielding the following update rule:</p> \[\hat{Z}_{t + \Delta t} = \hat{Z}_t + \Delta t \cdot v(\tilde{Z}_t)\] <p>Similarly, the SDE process can be discretized. When introducing a noise level $\sigma_t$ at time $t$, the update step becomes:</p> \[\hat{Z}_{t + \Delta t} = \hat{Z}_t + \Delta t \cdot (v(\hat{Z}_t) + \frac{\sigma_t^2}{\beta_t \lambda_t} (\alpha_t v(\hat{Z}_t) - \dot{\alpha}_t \hat{Z}_t)) + \sqrt{2} \sigma_t \xi_t,\] <p>Here:</p> <ul> <li>$\lambda_t = \dot{\alpha}_t \beta_t - \alpha_t \dot{\beta}_t$</li> <li>$\xi$ is random Gaussian noise sampled from $\mathcal{N}(0, I)$.</li> </ul> <p>This update rule explicitly incorporates the Langevin dynamics term, derived in detail in Chapter 5.3 of the <a href="TBD: insert link">Rectified Flow book</a>.</p> <p>In practice, the <code class="language-plaintext highlighter-rouge">AffineInterpSolver</code> in our <a href="https://github.com/lqiang67/rectified-flow">Rectified Flow repository</a> provides an efficient way to compute the score function. This solver supports scenarios where at least two of the variables $(x_0, x_1, x_t, \dot{x}_t)$ are known, enabling the estimation of the others.</p>]]></content><author><name>Qiang Liu</name></author><category term="tutorial"/><summary type="html"><![CDATA[Connections between Deterministic and Stochastic Samplers]]></summary></entry><entry><title type="html">Rectified Flow, An Introduction</title><link href="https://rectifiedflow.github.io/blog/2024/intro/" rel="alternate" type="text/html" title="Rectified Flow, An Introduction"/><published>2024-12-06T10:00:00+00:00</published><updated>2024-12-06T10:00:00+00:00</updated><id>https://rectifiedflow.github.io/blog/2024/intro</id><content type="html" xml:base="https://rectifiedflow.github.io/blog/2024/intro/"><![CDATA[<h2 id="overview">Overview</h2> <p>This blog provides a brief introduction to the Rectified Flow idea, which serves as a mainstream algorithm for training deep generative models. For a more comprehensive and rigorous discussion on the introduction, please refer to Chapter 1 in the <a href="">Rectified Flow book</a> and the original paper<d-cite key="Liu2022FlowSA"></d-cite>.</p> <p>Generative modeling can be formulated as finding a computational procedure that transforms a noise distribution, denoted by \(\pi_0\), into the unknown data distribution \(\pi_1\). In flow models, this procedure is represented by an ordinary differential equation (ODE):</p> \[\dot{Z}_t = v_t(Z_t), \quad \forall t \in [0,1], \quad \text{starting from } Z_0 \sim \pi_0, \tag{1}\] <p>where \(\dot{Z}_t = \mathrm dZ_t / \mathrm dt\) denotes the time derivative, and the velocity field \(v_t(x) = v(x, t)\) is a learnable function to be estimated to ensure that \(Z_1\) follows the target distribution \(\pi_1\) when starting from \(Z_0 \sim \pi_0\). In this case, we say that the stochastic process \(Z = \{Z_t\}\) provides an (ODE) transport from \(\pi_0\) to \(\pi_1\).</p> <p>It is important to note that, in all but trivial cases, there exist <em>infinitely many</em> ODE transports from \(\pi_0\) to \(\pi_1\), provided that at least one such process exists. Thus, it is essential to be clear about which types of ODEs we should prefer.</p> <p>One option is to favor ODEs that are easy to solve at inference time. In practice, the ODEs are approximated using numerical methods, which typically construct piecewise linear approximations of the ODE trajectories. For instance, a common choice is Euler’s method:</p> \[\hat{Z}_{t+\epsilon} = \hat{Z}_t + \epsilon v_t(\hat{Z}_t), \quad \forall t \in \{0, \epsilon, 2\epsilon, \dots, 1\}, \tag{2}\] <p>where \(\epsilon &gt; 0\) is a step size. Varying the step size \(\epsilon\) introduces a trade-off between accuracy and computational cost: smaller \(\epsilon\) yields high accuracy but incurs a larger number of calculation steps. Therefore, we should seek ODEs that can be approximated accurately even with large step sizes.</p> <div class="l-body"> <iframe src="/assets/plotly/intro_euler_approximation_with_arrows.html" frameborder="0" scrolling="no" height="480px" width="100%"></iframe> </div> <p>The ideal scenario arises when the ODE follows straight-line trajectories, in which case Euler approximation yields zero discretization error regardless of the choice of step sizes. In such cases, the ODE, up to time reparameterization, should satisfy:</p> \[Z_t = t Z_1 + (1 - t) Z_0, \quad \implies \quad \dot{Z}_t = Z_1 - Z_0.\] <p>These ODEs, known as straight transports, enable fast generative models that can be simulated in a single step. We refer to the resulting pair \((Z_0, Z_1)\) as a straight coupling of \(\pi_0\) and \(\pi_1\). In practice, perfect straightness may not be achievable, but a goal we can aim for is to make the ODE trajectories as straight as possible to maximize computational efficiency.</p> <p>It is possible to discuss generalized notions of straightness when solvers other than Euler’s method are used.</p> <h2 id="rectified-flow">Rectified Flow</h2> <p>To construct a flow transporting \(\pi_0\) to \(\pi_1\), let us assume that we are given an arbitrary coupling \((X_0, X_1)\) of \(\pi_0\) and \(\pi_1\), from which we can obtain empirical draws. This can be simply the independent coupling with law \(\pi_0 \times \pi_1\), as is common in practice when we have access to independent samples from \(\pi_0\) and \(\pi_1\). The idea is that we are going to take \((X_0, X_1)\) and convert it to a better coupling generated by an ODE model, and optionally, we can go further to iteratively repeat this process to further enhance desired properties, such as straightness.</p> <p>Rectified flow works in the following ways:</p> <ul> <li><strong>Build Interpolation:</strong><br/> We build an interpolation process \(\{X_t\} = \{X_t : t \in [0, 1]\}\) that smoothly interpolates between \(X_0\) and \(X_1\). Although general choices are possible, let us consider the canonical choice of straight-line interpolation: \(X_t = t X_1 + (1 - t) X_0.\) Here \(\{X_t\}\) is a stochastic process generated in a special way: we first sample the endpoints \(X_0\) and \(X_1\) and then sample the intermediate trajectory connecting them. Such processes are also known as bridge processes, where the intermediate values of \(X_t\) smoothly “bridge” the distribution between \(X_0\) and \(X_1\).</li> </ul> <div class="l-body"> <iframe src="/assets/plotly/intro_straight_interp.html" frameborder="0" scrolling="no" height="630px" width="100%"></iframe> </div> <ul> <li><strong>Marginal Matching:</strong><br/> By construction, the marginal distributions of \(X_0\) and \(X_1\) match the target distributions \(\pi_0\) and \(\pi_1\) through the interpolation process \(\{X_t\}\). However, \(\{X_t\}\) is not a causal ODE process like \(\dot{Z}_t = v_t(Z_t)\), which evolves forward from \(Z_0\). Instead, generating \(X_t\) requires knowledge of both \(X_0\) and \(X_1\), rather than evolving solely from \(X_0\) as \(t\) increases.</li> </ul> <p>This issue can be resolved if we can convert \(\{X_t\}\) somehow into a causal ODE process while preserving the marginal distributions of \(X_t\) at each time \(t\). Perhaps surprisingly, this can be achieved by simply training the ODE model \(\dot{Z}_t = v_t(Z_t)\) to match the slope \(\dot{X}_t\) of the interpolation process via:</p> \[\min_v \int_0^1 \mathbb{E} \left[ \left\| \dot{X}_t - v_t(X_t) \right\|^2 \right] \mathrm dt. \tag{3}\] <p>The theoretical minimum is achieved by:</p> \[v_t^*(x) = \mathbb{E} \left[ \dot{X}_t \mid X_t = x \right],\] <p>which denotes the expectation of the slope \(\dot{X}_t\) of the interpolation process passing through a given point \(X_t = x\).</p> <blockquote> <p><strong>Definition: Rectified Flow.</strong></p> <p>For any time-differential stochastic process \(\{X_t\} = \{X_t : t \in [0, 1]\}\), we call the ODE process:</p> \[\dot{Z}_t = v_t^*(Z_t) \quad \text{with} \quad v_t^*(x) = \mathbb{E} \left[ \dot{X}_t \mid X_t = x \right],\] <p>and \(Z_0 = X_0\) the <strong>rectified flow</strong> induced by \(\{X_t\}\). We denote it as:</p> \[\{Z_t\} = \text{RectFlow}(\{X_t\}).\] </blockquote> <p>With the canonical straight interpolation, we have \(\dot{X}_t = X_1 - X_0\) by taking the derivative of \(X_t\) with respect to \(t\). It yields:</p> \[\min_v \int_0^1 \mathbb{E} \left[ \| \dot{X}_t - v_t(X_t) \|^2 \right] \mathrm dt, \quad X_t = t X_1 + (1 - t) X_0.\] <p>In practice, the optimization in (3) can be efficiently solved even for large AI models when \(v\) is parameterized as modern deep neural nets. This is achieved by leveraging off-the-shelf optimizers with stochastic gradients, computed by drawing pairs \((X_0, X_1)\) from data, sampling \(t\) uniformly in \([0, 1]\), and then computing the corresponding \((X_t, \dot{X}_t)\) using the interpolation formula.</p> <div class="l-body"> <iframe src="/assets/plotly/intro_1rf.html" frameborder="0" scrolling="no" height="630px" width="100%"></iframe> </div> <p>This figure illustrates the intuition. In the interpolation process \(\{X_t\}\), different trajectories may have intersecting points, resulting in multiple possible values of \(\dot{X}_t\) associated with the same point \(X_t\) due to uncertainty about the originating trajectory (see the straight interpolation figure). However, by the definition of an ODE \(\dot{Z}_t = v_t^*(Z_t)\), the update direction \(\dot{Z}_t\) at each point \(Z_t\) is uniquely determined by \(Z_t\), making it impossible for different trajectories of \(\{Z_t\}\) to intersect and then diverge. At these intersection points of \(\{X_t\}\), where \(\dot{X}_t\) is stochastic and non-unique, \(Z_t\) “derandomizes” the update direction by following the conditional expectation:</p> \[v_t^*(X_t) = \mathbb{E} \left[ \dot{X}_t \mid X_t \right],\] <p>thus providing the unique update direction required by ODEs.</p> <p>What makes rectified flow \(\{Z_t\}\) useful is that it preserves the marginal distributions of \(\{X_t\}\) at each point while resulting in a “better” coupling \((Z_0, Z_1)\) in terms of optimal transport:</p> <h4 id="1-marginal-preservation">1. Marginal Preservation</h4> <p>The \(\{X_t\}\) and its rectified flow \(\{Z_t\}\) share the same marginal distributions at each time \(t \in [0, 1]\), that is:</p> \[\text{Law}(Z_t) = \text{Law}(X_t), \quad \forall t \in [0, 1].\] <div class="l-body"> <img src="/assets/img/flow_in_out.png" alt="cross" style="max-width:100%;"/> </div> <h4 id="2-transport-cost">2. Transport Cost</h4> <p>The start-end pairs \((Z_0, Z_1)\) from the rectified flow \(\{Z_t\}\) guarantee to yield no larger transport cost than \((X_0, X_1)\), simultaneously for all convex cost functions \(c\):</p> \[\mathbb{E} \left[ c(Z_1 - Z_0) \right] \leq \mathbb{E} \left[ c(X_1 - X_0) \right], \quad \forall \text{convex } c : \mathbb{R}^d \to \mathbb{R}.\] <h2 id="reflow">Reflow</h2> <p>While rectified flows tend to favor straight trajectories, they are not perfectly straight. As shown in Figure, the flow makes turns at intersection points of the interpolation trajectories \(\{X_t\}\). How can we further improve the flow to achieve straighter trajectories and hence speed up inference?</p> <p>A key insight is that the start-end pairs \((Z_0, Z_1)\) generated by rectified flow, called the <strong>rectified coupling</strong> of \((X_0, X_1)\), form a better and “straighter” coupling compared to \((X_0, X_1)\). This is because if we connect \(Z_0\) and \(Z_1\) with a new straight-line interpolation, it would yield fewer intersection points. Hence, training a new rectified flow based on this interpolation would result in straighter trajectories, leading to faster inference.</p> <p>Formally, we apply the RectFlow(·) procedure recursively, yielding a sequence of rectified flows starting from \(\{Z_t^0\} = \{X_t^0\}\):</p> <p><strong>Reflow:</strong></p> \[\{Z_t^{k+1}\} = \texttt{RectFlow}(\texttt{Interp}(Z_0^k, Z_1^k)), \tag{4}\] <p>where \(\text{Interp}(Z_0^k, Z_1^k)\) denotes an interpolation process given \((Z_0^k, Z_1^k)\) as the endpoints. We call \(\{Z_t^k\}\) the k-th rectified flow, or simply <strong>k-rectified flow</strong>, induced from \((X_0, X_1)\).</p> <p>This reflow procedure is proved to “straighten” the paths of rectified flows in the following sense: Define the following measure of straightness of \(\{Z_t\}\):</p> \[S(\{Z_t\}) = \int_0^1 \mathbb{E} \left[ \|Z_1 - Z_0 - \dot{Z}_t\|^2 \right] \mathrm dt,\] <p>where \(S(\{Z_t\})\) is a measure of the straightness of \(\{Z_t\}\), with \(S(\{Z_t\}) = 0\) corresponding to straight paths. Then we have the following for reflow:</p> \[\mathbb{E}_{k \sim \text{Unif}(\{1, \dots, K\})} \left[S(\{Z_t^k\})\right] = \mathcal{O}(1 / K), \tag{5}\] <p>Hence, we would obtain perfectly straight-line dynamics in the limit of \(k \to +\infty\). Note that reflow can begin from any coupling \((X_0, X_1)\), so it provides a general procedure for straightening and thus speeding up any given dynamics while preserving the marginals.</p> <div class="l-body"> <iframe src="/assets/plotly/intro_2rf.html" frameborder="0" scrolling="no" height="630px" width="100%"></iframe> </div>]]></content><author><name>Qiang Liu</name></author><category term="introduction"/><summary type="html"><![CDATA[A Brief Introduction to the Rectified Flow Model]]></summary></entry></feed>